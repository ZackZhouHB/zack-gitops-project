<?xml version="1.0" encoding="utf-8"?><feed xmlns="http://www.w3.org/2005/Atom" ><generator uri="https://jekyllrb.com/" version="4.3.2">Jekyll</generator><link href="http://localhost:4000/feed.xml" rel="self" type="application/atom+xml" /><link href="http://localhost:4000/" rel="alternate" type="text/html" /><updated>2024-07-24T20:51:59+10:00</updated><id>http://localhost:4000/feed.xml</id><title type="html">Zack’s Blog</title><subtitle>## AWS   ## Jenkins  ## Microservices ## Automation ## K8S   ## CICD     ## Gitops </subtitle><entry><title type="html">RedHat Identity Management (IdM) with AD Intergration</title><link href="http://localhost:4000/jekyll/cat2/2024/07/13/Redhatidm.html" rel="alternate" type="text/html" title="RedHat Identity Management (IdM) with AD Intergration" /><published>2024-07-13T10:15:29+10:00</published><updated>2024-07-13T10:15:29+10:00</updated><id>http://localhost:4000/jekyll/cat2/2024/07/13/Redhatidm</id><content type="html" xml:base="http://localhost:4000/jekyll/cat2/2024/07/13/Redhatidm.html"><![CDATA[<p><b> About Linux Identity Management </b></p>

<p>When a company faces challenge to manage its Linux environments across local and public cloud, RedHat Identity management can be the solution to achieve:</p>

<ul>
  <li>
    <p>With Local AD and Azure AD (AAD) Integration</p>
  </li>
  <li>
    <p>With AWS SSO Integration as externel identity provider</p>
  </li>
  <li>
    <p>LDAP, Kerberos and NTP</p>
  </li>
  <li>
    <p>A web-based management front-end running on Apache</p>
  </li>
</ul>

<p><b> A Typical AD User Authentication Flow End-to-End: </b></p>

<p>User Creation and Management:</p>

<ul>
  <li>
    <p>Azure AD / Local AD: Users are created in the Azure Active Directory or local Active Directory.</p>
  </li>
  <li>
    <p>Synchronization to RedHat IdM: The users are synchronized from AD to RedHat IdM using the two-way trust established between AD and IdM.</p>
  </li>
</ul>

<p>Accessing EC2 Instances via SSH:</p>

<ul>
  <li>User Sync to RedHat IdM: Users synchronized to RedHat IdM are assigned roles and permissions, including SSH access to specific EC2 instances.</li>
</ul>

<p>Host-Based Access Control (HBAC):</p>

<ul>
  <li>
    <p>HBAC Rules: RedHat IdM enforces HBAC rules to control which users can access specific EC2 instances.</p>
  </li>
  <li>
    <p>SSH Access Control: When a user attempts to SSH into an EC2 instance, RedHat IdM verifies the user’s identity and permissions, allowing or denying access based on the defined HBAC rules.</p>
  </li>
</ul>

<p><b> The design:</b></p>

<p>For Idm on AWS, configure the security groups to allow ports required by IdM. IdM desires below to be open:</p>

<p>HTTP/HTTPS — 80, 443 — TCP</p>

<p>LDAP/LDAPS — 389, 636 — TCP</p>

<p>Kerberos — 88, 464 — Both TCP and UDP</p>

<p>DNS — 53 — Both TCP and UDP</p>

<p>NTP — 123 — UDP</p>

<p>Here I am going to:</p>

<ul>
  <li>
    <p>install and configure a local freeIPA server</p>
  </li>
  <li>
    <p>enroll 2 Linux client machines (both CentOS and Ubuntu)</p>
  </li>
  <li>
    <p>Setup a local AD,</p>
  </li>
  <li>
    <p>build a 2 way trust between idm and AD</p>
  </li>
  <li>
    <p>Validate IDM and AD user to ssh into idm client machines.</p>
  </li>
</ul>

<p><b> Prerequisites: </b></p>

<ul>
  <li>
    <p>Windows AD Domain <b> ad.zack.world</b> and Idm Domain <b> ipa.zack.world</b></p>
  </li>
  <li>
    <p>Windows AD: 11.0.1.181 dc01.ad.zack.world (win server 2019)</p>
  </li>
  <li>
    <p>Windows client1: 11.0.1.182 win-client.ad.zack.world (win server 2019)</p>
  </li>
  <li>
    <p>idm Server: 11.0.1.180 server1.ipa.zack.world (CentOS 9)</p>
  </li>
  <li>
    <p>idm Client2: 11.0.1.184 ubt-client02.ipa.zack.world (Ubuntu 24.04)</p>
  </li>
  <li>
    <p>idm Client3: 11.0.1.185 idm-client3-centos7.ipa.zack.world (CentOS 9)</p>
  </li>
</ul>

<p><b> FreeIPA Installation </b></p>

<p>On freeIPA Server server1.ipa.zack.world 11.0.1.180 (CentOS 9):</p>

<figure class="highlight"><pre><code class="language-shell" data-lang="shell"><span class="c"># set hostname, IP and DNS</span>
hostnamectl set-hostname server1.ipa.zack.world

<span class="c"># add 3 hosts to /etc/hosts</span>
<span class="nb">echo </span>11.0.1.180 server1.ipa.zack.world  ipa <span class="o">&gt;&gt;</span> /etc/hosts
<span class="nb">echo </span>11.0.1.184 ubt-client02.ipa.zack.world ipa <span class="o">&gt;&gt;</span> /etc/hosts
<span class="nb">echo </span>11.0.1.185  idm-client3-centos7.ipa.zack.world  ipa <span class="o">&gt;&gt;</span> /etc/hosts
<span class="nb">echo </span>11.0.1.181  dc01.ad.zack.world ipa <span class="o">&gt;&gt;</span> /etc/hosts

<span class="c"># install ipa-server</span>
dnf <span class="nt">-y</span> <span class="nb">install </span>freeipa-server freeipa-server-dns freeipa-client

<span class="c"># Configure ipa-server and DNS, here set ipa console and domain admin password</span>
ipa-server-install <span class="nt">--setup-dns</span>

<span class="c"># confirm or change NetBIOS domain name</span>
NetBIOS domain name <span class="o">[</span>IPA]: IPA01

The ipa-server-install <span class="nb">command </span>was successful.

<span class="c"># Configure firewall rules and services</span>
firewall-cmd <span class="nt">--add-service</span><span class="o">={</span>freeipa-ldap,freeipa-ldaps,dns,ntp<span class="o">}</span>
firewall-cmd <span class="nt">--runtime-to-permanent</span>
firewall-cmd <span class="nt">--reload</span> 

<span class="c"># check ipastatus</span>
<span class="o">[</span>root@freeipa ~]# ipactl status
Directory Service: RUNNING
krb5kdc Service: RUNNING
kadmin Service: RUNNING
httpd Service: RUNNING
ipa-custodia Service: RUNNING
ntpd Service: RUNNING
pki-tomcatd Service: RUNNING
ipa-otpd Service: RUNNING
ipa: INFO: The ipactl <span class="nb">command </span>was successful

<span class="c"># Obtain a Kerberos ticket for the Kerberos admin user and Verify the ticket</span>
kinit admin
klist

Ticket cache: KEYRING:persistent:0:0
Default principal: admin@ZACKZ.OONLINE

Valid starting     Expires            Service principal
07/13/24 22:17:29  07/14/24 22:02:43  HTTP/server1.ipa.zack.world@IPA.ZACK.WORLD

<span class="c"># check content of /etc/resolv.conf</span>
<span class="nb">cat</span> /etc/resolv.conf
search ipa.zack.world
nameserver 127.0.0.1

<span class="c"># Configure default login shell to Bash and Create User tina</span>
ipa config-mod <span class="nt">--defaultshell</span><span class="o">=</span>/bin/bash
ipa user-add tina <span class="nt">--first</span><span class="o">=</span>tina <span class="nt">--last</span><span class="o">=</span>qi <span class="nt">--password</span></code></pre></figure>

<p><img src="/assets/idm3.png" alt="image tooltip here" /></p>

<p><b> Idm client Enrollment </b></p>

<p>Now the idm web portal should be accessible, by adding “11.0.1.180 server1.ipa.zack.world” into local “c:/wondows/system32/drivers/etc/hosts.</p>

<p>Then enrol both centos and Ubuntu IDM client machines</p>

<ul>
  <li>On FreeIPA Server, add DNS entry for FreeIPA Client machines</li>
</ul>

<figure class="highlight"><pre><code class="language-shell" data-lang="shell"><span class="c"># ipa dnsrecord-add [domain name] [record name] [record type] [record]</span>
ipa dnsrecord-add ipa.zack.world idm-client3-centos7 <span class="nt">--a-rec</span> 11.0.1.185
ipa dnsrecord-add ipa.zack.world ubt-client02 <span class="nt">--a-rec</span> 11.0.1.184

- <span class="nb">set </span>IP, <span class="nb">hostname</span>, DNS on idm client
<span class="c"># set idm server ID as client DNS</span>
nmcli connection modify ens33 ipv4.dns 11.0.1.180
nmcli connection up ens33

<span class="c"># Install FreeIPA Client packages.</span>
dnf <span class="nt">-y</span> <span class="nb">install </span>freeipa-client

<span class="c"># enrol client to idm server with domain name</span>
ipa-client-install <span class="nt">--server</span><span class="o">=</span>server1.ipa.zack.world <span class="nt">--domain</span> ipa.zack.world

Enrolled <span class="k">in </span>IPA realm IPA.ZACK.WORLD
Configuring ipa.zack.world as NIS domain.
Client configuration complete.
The ipa-client-install <span class="nb">command </span>was successful

<span class="c"># set create home directory at initial login</span>
authselect enable-feature with-mkhomedir
systemctl <span class="nb">enable</span> <span class="nt">--now</span> oddjobd

<span class="c"># same as Ubuntu client</span>
<span class="nb">echo </span>11.0.1.180 server1.ipa.zack.world server1 <span class="o">&gt;&gt;</span> /etc/hosts
<span class="nb">echo </span>11.0.1.184 ubt-client02.ipa.zack.world ubt-client02 <span class="o">&gt;&gt;</span> /etc/hosts
<span class="nb">echo </span>11.0.1.185 idm-client3-centos7.ipa.zack.world idm-client3-centos7 <span class="o">&gt;&gt;</span> /etc/hosts

<span class="c"># Edit host file and install client, then enrol into idm server domain</span>
apt update <span class="o">&amp;&amp;</span> apt <span class="nb">install </span>freeipa-client oddjob-mkhomedir <span class="nt">-y</span>
ipa-client-install <span class="nt">--server</span><span class="o">=</span>server1.ipa.zack.world <span class="nt">--domain</span> ipa.zack.world

Client configuration complete.
The ipa-client-install <span class="nb">command </span>was successful</code></pre></figure>

<p><img src="/assets/idm2.png" alt="image tooltip here" /></p>

<p><b> Setup idm and AD trust</b></p>

<p>On Windows DC, setup AD</p>

<ul>
  <li>
    <p>install ADDC role and feature</p>
  </li>
  <li>
    <p>create forest “ad.zack.world”</p>
  </li>
  <li>
    <p>promote to primary DC</p>
  </li>
  <li>
    <p>test AD to join Windows client machine to domain</p>
  </li>
  <li>
    <p>create AD user joez@ad.zack.world</p>
  </li>
  <li>
    <p>add idm domain to Windows AD zones</p>
  </li>
</ul>

<figure class="highlight"><pre><code class="language-shell" data-lang="shell"><span class="c"># dnscmd 127.0.0.1 /ZoneAdd [FreeIPA domain name] /Secondary [FreeIPA IP address]</span>
C:<span class="se">\U</span>sers<span class="se">\A</span>dministrator&gt;dnscmd 127.0.0.1 /ZoneAdd ipa.zack.world /Secondary 11.0.1.180
DNS Server 127.0.0.1 created zone ipa.zack.world:

Command completed successfully.

<span class="c"># Verify both AD and Idm DNS resolution, then setup trust</span>
dig SRV _ldap._tcp.ipa.zack.world
dig SRV _ldap._tcp.ad.zack.world</code></pre></figure>

<p><img src="/assets/idm1.png" alt="image tooltip here" /></p>

<ul>
  <li>Install required packages then setup trust on FreeIPA Server</li>
</ul>

<figure class="highlight"><pre><code class="language-shell" data-lang="shell"><span class="c"># Install packages</span>
dnf <span class="nt">-y</span> <span class="nb">install </span>ipa-server-trust-ad
<span class="c"># setup ad trust</span>
ipa-adtrust-install

<span class="c"># FreeIPA admin password</span>
admin password:
<span class="o">=============================================================================</span>
Setup <span class="nb">complete</span>

<span class="c"># add firewall service and ports for ad trust</span>
firewall-cmd <span class="nt">--add-service</span><span class="o">=</span>freeipa-trust

firewall-cmd <span class="nt">--permanent</span> <span class="nt">--add-port</span><span class="o">=</span>135/tcp
firewall-cmd <span class="nt">--permanent</span> <span class="nt">--add-port</span><span class="o">=</span>138/tcp
firewall-cmd <span class="nt">--permanent</span> <span class="nt">--add-port</span><span class="o">=</span>139/tcp
firewall-cmd <span class="nt">--permanent</span> <span class="nt">--add-port</span><span class="o">=</span>445/tcp
firewall-cmd <span class="nt">--permanent</span> <span class="nt">--add-port</span><span class="o">=</span>1024-1300/tcp
firewall-cmd <span class="nt">--permanent</span> <span class="nt">--add-port</span><span class="o">=</span>3268/tcp
<span class="c"># Open UDP ports</span>
firewall-cmd <span class="nt">--permanent</span> <span class="nt">--add-port</span><span class="o">=</span>138/udp
firewall-cmd <span class="nt">--permanent</span> <span class="nt">--add-port</span><span class="o">=</span>139/udp
firewall-cmd <span class="nt">--permanent</span> <span class="nt">--add-port</span><span class="o">=</span>389/udp
firewall-cmd <span class="nt">--permanent</span> <span class="nt">--add-port</span><span class="o">=</span>445/udp
<span class="c"># Open TCP ports</span>
firewall-cmd <span class="nt">--permanent</span> <span class="nt">--add-port</span><span class="o">=</span>80/tcp
firewall-cmd <span class="nt">--permanent</span> <span class="nt">--add-port</span><span class="o">=</span>443/tcp
firewall-cmd <span class="nt">--permanent</span> <span class="nt">--add-port</span><span class="o">=</span>389/tcp
firewall-cmd <span class="nt">--permanent</span> <span class="nt">--add-port</span><span class="o">=</span>636/tcp
firewall-cmd <span class="nt">--permanent</span> <span class="nt">--add-port</span><span class="o">=</span>88/tcp
<span class="nb">sudo </span>firewall-cmd <span class="nt">--permanent</span> <span class="nt">--add-port</span><span class="o">=</span>464/tcp
<span class="nb">sudo </span>firewall-cmd <span class="nt">--permanent</span> <span class="nt">--add-port</span><span class="o">=</span>53/tcp
<span class="c"># Open UDP ports</span>
firewall-cmd <span class="nt">--permanent</span> <span class="nt">--add-port</span><span class="o">=</span>88/udp
firewall-cmd <span class="nt">--permanent</span> <span class="nt">--add-port</span><span class="o">=</span>464/udp
firewall-cmd <span class="nt">--permanent</span> <span class="nt">--add-port</span><span class="o">=</span>53/udp
firewall-cmd <span class="nt">--permanent</span> <span class="nt">--add-port</span><span class="o">=</span>123/udp

firewall-cmd <span class="nt">--reload</span>

<span class="c"># Configure DNS Setting on FreeIPA Server</span>
<span class="c"># ipa dnsforwardzone-add [AD domain name] --forwarder=[AD IP address] --forward-policy=only</span>
ipa dnsforwardzone-add ad.zack.world <span class="nt">--forwarder</span><span class="o">=</span>11.0.1.181 <span class="nt">--forward-policy</span><span class="o">=</span>only
<span class="c"># ipa dnszone-mod [IPA domain name] --allow-transfer=[AD IP address]</span>
ipa dnszone-mod ipa.zack.world <span class="nt">--allow-transfer</span><span class="o">=</span>11.0.1.181

<span class="c"># ipa trust-add --type=ad [AD domain name] --admin Administrator --password</span>
ipa trust-add <span class="nt">--two-way</span><span class="o">=</span><span class="nb">true</span> <span class="nt">--type</span><span class="o">=</span>ad ad.zack.world <span class="nt">--admin</span> Administrator <span class="nt">--password</span>
Active Directory domain administrator<span class="s1">'s password:
-----------------------------------------------------
Added Active Directory trust for realm "ad.zack.world"
-----------------------------------------------------
 Realm name: ad.zack.world
 Domain NetBIOS name: AD01
 Domain Security Identifier: S-1-5-21-726412840-3773945212-2352305327
 Trust direction: Two-way trust
 Trust type: Active Directory domain
 Trust status: Established and verified

# set  home directory at initial login
authselect enable-feature with-mkhomedir
systemctl enable --now oddjobd</span></code></pre></figure>

<p><img src="/assets/idm4.png" alt="image tooltip here" /></p>

<p><b> Validation of both idm clients with idm and AD user</b></p>

<ul>
  <li>Validate ssh into ubuntu client with AD user “joez@ad.zack.world”</li>
</ul>

<p><img src="/assets/idm6.png" alt="image tooltip here" /></p>

<p>Validate ssh into Centos client with idm user “tina”</p>

<figure class="highlight"><pre><code class="language-shell" data-lang="shell">login as: tina
Keyboard-interactive authentication prompts from server:
| Password:
End of keyboard-interactive prompts from server
Last login: Sun Jul 14 20:48:42 2024 from 11.0.1.1
<span class="o">[</span>tina@idm-client3-centos7 ~]<span class="nv">$ </span><span class="nb">id
</span><span class="nv">uid</span><span class="o">=</span>1240000004<span class="o">(</span>tina<span class="o">)</span> <span class="nv">gid</span><span class="o">=</span>1240000004<span class="o">(</span>tina<span class="o">)</span> <span class="nb">groups</span><span class="o">=</span>1240000004<span class="o">(</span>tina<span class="o">)</span> 
<span class="nv">context</span><span class="o">=</span>unconfined_u:unconfined_r:unconfined_t:s0-s0:c0.c1023</code></pre></figure>

<p><b> Conclusion</b></p>

<p>Now we install Redhat IdM server and can enrol client hosts, set up AD trust, ssh and authenticate with both idm and AD users. IdM using Kerberos for authentication, together with user group, policy, HBAC and Sudo roles, provides a flexible and robust authentication framework that supports multiple authentication mechanisms, enabling organizations to authenticate users securely across their Linux and Unix environments.</p>

<p>More info can be found via <a href="https://freeipa.readthedocs.io/en/latest/workshop.html">Freeipa workshop</a>, <a href="https://www.server-world.info/en/note?os=CentOS_Stream_9&amp;p=freeipa&amp;f=8">FreeIPA:FreeIPA trust AD</a>, <a href="https://access.redhat.com/documentation/en-us/red_hat_enterprise_linux/9/html/managing_idm_users_groups_hosts_and_access_control_rules/index">Red Hat product documentation</a>, <a href="https://chamathb.wordpress.com/2019/06/21/setting-up-rhel-idm-with-integrated-dns-on-aws/">Redhat Idm on AWS with DNS forwarder</a>, <a href="https://www.reddit.com/r/redhat/comments/6ixtoe/idmfreeipa_dns_forwarding/">idmfreeipa DNS forwarder configurations on AWS</a>, and <a href="https://redhat.com/en/blog/automating-red-hat-identity-management-installation">Automating Red Hat Identity Management installation with Ansible</a>.</p>]]></content><author><name></name></author><category term="jekyll" /><category term="Cat2" /><summary type="html"><![CDATA[About Linux Identity Management]]></summary></entry><entry><title type="html">Serverless with AWS Fargate</title><link href="http://localhost:4000/jekyll/cat2/2024/07/10/aws-fargate.html" rel="alternate" type="text/html" title="Serverless with AWS Fargate" /><published>2024-07-10T10:15:29+10:00</published><updated>2024-07-10T10:15:29+10:00</updated><id>http://localhost:4000/jekyll/cat2/2024/07/10/aws-fargate</id><content type="html" xml:base="http://localhost:4000/jekyll/cat2/2024/07/10/aws-fargate.html"><![CDATA[<p><b>Why go serverless</b></p>

<p>Some of the company’s applications recently moved from Rancher to Fargate, which is understandable as the cloud resource and traffic will be very intensive only during a certain period (HSC exam), hence AWS serverless with Fargate can be a better option for such business mode so rest of the year without exam we can save cost significantly.</p>

<p><b>Hosting our blog on Fargate? Why not!</b></p>

<p>In the past, I used to try different methods to host this blog:</p>

<ul>
  <li><a href="https://zackz.site/jekyll/cat2/2023/11/02/about-this-project.html">EC2 with docker</a></li>
  <li><a href="https://zackz.site/jekyll/cat2/2023/11/07/ArgoCD.html">K8s with ArgoCD</a></li>
  <li><a href="https://zackz.site/jekyll/cat2/2024/04/30/serverless.html">S3 with static website</a></li>
  <li><a href="https://zackz.site/jekyll/cat2/2024/05/12/Helm.html">Customize Helm Chart for Zack’ Blog</a></li>
</ul>

<p>Here I will use AWS Fargate, together with AWS ECR, Docker, Terraform and Github Action workflow to move this blog to AWS serverless compute for containers.</p>

<ul>
  <li>Terraform Provisioning</li>
</ul>

<figure class="highlight"><pre><code class="language-shell" data-lang="shell"><span class="c"># Provider Configuration  "provider.tf"</span>
provider <span class="s2">"aws"</span> <span class="o">{</span>
 region <span class="o">=</span> <span class="s2">"ap-southeast-2"</span>
<span class="o">}</span>

<span class="c"># Create an ECR Repository "ecr.tf"</span>
resource <span class="s2">"aws_ecr_repository"</span> <span class="s2">"zackblog_repo"</span> <span class="o">{</span>
 name <span class="o">=</span> <span class="s2">"zackblog-repo"</span>
<span class="o">}</span>

<span class="c"># Fargate Task Definition  "task_definition.tf"</span>
resource <span class="s2">"aws_ecs_task_definition"</span> <span class="s2">"zackblog_task"</span> <span class="o">{</span>
 family                   <span class="o">=</span> <span class="s2">"zackblog-task"</span>
 network_mode             <span class="o">=</span> <span class="s2">"awsvpc"</span>
 requires_compatibilities <span class="o">=</span> <span class="o">[</span><span class="s2">"FARGATE"</span><span class="o">]</span>
 cpu                      <span class="o">=</span> <span class="s2">"256"</span>
 memory                   <span class="o">=</span> <span class="s2">"512"</span>

 container_definitions <span class="o">=</span> jsonencode<span class="o">([</span>
 <span class="o">{</span>
 name      <span class="o">=</span> <span class="s2">"zackblog-container"</span>,
 image     <span class="o">=</span> <span class="s2">"</span><span class="k">${</span><span class="nv">aws_ecr_repository</span><span class="p">.zackblog_repo.repository_url</span><span class="k">}</span><span class="s2">:latest"</span>,
 essential <span class="o">=</span> <span class="nb">true</span>,
 portMappings <span class="o">=</span> <span class="o">[</span>
 <span class="o">{</span>
 containerPort <span class="o">=</span> 80,
 hostPort      <span class="o">=</span> 80,
 protocol      <span class="o">=</span> <span class="s2">"tcp"</span>
 <span class="o">}</span>
 <span class="o">]</span>
 <span class="o">}</span>
 <span class="o">])</span>
<span class="o">}</span>

<span class="c"># Create an ECS Cluster "cluster.tf"</span>
resource <span class="s2">"aws_ecs_cluster"</span> <span class="s2">"zackblog_cluster"</span> <span class="o">{</span>
 name <span class="o">=</span> <span class="s2">"zackblog-cluster"</span>
<span class="o">}</span>

<span class="c"># Configure Networking to Use Default VPC - save cost haha</span>
<span class="c"># use the data block to fetch existing resources</span>
data <span class="s2">"aws_vpc"</span> <span class="s2">"default"</span> <span class="o">{</span>
 default <span class="o">=</span> <span class="nb">true</span>
<span class="o">}</span>

data <span class="s2">"aws_subnet"</span> <span class="s2">"default"</span> <span class="o">{</span>
 filter <span class="o">{</span>
 name   <span class="o">=</span> <span class="s2">"vpc-id"</span>
 values <span class="o">=</span> <span class="o">[</span>data.aws_vpc.default.id]
 <span class="o">}</span>
<span class="o">}</span>

resource <span class="s2">"aws_security_group"</span> <span class="s2">"zackblog_sg"</span> <span class="o">{</span>
 name_prefix <span class="o">=</span> <span class="s2">"zackblog-sg"</span>
 vpc_id      <span class="o">=</span> data.aws_vpc.default.id

 ingress <span class="o">{</span>
 from_port   <span class="o">=</span> 80
 to_port     <span class="o">=</span> 80
 protocol    <span class="o">=</span> <span class="s2">"tcp"</span>
 cidr_blocks <span class="o">=</span> <span class="o">[</span><span class="s2">"0.0.0.0/0"</span><span class="o">]</span>
 <span class="o">}</span>

 egress <span class="o">{</span>
 from_port   <span class="o">=</span> 0
 to_port     <span class="o">=</span> 0
 protocol    <span class="o">=</span> <span class="s2">"-1"</span>
 cidr_blocks <span class="o">=</span> <span class="o">[</span><span class="s2">"0.0.0.0/0"</span><span class="o">]</span>
 <span class="o">}</span>
<span class="o">}</span>

<span class="c"># Define the ECS Service "service.tf"</span>
resource <span class="s2">"aws_ecs_service"</span> <span class="s2">"zackblog_service"</span> <span class="o">{</span>
 name            <span class="o">=</span> <span class="s2">"zackblog-service"</span>
 cluster         <span class="o">=</span> aws_ecs_cluster.zackblog_cluster.id
 task_definition <span class="o">=</span> aws_ecs_task_definition.zackblog_task.arn
 desired_count   <span class="o">=</span> 1
 launch_type     <span class="o">=</span> <span class="s2">"FARGATE"</span>

 network_configuration <span class="o">{</span>
 subnets         <span class="o">=</span> <span class="o">[</span><span class="k">for </span>subnet <span class="k">in </span>data.aws_subnet.default : subnet.id]
 security_groups <span class="o">=</span> <span class="o">[</span>aws_security_group.zackblog_sg.id]
 assign_public_ip <span class="o">=</span> <span class="nb">true</span>
 <span class="o">}</span>
<span class="o">}</span>

<span class="c"># Configure Load Balancer and attach to Fargate service "load_balancer.tf"</span>
resource <span class="s2">"aws_lb"</span> <span class="s2">"zackblog_lb"</span> <span class="o">{</span>
 name               <span class="o">=</span> <span class="s2">"zackblog-lb"</span>
 internal           <span class="o">=</span> <span class="nb">false
 </span>load_balancer_type <span class="o">=</span> <span class="s2">"application"</span>
 security_groups    <span class="o">=</span> <span class="o">[</span>aws_security_group.zackblog_sg.id]
 subnets            <span class="o">=</span> <span class="o">[</span><span class="k">for </span>subnet <span class="k">in </span>data.aws_subnet.default : subnet.id]
<span class="o">}</span>

resource <span class="s2">"aws_lb_target_group"</span> <span class="s2">"zackblog_tg"</span> <span class="o">{</span>
 name     <span class="o">=</span> <span class="s2">"zackblog-tg"</span>
 port     <span class="o">=</span> 80
 protocol <span class="o">=</span> <span class="s2">"HTTP"</span>
 vpc_id   <span class="o">=</span> data.aws_vpc.default.id
<span class="o">}</span>

resource <span class="s2">"aws_lb_listener"</span> <span class="s2">"zackblog_listener"</span> <span class="o">{</span>
 load_balancer_arn <span class="o">=</span> aws_lb.zackblog_lb.arn
 port              <span class="o">=</span> 80
 protocol          <span class="o">=</span> <span class="s2">"HTTP"</span>

 default_action <span class="o">{</span>
 <span class="nb">type</span>             <span class="o">=</span> <span class="s2">"forward"</span>
 target_group_arn <span class="o">=</span> aws_lb_target_group.zackblog_tg.arn
 <span class="o">}</span>
<span class="o">}</span>

resource <span class="s2">"aws_lb_target_group_attachment"</span> <span class="s2">"zackblog_tg_attachment"</span> <span class="o">{</span>
 target_group_arn <span class="o">=</span> aws_lb_target_group.zackblog_tg.arn
 target_id        <span class="o">=</span> aws_ecs_service.zackblog_service.id
 port             <span class="o">=</span> 80
<span class="o">}</span></code></pre></figure>

<ul>
  <li>Github Action Workflow fo CICD</li>
</ul>

<p>1.First we need to create Github Secret to contain dockerhub and aws credentials and some other vars:</p>

<figure class="highlight"><pre><code class="language-shell" data-lang="shell">AWS_ACCESS_KEY_ID

AWS_SECRET_ACCESS_KEY

AWS_REGION

<span class="c"># xxx.dkr.ecr.ap-southeast-2.amazonaws.com</span>
ECR_REGISTRY  

<span class="c"># zackblog-repo</span>
ECR_REPOSITORY  

<span class="c"># zackblog-cluster</span>
ECS_CLUSTER 

<span class="c"># zackblog-service</span>
ECS_SERVICE </code></pre></figure>

<p>2.Then define the workflow to create /.github/workflows/zackblog-fargate.yaml, in this configure Github runner, it will :</p>

<p>Log in to Amazon ECR</p>

<p>Build and push Docker Image to the ECR repository</p>

<p>Deploy to ECS by updating the ECS service to use the new image by forcing a new deployment</p>

<figure class="highlight"><pre><code class="language-yaml" data-lang="yaml"><span class="na">name</span><span class="pi">:</span> <span class="s">Deploy to AWS Fargate</span>

<span class="na">on</span><span class="pi">:</span>
 <span class="na">push</span><span class="pi">:</span>
 <span class="na">branches</span><span class="pi">:</span>
 <span class="pi">-</span> <span class="s">editing  # not main branch</span>

<span class="na">jobs</span><span class="pi">:</span>
 <span class="na">deploy</span><span class="pi">:</span>
 <span class="na">runs-on</span><span class="pi">:</span> <span class="s">ubuntu-latest</span>

 <span class="na">steps</span><span class="pi">:</span>
 <span class="pi">-</span> <span class="na">name</span><span class="pi">:</span> <span class="s">Checkout code</span>
 <span class="na">uses</span><span class="pi">:</span> <span class="s">actions/checkout@v3</span>

 <span class="pi">-</span> <span class="na">name</span><span class="pi">:</span> <span class="s">Set up Docker Buildx</span>
 <span class="na">uses</span><span class="pi">:</span> <span class="s">docker/setup-buildx-action@v2</span>

 <span class="pi">-</span> <span class="na">name</span><span class="pi">:</span> <span class="s">Log in to Amazon ECR</span>
 <span class="na">env</span><span class="pi">:</span>
 <span class="na">AWS_REGION</span><span class="pi">:</span> <span class="s">${{ secrets.AWS_REGION }}</span>
 <span class="na">run</span><span class="pi">:</span> <span class="pi">|</span>
 <span class="s">aws ecr get-login-password --region $AWS_REGION | docker login --username AWS --password-stdin ${{ secrets.ECR_REGISTRY }}</span>

 <span class="s">- name: Build and push Docker image</span>
 <span class="s">env:</span>
 <span class="s">IMAGE_TAG: ${{ github.sha }}</span>
 <span class="s">ECR_REGISTRY: ${{ secrets.ECR_REGISTRY }}</span>
 <span class="s">ECR_REPOSITORY: ${{ secrets.ECR_REPOSITORY }}</span>
 <span class="s">run: |</span>
 <span class="s">docker build -t $ECR_REGISTRY/$ECR_REPOSITORY:$IMAGE_TAG .</span>
 <span class="s">docker push $ECR_REGISTRY/$ECR_REPOSITORY:$IMAGE_TAG</span>

 <span class="s">- name: Deploy to ECS</span>
 <span class="s">env:</span>
 <span class="s">AWS_REGION: ${{ secrets.AWS_REGION }}</span>
 <span class="s">ECS_CLUSTER: ${{ secrets.ECS_CLUSTER }}</span>
 <span class="s">ECS_SERVICE: ${{ secrets.ECS_SERVICE }}</span>
 <span class="s">ECR_REGISTRY: ${{ secrets.ECR_REGISTRY }}</span>
 <span class="s">ECR_REPOSITORY: ${{ secrets.ECR_REPOSITORY }}</span>
 <span class="s">IMAGE_TAG: ${{ github.sha }}</span>
 <span class="s">run: |</span>
 <span class="s">aws ecs update-service --cluster $ECS_CLUSTER --service $ECS_SERVICE --force-new-deployment --region $AWS_REGION</span></code></pre></figure>

<p><b> Conclusion</b></p>

<p>Now we have a seamless incurvature as a code together with CICD pipeline to ensure that the “Zack’s Blog” can be moved to AWS serverless container service Fargate, every time I update the blog by committing changes to “zack-gitops-project” editing branch, a new Docker image will be built, pushed to ECR, and the AWS Fargate service is automatically updated.  </p>]]></content><author><name></name></author><category term="jekyll" /><category term="Cat2" /><summary type="html"><![CDATA[Why go serverless]]></summary></entry><entry><title type="html">Automate Package Deployment via AWS System Manager</title><link href="http://localhost:4000/jekyll/cat2/2024/06/23/aws-ssm.html" rel="alternate" type="text/html" title="Automate Package Deployment via AWS System Manager" /><published>2024-06-23T10:15:29+10:00</published><updated>2024-06-23T10:15:29+10:00</updated><id>http://localhost:4000/jekyll/cat2/2024/06/23/aws-ssm</id><content type="html" xml:base="http://localhost:4000/jekyll/cat2/2024/06/23/aws-ssm.html"><![CDATA[<p><b>The task</b></p>

<p>Recently we got a task from the Company’s security team, to install 2 security agents which will be used to perform centralized security scans for all active AWS EC2 instances. here I will see how to use AWS Systems Manager for software distribution and installation for multiple AWS accounts and infrastructure at scale.</p>

<p>SSM features will be used :</p>

<ul>
  <li><b>Session Manager</b>: ensure the EC2 instance has the SSM Agent installed and running and The instances need an IAM role with at least the <code class="language-plaintext highlighter-rouge">AmazonSSMManagedInstanceCore</code> policy attached  </li>
  <li><b>Run Command</b>: send command and execute security agent software package installation scripts and command to varify post-installation status on remote instances for task automation</li>
</ul>

<p>Prerequisites:</p>
<ul>
  <li>
    <p><b>AWSCLI</b>: programatically manage all the operation bellow.</p>
  </li>
  <li>
    <p><b>SSM Agent</b>: Ensure the SSM Agent is installed and running on all EC2 instances. Most Amazon Machine Images (AMIs) have the SSM Agent pre-installed.</p>
  </li>
  <li>
    <p><b>IAM Role</b>: Attach an IAM role to each instance with the AmazonSSMManagedInstanceCore policy.</p>
  </li>
</ul>

<p>Create and attach IAM role to EC2 instance for SSM to be able to perform action:</p>

<figure class="highlight"><pre><code class="language-shell" data-lang="shell"><span class="o">[</span>cloudshell-user@ip-10-134-56-72 ~]<span class="nv">$ </span>vim trust-policy.json

<span class="o">{</span>
 <span class="s2">"Version"</span>: <span class="s2">"2012-10-17"</span>,
 <span class="s2">"Statement"</span>: <span class="o">[</span>
 <span class="o">{</span>
 <span class="s2">"Effect"</span>: <span class="s2">"Allow"</span>,
 <span class="s2">"Principal"</span>: <span class="o">{</span>
 <span class="s2">"Service"</span>: <span class="s2">"ec2.amazonaws.com"</span>
 <span class="o">}</span>,
 <span class="s2">"Action"</span>: <span class="s2">"sts:AssumeRole"</span>
 <span class="o">}</span>
 <span class="o">]</span>
<span class="o">}</span>

<span class="o">[</span>cloudshell-user@ip-10-134-56-72 ~]<span class="nv">$ </span>aws iam create-role <span class="nt">--role-name</span> SSMAccessRole <span class="nt">--assume-role-policy-document</span> file://trust-policy.json
<span class="o">{</span>
 <span class="s2">"Role"</span>: <span class="o">{</span>
 <span class="s2">"Path"</span>: <span class="s2">"/"</span>,
 <span class="s2">"RoleName"</span>: <span class="s2">"SSMAccessRole"</span>,
 <span class="s2">"RoleId"</span>: <span class="s2">"AROA4MTWLTSHKK3QL3NOU"</span>,
 <span class="s2">"Arn"</span>: <span class="s2">"arn:aws:iam::85xxxxxx1342:role/SSMAccessRole"</span>,
 <span class="s2">"CreateDate"</span>: <span class="s2">"2024-06-25T00:29:07+00:00"</span>,
 <span class="s2">"AssumeRolePolicyDocument"</span>: <span class="o">{</span>
 <span class="s2">"Version"</span>: <span class="s2">"2012-10-17"</span>,
 <span class="s2">"Statement"</span>: <span class="o">[</span>
 <span class="o">{</span>
 <span class="s2">"Effect"</span>: <span class="s2">"Allow"</span>,
 <span class="s2">"Principal"</span>: <span class="o">{</span>
 <span class="s2">"Service"</span>: <span class="s2">"ec2.amazonaws.com"</span>
 <span class="o">}</span>,
 <span class="s2">"Action"</span>: <span class="s2">"sts:AssumeRole"</span>
 <span class="o">}</span>
 <span class="o">]</span>
 <span class="o">}</span>
 <span class="o">}</span>
<span class="o">}</span>

<span class="o">[</span>cloudshell-user@ip-10-134-56-72 ~]<span class="nv">$ </span>aws iam attach-role-policy <span class="nt">--role-name</span> SSMAccessRole <span class="nt">--policy-arn</span> arn:aws:iam::aws:policy/AmazonSSMManagedInstanceCore

<span class="o">[</span>cloudshell-user@ip-10-134-56-72 ~]<span class="nv">$ </span>aws iam create-instance-profile <span class="nt">--instance-profile-name</span> SSMInstanceProfile
<span class="o">{</span>
 <span class="s2">"InstanceProfile"</span>: <span class="o">{</span>
 <span class="s2">"Path"</span>: <span class="s2">"/"</span>,
 <span class="s2">"InstanceProfileName"</span>: <span class="s2">"SSMInstanceProfile"</span>,
 <span class="s2">"InstanceProfileId"</span>: <span class="s2">"AIPA4MTWLTSHF7KJRFLYC"</span>,
 <span class="s2">"Arn"</span>: <span class="s2">"arn:aws:iam::851xxxxxxx42:instance-profile/SSMInstanceProfile"</span>,
 <span class="s2">"CreateDate"</span>: <span class="s2">"2024-06-25T00:31:25+00:00"</span>,
 <span class="s2">"Roles"</span>: <span class="o">[]</span>
 <span class="o">}</span>
<span class="o">}</span>

<span class="o">[</span>cloudshell-user@ip-10-134-56-72 ~]<span class="nv">$ INSTANCE_IDS</span><span class="o">=</span><span class="si">$(</span>aws ec2 describe-instances <span class="nt">--query</span> <span class="s2">"Reservations[*].Instances[*].InstanceId"</span> <span class="nt">--output</span> text<span class="si">)</span>
<span class="k">for </span>INSTANCE_ID <span class="k">in</span> <span class="nv">$INSTANCE_IDS</span><span class="p">;</span> <span class="k">do</span>
<span class="o">&gt;</span> aws ec2 associate-iam-instance-profile <span class="nt">--instance-id</span> <span class="nv">$INSTANCE_ID</span> <span class="nt">--iam-instance-profile</span> <span class="nv">Name</span><span class="o">=</span>SSMInstanceProfile
<span class="o">&gt;</span> <span class="k">done</span>

<span class="o">{</span>
 <span class="s2">"IamInstanceProfileAssociation"</span>: <span class="o">{</span>
 <span class="s2">"AssociationId"</span>: <span class="s2">"iip-assoc-04e81626bf6bcd9b5"</span>,
 <span class="s2">"InstanceId"</span>: <span class="s2">"i-0762xxxxxxxcf2"</span>,
 <span class="s2">"IamInstanceProfile"</span>: <span class="o">{</span>
 <span class="s2">"Arn"</span>: <span class="s2">"arn:aws:iam::8517xxxxxxx42:instance-profile/SSMInstanceProfile"</span>,
 <span class="s2">"Id"</span>: <span class="s2">"AIPA4MTWLTSHF7KJRFLYC"</span>
 <span class="o">}</span>,
 <span class="s2">"State"</span>: <span class="s2">"associating"</span>
 <span class="o">}</span>
<span class="o">}</span>
<span class="o">{</span>
 <span class="s2">"IamInstanceProfileAssociation"</span>: <span class="o">{</span>
 <span class="s2">"AssociationId"</span>: <span class="s2">"iip-assoc-09233165b3a53ca68"</span>,
 <span class="s2">"InstanceId"</span>: <span class="s2">"i-01a2xxxxxx048c"</span>,
 <span class="s2">"IamInstanceProfile"</span>: <span class="o">{</span>
 <span class="s2">"Arn"</span>: <span class="s2">"arn:aws:iam::851xxxx42:instance-profile/SSMInstanceProfile"</span>,
 <span class="s2">"Id"</span>: <span class="s2">"AIPA4MTWLTSHF7KJRFLYC"</span>
 <span class="o">}</span>,
 <span class="s2">"State"</span>: <span class="s2">"associating"</span>
 <span class="o">}</span>
<span class="o">}</span>
<span class="o">{</span>
 <span class="s2">"IamInstanceProfileAssociation"</span>: <span class="o">{</span>
 <span class="s2">"AssociationId"</span>: <span class="s2">"iip-assoc-09236a8ee456e39cd"</span>,
 <span class="s2">"InstanceId"</span>: <span class="s2">"i-07axxxxxxb823"</span>,
 <span class="s2">"IamInstanceProfile"</span>: <span class="o">{</span>
 <span class="s2">"Arn"</span>: <span class="s2">"arn:aws:iam::85xxxxxxx42:instance-profile/SSMInstanceProfile"</span>,
 <span class="s2">"Id"</span>: <span class="s2">"AIPA4MTWLTSHF7KJRFLYC"</span>
 <span class="o">}</span>,
 <span class="s2">"State"</span>: <span class="s2">"associating"</span>
 <span class="o">}</span>
<span class="o">}</span>

<span class="o">[</span>cloudshell-user@ip-10-134-56-72 ~]<span class="nv">$ </span>aws ssm describe-instance-information</code></pre></figure>

<p>Now verify from session manager to see if instances are there:</p>

<p><img src="/assets/ssm1.png" alt="image tooltip here" /></p>

<ul>
  <li>Tag Instances</li>
</ul>

<p>Tag EC2 instances to identify which instances need the security agent to be installed:</p>

<figure class="highlight"><pre><code class="language-shell" data-lang="shell"><span class="nv">Key</span><span class="o">=</span>InstallSecurityAgent, <span class="nv">Value</span><span class="o">=</span>True.</code></pre></figure>

<figure class="highlight"><pre><code class="language-shell" data-lang="shell"><span class="c"># List all instance IDs #: </span>
<span class="nv">INSTANCE_IDS</span><span class="o">=</span><span class="si">$(</span>aws ec2 describe-instances <span class="nt">--query</span> <span class="s2">"Reservations[*].Instances[*].InstanceId"</span> <span class="nt">--output</span> text<span class="si">)</span>

<span class="c"># Tag all instances with Key=InstallSecurityAgent and Value=True</span>
<span class="k">for </span>INSTANCE_ID <span class="k">in</span> <span class="nv">$INSTANCE_IDS</span><span class="p">;</span> <span class="k">do
 </span>aws ec2 create-tags <span class="nt">--resources</span> <span class="nv">$INSTANCE_ID</span> <span class="nt">--tags</span> <span class="nv">Key</span><span class="o">=</span>InstallSecurityAgent,Value<span class="o">=</span>True
<span class="k">done</span></code></pre></figure>

<ul>
  <li>SSM Run Command to Create a custom SSM document that contains the script to install the security agent</li>
</ul>

<figure class="highlight"><pre><code class="language-shell" data-lang="shell"><span class="o">[</span>cloudshell-user@ip-10-134-56-72 ~]<span class="nv">$ </span>vim install_security_agent.json
<span class="o">{</span>
 <span class="s2">"schemaVersion"</span>: <span class="s2">"2.2"</span>,
 <span class="s2">"description"</span>: <span class="s2">"Install Security Agent"</span>,
 <span class="s2">"mainSteps"</span>: <span class="o">[</span>
 <span class="o">{</span>
 <span class="s2">"action"</span>: <span class="s2">"aws:runShellScript"</span>,
 <span class="s2">"name"</span>: <span class="s2">"installSecurityAgent"</span>,
 <span class="s2">"inputs"</span>: <span class="o">{</span>
 <span class="s2">"runCommand"</span>: <span class="o">[</span>
 <span class="s2">"curl -o /tmp/security-agent-installer.sh https://github.com/ZackZhouHB/zack-gitops-project/blob/editing/Python_scripts/security-agent-installer.sh"</span>,
 <span class="s2">"chmod +x /tmp/security-agent-installer.sh"</span>,
 <span class="s2">"/tmp/security-agent-installer.sh"</span>
 <span class="o">]</span>
 <span class="o">}</span>
 <span class="o">}</span>
 <span class="o">]</span>
<span class="o">}</span></code></pre></figure>

<p>Create Document to execute the installation script on all tagged instances.</p>

<figure class="highlight"><pre><code class="language-shell" data-lang="shell"><span class="o">[</span>cloudshell-user@ip-10-134-56-72 ~]<span class="nv">$ </span>aws ssm create-document <span class="se">\</span>
 <span class="nt">--name</span> <span class="s2">"InstallSecurityAgent"</span> <span class="se">\</span>
 <span class="nt">--document-type</span> <span class="s2">"Command"</span> <span class="se">\</span>
 <span class="nt">--content</span> file://install_security_agent.json

<span class="o">{</span>
 <span class="s2">"DocumentDescription"</span>: <span class="o">{</span>
 <span class="s2">"Hash"</span>: <span class="s2">"9e17a699d2d987134eb05f6b49a7c837161320b0ed42635b07928acc557970b5"</span>,
 <span class="s2">"HashType"</span>: <span class="s2">"Sha256"</span>,
 <span class="s2">"Name"</span>: <span class="s2">"InstallSecurityAgent"</span>,
 <span class="s2">"Owner"</span>: <span class="s2">"851725491342"</span>,
 <span class="s2">"CreatedDate"</span>: <span class="s2">"2024-06-25T01:51:36.666000+00:00"</span>,
 <span class="s2">"Status"</span>: <span class="s2">"Creating"</span>,
 <span class="s2">"DocumentVersion"</span>: <span class="s2">"1"</span>,
 <span class="s2">"Description"</span>: <span class="s2">"Install Security Agent"</span>,
 <span class="s2">"PlatformTypes"</span>: <span class="o">[</span>
 <span class="s2">"Linux"</span>,
 <span class="s2">"MacOS"</span>
 <span class="o">]</span>,
 <span class="s2">"DocumentType"</span>: <span class="s2">"Command"</span>,
 <span class="s2">"SchemaVersion"</span>: <span class="s2">"2.2"</span>,
 <span class="s2">"LatestVersion"</span>: <span class="s2">"1"</span>,
 <span class="s2">"DefaultVersion"</span>: <span class="s2">"1"</span>,
 <span class="s2">"DocumentFormat"</span>: <span class="s2">"JSON"</span>,
 <span class="s2">"Tags"</span>: <span class="o">[]</span>
 <span class="o">}</span>
<span class="o">}</span>

<span class="o">[</span>cloudshell-user@ip-10-132-90-150 ~]<span class="nv">$ </span>aws ssm send-command <span class="se">\</span>
<span class="o">&gt;</span> <span class="nt">--document-name</span> <span class="s2">"InstallSecurityAgent"</span> <span class="se">\</span>
<span class="o">&gt;</span> <span class="nt">--targets</span> <span class="s2">"Key=tag:InstallSecurityAgent,Values=True"</span> <span class="se">\</span>
<span class="o">&gt;</span> <span class="nt">--comment</span> <span class="s2">"Installing security agent on all instances with the specified tag"</span> <span class="se">\</span>
<span class="o">&gt;</span> <span class="nt">--max-concurrency</span> <span class="s2">"50"</span> <span class="se">\</span>
<span class="o">&gt;</span> <span class="nt">--max-errors</span> <span class="s2">"0"</span> <span class="se">\</span>
<span class="o">&gt;</span> <span class="nt">--region</span> ap-southeast-2
<span class="o">{</span>
 <span class="s2">"Command"</span>: <span class="o">{</span>
 <span class="s2">"CommandId"</span>: <span class="s2">"edfc9e9b-5e74-4660-8335-a98eb48251f7"</span>,
 <span class="s2">"DocumentName"</span>: <span class="s2">"InstallSecurityAgent"</span>,
 <span class="s2">"DocumentVersion"</span>: <span class="s2">"</span><span class="nv">$DEFAULT</span><span class="s2">"</span>,
 <span class="s2">"Comment"</span>: <span class="s2">"Installing security agent on all instances with the specified tag"</span>,
 <span class="s2">"ExpiresAfter"</span>: <span class="s2">"2024-06-25T04:03:44.665000+00:00"</span>,
 <span class="s2">"Parameters"</span>: <span class="o">{}</span>,
 <span class="s2">"InstanceIds"</span>: <span class="o">[]</span>,
 <span class="s2">"Targets"</span>: <span class="o">[</span>
 <span class="o">{</span>
 <span class="s2">"Key"</span>: <span class="s2">"tag:InstallSecurityAgent"</span>,
 <span class="s2">"Values"</span>: <span class="o">[</span>
 <span class="s2">"True"</span>
 <span class="o">]</span>
 <span class="o">}</span>
 <span class="o">]</span>,
 <span class="s2">"RequestedDateTime"</span>: <span class="s2">"2024-06-25T02:03:44.665000+00:00"</span>,
 <span class="s2">"Status"</span>: <span class="s2">"Pending"</span>,
 <span class="s2">"StatusDetails"</span>: <span class="s2">"Pending"</span>,
 <span class="s2">"OutputS3Region"</span>: <span class="s2">"ap-southeast-2"</span>,
 <span class="s2">"OutputS3BucketName"</span>: <span class="s2">""</span>,
 <span class="s2">"OutputS3KeyPrefix"</span>: <span class="s2">""</span>,
 <span class="s2">"MaxConcurrency"</span>: <span class="s2">"50"</span>,
 <span class="s2">"MaxErrors"</span>: <span class="s2">"0"</span>,
 <span class="s2">"TargetCount"</span>: 0,
 <span class="s2">"CompletedCount"</span>: 0,
 <span class="s2">"ErrorCount"</span>: 0,
 <span class="s2">"DeliveryTimedOutCount"</span>: 0,
 <span class="s2">"ServiceRole"</span>: <span class="s2">""</span>,
 <span class="s2">"NotificationConfig"</span>: <span class="o">{</span>
 <span class="s2">"NotificationArn"</span>: <span class="s2">""</span>,
 <span class="s2">"NotificationEvents"</span>: <span class="o">[]</span>,
 <span class="s2">"NotificationType"</span>: <span class="s2">""</span>
 <span class="o">}</span>,
 <span class="s2">"CloudWatchOutputConfig"</span>: <span class="o">{</span>
 <span class="s2">"CloudWatchLogGroupName"</span>: <span class="s2">""</span>,
 <span class="s2">"CloudWatchOutputEnabled"</span>: <span class="nb">false</span>
 <span class="o">}</span>,
 <span class="s2">"TimeoutSeconds"</span>: 3600,
 <span class="s2">"AlarmConfiguration"</span>: <span class="o">{</span>
 <span class="s2">"IgnorePollAlarmFailure"</span>: <span class="nb">false</span>,
 <span class="s2">"Alarms"</span>: <span class="o">[]</span>
 <span class="o">}</span>,
 <span class="s2">"TriggeredAlarms"</span>: <span class="o">[]</span>
 <span class="o">}</span>
<span class="o">}</span>
<span class="o">(</span>END<span class="o">)</span></code></pre></figure>

<p>Validate from Run Command console for the installation:
<img src="/assets/ssm2.png" alt="image tooltip here" /></p>

<p>Create an SSM Document to Check the package installation status:</p>

<figure class="highlight"><pre><code class="language-shell" data-lang="shell"><span class="o">[</span>cloudshell-user@ip-10-134-56-72 ~]<span class="nv">$ </span>vim verify.json

<span class="o">{</span>
 <span class="s2">"schemaVersion"</span>: <span class="s2">"2.2"</span>,
 <span class="s2">"description"</span>: <span class="s2">"Install Security Agent"</span>,
 <span class="s2">"mainSteps"</span>: <span class="o">[</span>
 <span class="o">{</span>
 <span class="s2">"action"</span>: <span class="s2">"aws:runShellScript"</span>,
 <span class="s2">"name"</span>: <span class="s2">"installSecurityAgent"</span>,
 <span class="s2">"inputs"</span>: <span class="o">{</span>
 <span class="s2">"runCommand"</span>: <span class="o">[</span>
 <span class="s2">"apt list --installed | grep nfs-common"</span>,
 <span class="s2">"apt list --installed | grep lrzsz"</span>
 <span class="o">]</span>
 <span class="o">}</span>
 <span class="o">}</span>
 <span class="o">]</span>
<span class="o">}</span></code></pre></figure>

<p>Create this document using the AWS CLI:</p>

<figure class="highlight"><pre><code class="language-shell" data-lang="shell"><span class="o">[</span>cloudshell-user@ip-10-134-56-72 ~]<span class="nv">$ </span>aws ssm create-document <span class="se">\</span>
 <span class="nt">--name</span> <span class="s2">"VerifyPackageInstallation"</span> <span class="se">\</span>
 <span class="nt">--document-type</span> <span class="s2">"Command"</span> <span class="se">\</span>
 <span class="nt">--content</span> file://verify.json

<span class="o">[</span>cloudshell-user@ip-10-134-56-72 ~]<span class="nv">$ </span>aws ssm send-command <span class="se">\</span>
 <span class="nt">--document-name</span> <span class="s2">"VerifyPackageInstallation"</span> <span class="se">\</span>
 <span class="nt">--targets</span> <span class="s2">"Key=tag:InstallSecurityAgent,Values=True"</span> <span class="se">\</span>
 <span class="nt">--comment</span> <span class="s2">"Check if Packages installed on all instances"</span> <span class="se">\</span>
 <span class="nt">--max-concurrency</span> <span class="s2">"50"</span> <span class="se">\</span>
 <span class="nt">--max-errors</span> <span class="s2">"0"</span> <span class="se">\</span>
 <span class="nt">--region</span> ap-southeast-2</code></pre></figure>

<p>Verify both “nfs-common” and “lrzsz”, we have 3 machines with “nfs-common” installed, and 2 instances with Ubuntu24.04 which did not get “lrzsz” installed.</p>

<p><img src="/assets/ssm3.png" alt="image tooltip here" /></p>

<p><img src="/assets/ssm4.png" alt="image tooltip here" /></p>

<p><b> Conclusion</b></p>

<p>So now we can use AWS CLI and AWS System Manager to automate software deployment and verify the installation status.</p>]]></content><author><name></name></author><category term="jekyll" /><category term="Cat2" /><summary type="html"><![CDATA[The task]]></summary></entry><entry><title type="html">Handling a RDS MySQL cluster CPU 100%</title><link href="http://localhost:4000/jekyll/cat2/2024/06/17/mysql-cup100.html" rel="alternate" type="text/html" title="Handling a RDS MySQL cluster CPU 100%" /><published>2024-06-17T10:15:29+10:00</published><updated>2024-06-17T10:15:29+10:00</updated><id>http://localhost:4000/jekyll/cat2/2024/06/17/mysql-cup100</id><content type="html" xml:base="http://localhost:4000/jekyll/cat2/2024/06/17/mysql-cup100.html"><![CDATA[<p><b>The Incident</b></p>

<p>Today I got a performance issue from our analytic team, saying they experienced a Production MySQL cluster running on RDS very slow since yesterday morning.  </p>

<p>I started to look into bellow areas for investigation:</p>

<ul>
  <li>AWS CloudWatch Metrics for RDS</li>
</ul>

<p>AWS CloudWatch provides a wide range of metrics that can help diagnose resource usage for databases. So I started with</p>

<p><em>CloudWatch - Metrics - All metrics - Add query - RDS - Top 10 RDS instances by highest CPU utilization</em></p>

<p>This only queries the recent 3 hours metrics, but it is enough for me to identify the issue: CPU 100%</p>

<p><img src="/assets/mysqlcpu1.png" alt="image tooltip here" /></p>

<p>To further understand the high CUP, I go:</p>

<p><em>CloudWatch - Metrics - All metrics - Browse - RDS - DBClusterIdentifier - CPUUtilization</em></p>

<p>which gives me a long period of monitoring, so I can see it started to 100% CPU since yesterday morning.</p>

<p><img src="/assets/mysqlcpu2.png" alt="image tooltip here" /></p>

<ul>
  <li>AWS console RDS Logs &amp; events</li>
</ul>

<p>Now let’s find out from the RDS logs to see if any errors can indicate who could be the person. So I go</p>

<p><em>RDS - “the DB cluster” - “the DB instance” - “Logs &amp; events” - “error/mysql-error-running.log.2024-06-18.02”</em></p>

<p>I got :</p>

<figure class="highlight"><pre><code class="language-shell" data-lang="shell">2024-06-18T00:04:58.750212Z 2831474 <span class="o">[</span>Note] Aborted connection 2831474 to db: <span class="s1">'xxxxxx'</span> user: <span class="s1">'xxxx'</span> host: <span class="s1">'10.xx.xx.xx'</span> <span class="o">(</span>Unknown error<span class="o">)</span>
2024-06-18T00:12:00.798173Z 2831498 <span class="o">[</span>Note] Aborted connection 2831498 to db: <span class="s1">'xxxx'</span> user: <span class="s1">'xxxx'</span> host: <span class="s1">'10.xx.xx.xx'</span> <span class="o">(</span>Got an error writing communication packets<span class="o">)</span>
<span class="nt">-----------------------</span> END OF LOG <span class="nt">----------------------</span></code></pre></figure>

<p>Up to here I generally have an idea of what is going on and can locate the person “xxxx” who was running something at the time CPU 100%.</p>

<ul>
  <li>MySQL Client Tool to list, identiry and terminate long-running queries</li>
</ul>

<p>It is time to log in to the RDS endpoint to see what is happening and which queries might cause the CPU usage. Here we need login via MySQL “root” to be able to see all other users’ running processes. Then pay attention to the high “Time” and “State” values indicating all the stuck processes, then we kill them and restart the RDS instance</p>

<figure class="highlight"><pre><code class="language-shell" data-lang="shell">mysql <span class="nt">-u</span> root <span class="nt">-p</span> <span class="nt">-h</span> rds_endpoint
SHOW PROCESSLIST<span class="p">;</span>
KILL &lt;process_id&gt;<span class="p">;</span></code></pre></figure>

<p><img src="/assets/mysqlcpu4.png" alt="image tooltip here" /></p>

<p>Then I go <em>AWS RDS console - Actions - Reboot</em> the RDS instance.</p>

<ul>
  <li>Now the CPU usage started to drop and back to normal after terminating the stuck processes and DB instance reboot.</li>
</ul>

<p><img src="/assets/mysqlcpu3.png" alt="image tooltip here" /></p>

<p>Done.</p>

<p><b> Conclusion</b></p>

<p>Even the issue had been fixed, I was still thinking how to better monitor RDS resource usage. I think we need:</p>

<ul>
  <li>
    <p>A “CloudWatch Alarm” to set “CPUUtilization” metric threshold to 80%, then specify the period (e.g., 5 minutes) and the number of periods (e.g., 2 out of 3) that the metric must breach the threshold to trigger the alarm.</p>
  </li>
  <li>
    <p>Create “SNS topic” with team Email for the alarm to send a notification</p>
  </li>
  <li>
    <p>Enable “RDS Performance Insights”, this can monitor the load on the database, identify the source of bottlenecks, and understand how the DB is performing, especially during troubleshooting.</p>
  </li>
  <li>
    <p>Enable “Enhanced Monitoring” and select the monitoring interval (e.g., 1 minute), which provides real-time metrics for the operating system that the DB instance runs on, this helps for immediate investigation on OS level</p>
  </li>
  <li>
    <p>Enable “Slow Query Log” for regularly analysing slow query logs and performance insights to optimize RDS database queries, identify queries that take a long time to execute, use tools like EXPLAIN to understand query performance, add appropriate indexes, and then ultimately rewrite queries for better performance.</p>
  </li>
</ul>]]></content><author><name></name></author><category term="jekyll" /><category term="Cat2" /><summary type="html"><![CDATA[The Incident]]></summary></entry><entry><title type="html">Istio: Distributed Tracing with Jaeger</title><link href="http://localhost:4000/jekyll/cat2/2024/05/24/istio2.html" rel="alternate" type="text/html" title="Istio: Distributed Tracing with Jaeger" /><published>2024-05-24T10:15:29+10:00</published><updated>2024-05-24T10:15:29+10:00</updated><id>http://localhost:4000/jekyll/cat2/2024/05/24/istio2</id><content type="html" xml:base="http://localhost:4000/jekyll/cat2/2024/05/24/istio2.html"><![CDATA[<p><b>About Jaeger</b></p>

<p>Last post we are able to depoly <a href="https://zackz.online/jekyll/cat2/2024/05/22/istio.html">Istio</a> and manage traffic for a book review microservice application. This session we will dive deeper into Istia for it add-on Jaeger for Microservice tracing.</p>

<p>Jaeger is an open-source end-to-end distributed tracing tool to monitor and troubleshoot the performance of microservices-based distributed systems by providing insights into the latency and other performance metrics.</p>

<ul>
  <li>Trace</li>
</ul>

<p>A trace represents the entire journey of a request or transaction as it propagates through various services and components of a distributed system. It captures the path the request takes, including all the microservices it interacts with, from start to finish. A trace is composed of multiple spans.</p>

<ul>
  <li>Span</li>
</ul>

<p>A span is a single unit of work within a trace. It represents an individual operation within a microservice, such as a function call, database query, or external API request. Each span contains metadata such as:</p>

<p><b>Prepration for Hands on</b></p>

<p>Here we will use <a href="https://github.com/DickChesterwood/k8s-fleetman">Fleetman GPS sumilater microservice application</a> as example to explore Jaeger and it capabilities.</p>

<ul>
  <li>Enable Istio sidecar injection for existing deployment</li>
</ul>

<figure class="highlight"><pre><code class="language-shell" data-lang="shell"><span class="c"># lable the namaspace to allow istio sidecar container injection</span>
<span class="o">[</span>root@freeipa-server ~]# kubectl label namespace default istio-injection<span class="o">=</span>enabled <span class="nt">--overwrite</span>

<span class="c"># Redeploy fleetman application</span>
<span class="o">[</span>root@freeipa-server ~]# kubectl rollout restart deployment <span class="nt">-n</span> default</code></pre></figure>

<ul>
  <li>validate pod for istio sidecar injection, also check service status in Kiali</li>
</ul>

<figure class="highlight"><pre><code class="language-shell" data-lang="shell"><span class="o">[</span>root@freeipa-server ~]# kubectl get po
NAME                                                        READY   STATUS    RESTARTS       AGE
api-gateway-58f978dfc6-phdgp                                2/2     Running   4 <span class="o">(</span>30m ago<span class="o">)</span>    17h
position-simulator-6f5df9b447-57d75                         2/2     Running   4 <span class="o">(</span>30m ago<span class="o">)</span>    17h
position-tracker-6698577777-fz52v                           2/2     Running   4 <span class="o">(</span>30m ago<span class="o">)</span>    17h
staff-service-59987757dc-mfm2t                              2/2     Running   4 <span class="o">(</span>30m ago<span class="o">)</span>    17h
vehicle-telemetry-56c7f8d859-jvtpj                          2/2     Running   4 <span class="o">(</span>30m ago<span class="o">)</span>    17h
webapp-59bc7757fb-trnnv                                     2/2     Running   6 <span class="o">(</span>30m ago<span class="o">)</span>    17h</code></pre></figure>

<p><img src="/assets/istio2-2.png" alt="image tooltip here" /></p>

<p><b>How Jaeger Works</b></p>

<p>When a request enters a microservice (e.g., a user making a request to a frontend service), the tracing library creates a span and assigns it a trace ID. As the request propagates through other services, additional spans are created and linked to the same trace ID. Each span is recorded with its respective start and end timestamps, operation name, and other metadata.</p>

<p>The Jaeger UI provides a way to visualize traces. Users can search for traces based on various criteria (e.g., service name, operation name, duration) and view the detailed structure of individual traces, like durations of time spent between microservices.</p>

<p>As the request flows through different services, each service creates additional or child spans. (e.g., The frontend service might call an authentication service. then authentication service call a user service, thus Jaeger will create 2 child spans)</p>

<p><img src="/assets/istio2-1.png" alt="image tooltip here" /></p>

<p><b>Latency and Performance Analysis</b></p>

<p>By examining the durations of each span, If a particular span has a long duration, that service might be a bottleneck.
If spans have significant gaps between them, network latency or queuing delays might be an issue. so we can identify which part of the request is taking the most time and investigate further to optimize performance.</p>

<p><img src="/assets/istio2-4.png" alt="image tooltip here" /></p>

<p><b>Manage routing in each service from Kiali </b></p>

<p>Managing routing in Istio can be done either through the Kiali console or by defining VirtualServices and DestinationRules using Kubernetes YAML manifests. here from Kiali console, we have the visualization of each service traffic flow, metrics, and dependencies between services in real-time.</p>

<p>By create weighted routing or suspend traffic, Kiali will create it own VirtualServices and DestinationRules to manage the traffic</p>

<p><img src="/assets/istio2-3.png" alt="image tooltip here" /></p>

<p><b>Add timeout in istio virtual service YAML</b></p>

<p>To add a timeout into istio virtual service YAML and ensure it works with Jaeger for better visibility and efficiency in the microservice architecture.</p>

<p>By adding this timeout to 3s for bellow “api-gateway” virtual service, Jaeger trace will aviod long response time when a request call api-gateway, any response longer than 3s will reture http timeout, which add visibility to Jaeger UI to determine if the request successful or not.</p>

<figure class="highlight"><pre><code class="language-shell" data-lang="shell">apiVersion: networking.istio.io/v1alpha3
kind: VirtualService
metadata:
  name: api-gateway
spec:
  hosts:
  - api-gateway
  http:
  - route:
    - destination:
        host: api-gateway
        port:
          number: 80
    <span class="nb">timeout</span>: 3s <span class="c"># 3 seconds timeout add</span></code></pre></figure>

<p><b> Conclusion</b></p>

<p>In this session we deep dive into Istio add-on Jaeger for distributed tracing, which Jaeger facilitates, involves tracking requests as they flow through various services and components of an application. This helps identify bottlenecks, understand service dependencies, and improve overall performance.</p>

<p>In the next post I will see how to use Istio and Kiali to run some Canary Releases, Blue-Green deployment Rolling Updates and A/B Testing.</p>]]></content><author><name></name></author><category term="jekyll" /><category term="Cat2" /><summary type="html"><![CDATA[About Jaeger]]></summary></entry><entry><title type="html">Istio: Traffic Routing</title><link href="http://localhost:4000/jekyll/cat2/2024/05/22/istio.html" rel="alternate" type="text/html" title="Istio: Traffic Routing" /><published>2024-05-22T10:15:29+10:00</published><updated>2024-05-22T10:15:29+10:00</updated><id>http://localhost:4000/jekyll/cat2/2024/05/22/istio</id><content type="html" xml:base="http://localhost:4000/jekyll/cat2/2024/05/22/istio.html"><![CDATA[<p><b>Helm install istio </b></p>

<p>Here we use helm to install istio (istio-base, istiod, istia gateway), then deploy a sample online book store microservice “bookinfo”, practise istio tasks include Traffic Management, Observability, Security.</p>

<p>Bookinfo Topology:</p>

<p><img src="/assets/bookinfo.png" alt="image tooltip here" /></p>

<ul>
  <li>Helm install istio (istiod, istio-ingress)</li>
</ul>

<figure class="highlight"><pre><code class="language-shell" data-lang="shell">kubectl create namespace istio-system
helm pull istio/base
helm <span class="nb">install </span>istio-base <span class="nb">.</span> <span class="nt">-n</span> istio-system <span class="nt">--set</span> <span class="nv">defaultRevision</span><span class="o">=</span>default

helm pull istio/istiod
helm <span class="nb">install </span>istiod <span class="nb">.</span> <span class="nt">-n</span> istio-system 

kubectl create namespace istio-ingress
helm pull istio/gateway
helm <span class="nb">install </span>istio-ingress <span class="nb">.</span> <span class="nt">-n</span> istio-ingress

helm <span class="nb">ls</span> <span class="nt">-n</span> istio-system
NAME      	NAMESPACE   	REVISION	UPDATED                                	STATUS  	CHART        	APP VERSION
istio-base	istio-system	1       	2023-12-17 08:14:06.943276388 +0800 CST	deployed	base-1.20.1  	1.20.1     
istiod    	istio-system	1       	2023-12-17 08:15:40.370551503 +0800 CST	deployed	istiod-1.20.1	1.20.1 

helm <span class="nb">ls</span> <span class="nt">-n</span> istio-ingress
NAME         	NAMESPACE    	REVISION	UPDATED                                	STATUS  	CHART         	APP VERSION
istio-ingress	istio-ingress	1       	2023-12-17 08:25:07.111999373 +0800 CST	deployed	gateway-1.20.1	1.20.1</code></pre></figure>

<ul>
  <li>Deploy bookinfo microservice and istio ingressgateway and virtualservice</li>
</ul>

<figure class="highlight"><pre><code class="language-shell" data-lang="shell">kubectl label namespace istio-system istio-injection<span class="o">=</span>enabled

kubectl apply <span class="nt">-f</span> https://github.com/istio/istio/blob/master/samples/bookinfo/platform/kube/bookinfo.yaml <span class="nt">-oyaml</span> <span class="o">&gt;</span> bookinfo.yaml
kubectl apply <span class="nt">-f</span> bookinfo.yaml

kubectl get po
NAME                                                     READY   STATUS    RESTARTS       AGE
details-v1-698d88b-wmfcb                                 2/2     Running   0              21m
ratings-v1-6484c4d9bb-cb6gx                              2/2     Running   0              21m
reviews-v1-5b5d6494f4-jrsvc                              2/2     Running   0              21m
reviews-v2-5b667bcbf8-jgfzj                              2/2     Running   0              21m
reviews-v3-5b9bd44f4-tmmfz                               2/2     Running   0              21m

kubectl apply <span class="nt">-f</span> https://github.com/istio/istio/blob/master/samples/bookinfo/networking/bookinfo-gateway.yaml <span class="nt">-oyaml</span> <span class="o">&gt;</span> bookinfo-gateway.yaml
kubectl apply <span class="nt">-f</span> bookinfo-gateway.yaml</code></pre></figure>

<ul>
  <li>Deploy Kiali, jaeger, grafana, prometheus</li>
</ul>

<figure class="highlight"><pre><code class="language-shell" data-lang="shell">wget https://raw.githubusercontent.com/istio/istio/release-1.20/samples/addons/prometheus.yaml
wget https://raw.githubusercontent.com/istio/istio/release-1.20/samples/addons/jaeger.yaml
wget https://raw.githubusercontent.com/istio/istio/release-1.20/samples/addons/grafana.yaml
kubectl create <span class="nt">-f</span> prometheus.yaml <span class="nt">-f</span> jaeger.yaml <span class="nt">-f</span> grafana.yaml</code></pre></figure>

<ul>
  <li>
    <p>visit http://book.istio:31000/productpage, with review (v1, v2, v3)
<img src="/assets/kiali.png" alt="image tooltip here" /></p>
  </li>
  <li>
    <p>define destination rules and virtual service for reviews</p>
  </li>
</ul>

<figure class="highlight"><pre><code class="language-shell" data-lang="shell">wget https://raw.githubusercontent.com/istio/istio/master/samples/bookinfo/networking/destination-rule-all.yaml
wget https://raw.githubusercontent.com/istio/istio/master/samples/bookinfo/networking/virtual-service-reviews-90-10.yaml

kubectl create <span class="nt">-f</span> destination-rule-all.yaml <span class="nt">-f</span> virtual-service-reviews-90-10.yaml   <span class="c"># route v1 10% and v3 90%</span>
kubectl scale deployment reviews-v2 <span class="nt">-n</span> istio-system <span class="nt">--replicas</span><span class="o">=</span>0 <span class="c"># scale down v2 to 0</span>

kubectl get dr <span class="nt">-A</span>
NAMESPACE      NAME          HOST          AGE
istio-system   details       details       6m56s
istio-system   productpage   productpage   6m56s
istio-system   ratings       ratings       6m56s
istio-system   reviews       reviews       6m56s
kubectl get vs <span class="nt">-A</span>
NAMESPACE      NAME       GATEWAYS               HOSTS            AGE
istio-system   bookinfo   <span class="o">[</span><span class="s2">"bookinfo-gateway"</span><span class="o">]</span>   <span class="o">[</span><span class="s2">"book.istio"</span><span class="o">]</span>   19h
istio-system   reviews                           <span class="o">[</span><span class="s2">"reviews"</span><span class="o">]</span>      5m26s

Spec:
  Hosts:
    reviews
  Http:
    Route:
      Destination:
        Host:    reviews
        Subset:  v1
      Weight:    10
      Destination:
        Host:    reviews
        Subset:  v3
      Weight:    90</code></pre></figure>

<p>refresh bookinfo webpage, test Traffic route weight as bellow</p>

<p>90% traffic for reviews v3  vs  10% traffic for review v1</p>

<p><img src="/assets/1090.png" alt="image tooltip here" /></p>]]></content><author><name></name></author><category term="jekyll" /><category term="Cat2" /><summary type="html"><![CDATA[Helm install istio]]></summary></entry><entry><title type="html">Python Flask Microservice: K8S deployment</title><link href="http://localhost:4000/jekyll/cat2/2024/05/22/py-flask5.html" rel="alternate" type="text/html" title="Python Flask Microservice: K8S deployment" /><published>2024-05-22T00:17:29+10:00</published><updated>2024-05-22T00:17:29+10:00</updated><id>http://localhost:4000/jekyll/cat2/2024/05/22/py-flask5</id><content type="html" xml:base="http://localhost:4000/jekyll/cat2/2024/05/22/py-flask5.html"><![CDATA[<p><b> About K8S deployment</b></p>

<p>Now It is time to change from docker-compose to deploy into Kubernetes.  </p>

<p>As this is not new to me to deploy microservice into K8S, also I already have a running Kubernetes cluster in hand, so here I will just create docker images for the 3 services: API gateway, user and order, then push them into the docker hub repository, then create Kubernetes manifest for deployment and service.  </p>

<figure class="highlight"><pre><code class="language-shell" data-lang="shell"><span class="c"># Folder structure</span>
/07-with-k8s
<span class="nb">.</span>
├── api_gateway.py
├── depolyment.yaml
├── Dockerfile_apigateway
├── Dockerfile_order
├── Dockerfile_user
├── order_service.py
└── user_service.py

<span class="c"># Build, tag and push the docker images</span>
docker login

docker build <span class="nt">-t</span> zackz001/python-user:latest <span class="nt">-f</span> Dockerfile_user <span class="nb">.</span>
docker build <span class="nt">-t</span> zackz001/python-order:latest <span class="nt">-f</span> Dockerfile_order <span class="nb">.</span>
docker build <span class="nt">-t</span> zackz001/python-apigateway:latest <span class="nt">-f</span> Dockerfile_apigateway <span class="nb">.</span>
docker push zackz001/python-apigateway:latest
docker push zackz001/python-user:latest
docker push zackz001/python-order:latest

docker image <span class="nb">ls

</span>REPOSITORY                                      TAG       IMAGE ID       CREATED        SIZE
zackz001/python-apigateway                      latest    bc3db11f4be8   1 hours ago    138MB
zackz001/python-user                            latest    c93973bece33   1 hours ago    136MB
zackz001/python-order                           latest    e35d5de9254b   1 hours ago    136MB
prom/prometheus                                 latest    1bd2b9635267   8 days ago     271MB
grafana/grafana                                 latest    c42c21cd0ebc   3 weeks ago    453MB
consul                                          1.15.4    686495461132   4 months ago   155MB
docker.elastic.co/elasticsearch/elasticsearch   7.13.2    11a830014f7c   3 years ago    1.02GB
docker.elastic.co/logstash/logstash             7.13.2    8dc1af4dd662   3 years ago    965MB
docker.elastic.co/kibana/kibana                 7.13.2    6c4869a27be1   3 years ago    1.35GB

<span class="c"># k8s deployment Manifests</span>

apiVersion: apps/v1
kind: Deployment
metadata:
 name: user-service
spec:
 replicas: 1
 selector:
 matchLabels:
 app: user-service
 template:
 metadata:
 labels:
 app: user-service
 spec:
 containers:
 - name: user-service
 image: zackz001/python-user:latest
 ports:
 - containerPort: 5001

<span class="nt">---</span>
apiVersion: v1
kind: Service
metadata:
 name: user-service
spec:
 selector:
 app: user-service
 ports:
 - protocol: TCP
 port: 5001
 targetPort: 5001

<span class="nt">---</span>
apiVersion: apps/v1
kind: Deployment
metadata:
 name: order-service
spec:
 replicas: 1
 selector:
 matchLabels:
 app: order-service
 template:
 metadata:
 labels:
 app: order-service
 spec:
 containers:
 - name: order-service
 image: zackz001/python-order:latest
 ports:
 - containerPort: 5002

<span class="nt">---</span>
apiVersion: v1
kind: Service
metadata:
 name: order-service
spec:
 selector:
 app: order-service
 ports:
 - protocol: TCP
 port: 5002
 targetPort: 5002

<span class="nt">---</span>
apiVersion: apps/v1
kind: Deployment
metadata:
 name: api-gateway
spec:
 replicas: 1
 selector:
 matchLabels:
 app: api-gateway
 template:
 metadata:
 labels:
 app: api-gateway
 spec:
 containers:
 - name: api-gateway
 image: zackz001/python-apigateway:latest
 ports:
 - containerPort: 5000

<span class="nt">---</span>
apiVersion: v1
kind: Service
metadata:
 name: api-gateway
spec:
 <span class="nb">type</span>: NodePort
 selector:
 app: api-gateway
 ports:
 - protocol: TCP
 port: 5000
 targetPort: 5000</code></pre></figure>

<p>Now Run kubectl apply -f to bring all deployments and services up and running. Should see all services in the Rancher console.</p>

<figure class="highlight"><pre><code class="language-shell" data-lang="shell">kubectl create ns python

kubectl apply <span class="nt">-f</span> depolyment.yaml <span class="nt">-n</span> python

kubectl get all <span class="nt">-n</span> python

NAME                                 READY   STATUS    RESTARTS      AGE
pod/api-gateway-d664cf8c4-7l7q8      1/1     Running   2 <span class="o">(</span>50m ago<span class="o">)</span>   1h
pod/order-service-856577f666-gk5gt   1/1     Running   2 <span class="o">(</span>50m ago<span class="o">)</span>   1h
pod/user-service-5d8766d9cb-4rqnz    1/1     Running   2 <span class="o">(</span>50m ago<span class="o">)</span>   1h

NAME                    TYPE        CLUSTER-IP      EXTERNAL-IP   PORT<span class="o">(</span>S<span class="o">)</span>          AGE
service/api-gateway     NodePort    10.43.38.27     &lt;none&gt; 5000:32060/TCP   1h
service/order-service   ClusterIP   10.43.27.255    &lt;none&gt; 5002/TCP         1h
service/user-service    ClusterIP   10.43.160.232   &lt;none&gt; 5001/TCP         1h

NAME                            READY   UP-TO-DATE   AVAILABLE   AGE
deployment.apps/api-gateway     1/1     1            1           1h
deployment.apps/order-service   1/1     1            1           1h
deployment.apps/user-service    1/1     1            1           1h

NAME                                       DESIRED   CURRENT   READY   AGE
replicaset.apps/api-gateway-d664cf8c4      1         1         1       1h
replicaset.apps/order-service-856577f666   1         1         1       1h
replicaset.apps/user-service-5d8766d9cb    1         1         1       1h</code></pre></figure>

<p><b> Verify API gateway, user and order services</b></p>

<p>Access API gateway via http://NodeIP:NodePort/users and http://NodeIP:NodePort/orders</p>

<p><img src="/assets/flask11.png" alt="image tooltip here" /></p>

<p><img src="/assets/flask12.png" alt="image tooltip here" /></p>

<p><b> Conclusion</b></p>

<p>Now we complete all Python Flask sessions.</p>

<p>I have done this End-to-End Python Flask microservice application solution development, which enhanced my DevOps practices of Python programming, microservices architecture design and deployment with docker-compose, API Gateway implementation, service registery with Consul, logging and monitoring, and finally Kubernetes deployment.  </p>

<ul>
  <li>
    <p>simple Python Flask app</p>
  </li>
  <li>
    <p>Microservice applications with user and order</p>
  </li>
  <li>
    <p>Create API gateway Flask app</p>
  </li>
  <li>
    <p>Service registery with Consul</p>
  </li>
  <li>
    <p>Logging with ELK</p>
  </li>
  <li>
    <p>Monitoring with Prometheus and Grafana</p>
  </li>
  <li>
    <p>K8S deployment</p>
  </li>
</ul>]]></content><author><name></name></author><category term="jekyll" /><category term="Cat2" /><summary type="html"><![CDATA[About K8S deployment]]></summary></entry><entry><title type="html">Python Flask Microservice: Monitoring with Prometheus and Grafana</title><link href="http://localhost:4000/jekyll/cat2/2024/05/21/py-flask4.html" rel="alternate" type="text/html" title="Python Flask Microservice: Monitoring with Prometheus and Grafana" /><published>2024-05-21T00:17:29+10:00</published><updated>2024-05-21T00:17:29+10:00</updated><id>http://localhost:4000/jekyll/cat2/2024/05/21/py-flask4</id><content type="html" xml:base="http://localhost:4000/jekyll/cat2/2024/05/21/py-flask4.html"><![CDATA[<p><b> About Monitoring with Prometheus and Grafana</b></p>

<p>Both Prometheus and Grafana are compatible with microservice applications, integrating Prometheus with Flask is straightforward to provide performance and monitoring metrics.</p>

<p>Here I will update the docker-compose to add Prometheus and Grafana as services, then add Prometheus metrics in both order and user application code by importing <code class="language-plaintext highlighter-rouge">PrometheusMetrics</code> from the <code class="language-plaintext highlighter-rouge">prometheus_flask_exporter</code> module, which is used to expose Prometheus metrics for the Flask application. then initialize Prometheus metrics with <code class="language-plaintext highlighter-rouge">metrics = PrometheusMetrics(app)</code>. Use <code class="language-plaintext highlighter-rouge">@metrics.counter('get_orders_count', 'Count of calls to the get_orders endpoint')</code> to define a Prometheus counter metric that increments each time the get_orders endpoint is called.</p>

<p>Import <code class="language-plaintext highlighter-rouge">os</code> to enable environment variable for Logstash host, <code class="language-plaintext highlighter-rouge">logstash_host = os.getenv('LOGSTASH_HOST', 'localhost')</code> to fetche the Logstash host from environment variables, defaulting to localhost.</p>

<figure class="highlight"><pre><code class="language-shell" data-lang="shell"><span class="c"># Folder structure</span>
/06-with-monitoringstack
├── api_gateway
│   ├── api_gateway.py
│   └── Dockerfile
├── docker-compose.yml
├── logstash.conf
├── order_service
│   ├── Dockerfile
│   ├── order_service.py
├── prometheus.yaml
└── user_service
    ├── Dockerfile
    └── user_service.py

<span class="c"># add Prometheus and Grafana in docker-compose.yaml</span>
version: <span class="s1">'3'</span>
services:
  prometheus:
    image: prom/prometheus
    volumes:
      - ./prometheus.yml:/etc/prometheus/prometheus.yml
    ports:
      - <span class="s2">"9090:9090"</span>
  grafana:
    image: grafana/grafana
    ports:
      - <span class="s2">"3000:3000"</span>

<span class="c"># create prometheus.yml for Prometheus configration</span>
<span class="c"># vim prometheus.yml</span>
global:
  scrape_interval: 15s

scrape_configs:
  - job_name: <span class="s1">'flask'</span>
    static_configs:
      - targets: <span class="o">[</span><span class="s1">'user-service:5001'</span>, <span class="s1">'order-service:5002'</span><span class="o">]</span>

<span class="c"># add Monitoring logic into python code </span>

<span class="c"># order_service.py</span>
import logging
import requests
from flask import Flask, jsonify
from pygelf import GelfUdpHandler
from prometheus_flask_exporter import PrometheusMetrics
import os

app <span class="o">=</span> Flask<span class="o">(</span>__name__<span class="o">)</span>
metrics <span class="o">=</span> PrometheusMetrics<span class="o">(</span>app<span class="o">)</span>

@app.route<span class="o">(</span><span class="s1">'/orders'</span><span class="o">)</span>
def get_orders<span class="o">()</span>:
    orders <span class="o">=</span> <span class="o">[</span>
        <span class="o">{</span><span class="s1">'id'</span>: 1, <span class="s1">'item'</span>: <span class="s1">'Laptop'</span>, <span class="s1">'price'</span>: 1200<span class="o">}</span>,
        <span class="o">{</span><span class="s1">'id'</span>: 2, <span class="s1">'item'</span>: <span class="s1">'Phone'</span>, <span class="s1">'price'</span>: 800<span class="o">}</span>
    <span class="o">]</span>
    app.logger.info<span class="o">(</span><span class="s2">"Fetched order data"</span><span class="o">)</span>
    <span class="k">return </span>jsonify<span class="o">(</span>orders<span class="o">)</span>

def register_service<span class="o">()</span>:
    payload <span class="o">=</span> <span class="o">{</span>
        <span class="s2">"ID"</span>: <span class="s2">"order-service"</span>,
        <span class="s2">"Name"</span>: <span class="s2">"order-service"</span>,
        <span class="s2">"Address"</span>: <span class="s2">"order-service"</span>,
        <span class="s2">"Port"</span>: 5002
    <span class="o">}</span>
    response <span class="o">=</span> requests.put<span class="o">(</span><span class="s1">'http://consul:8500/v1/agent/service/register'</span>, <span class="nv">json</span><span class="o">=</span>payload<span class="o">)</span>
    <span class="k">if </span>response.status_code <span class="o">==</span> 200:
        app.logger.info<span class="o">(</span><span class="s2">"Order service registered successfully"</span><span class="o">)</span>
    <span class="k">else</span>:
        app.logger.error<span class="o">(</span><span class="s2">"Failed to register order service"</span><span class="o">)</span>

<span class="k">if </span>__name__ <span class="o">==</span> <span class="s1">'__main__'</span>:
    <span class="c"># Configure logging</span>
    logstash_host <span class="o">=</span> os.getenv<span class="o">(</span><span class="s1">'LOGSTASH_HOST'</span>, <span class="s1">'localhost'</span><span class="o">)</span>
    handler <span class="o">=</span> GelfUdpHandler<span class="o">(</span><span class="nv">host</span><span class="o">=</span>logstash_host, <span class="nv">port</span><span class="o">=</span>12201<span class="o">)</span>
    app.logger.addHandler<span class="o">(</span>handler<span class="o">)</span>
    app.logger.setLevel<span class="o">(</span>logging.INFO<span class="o">)</span>
    
    register_service<span class="o">()</span>
    app.run<span class="o">(</span><span class="nv">host</span><span class="o">=</span><span class="s1">'0.0.0.0'</span>, <span class="nv">port</span><span class="o">=</span>5002<span class="o">)</span>


<span class="c"># user_service.py</span>
import logging
import requests
from flask import Flask, jsonify
from pygelf import GelfUdpHandler
from prometheus_flask_exporter import PrometheusMetrics
import os

app <span class="o">=</span> Flask<span class="o">(</span>__name__<span class="o">)</span>
metrics <span class="o">=</span> PrometheusMetrics<span class="o">(</span>app<span class="o">)</span>

@app.route<span class="o">(</span><span class="s1">'/users'</span><span class="o">)</span>
def get_users<span class="o">()</span>:
    <span class="nb">users</span> <span class="o">=</span> <span class="o">[</span>
        <span class="o">{</span><span class="s1">'id'</span>: 1, <span class="s1">'name'</span>: <span class="s1">'Alice'</span><span class="o">}</span>,
        <span class="o">{</span><span class="s1">'id'</span>: 2, <span class="s1">'name'</span>: <span class="s1">'Bob'</span><span class="o">}</span>
    <span class="o">]</span>
    app.logger.info<span class="o">(</span><span class="s2">"Fetched user data"</span><span class="o">)</span>
    <span class="k">return </span>jsonify<span class="o">(</span><span class="nb">users</span><span class="o">)</span>

def register_service<span class="o">()</span>:
    payload <span class="o">=</span> <span class="o">{</span>
        <span class="s2">"ID"</span>: <span class="s2">"user-service"</span>,
        <span class="s2">"Name"</span>: <span class="s2">"user-service"</span>,
        <span class="s2">"Address"</span>: <span class="s2">"user-service"</span>,
        <span class="s2">"Port"</span>: 5001
    <span class="o">}</span>
    response <span class="o">=</span> requests.put<span class="o">(</span><span class="s1">'http://consul:8500/v1/agent/service/register'</span>, <span class="nv">json</span><span class="o">=</span>payload<span class="o">)</span>
    <span class="k">if </span>response.status_code <span class="o">==</span> 200:
        app.logger.info<span class="o">(</span><span class="s2">"User service registered successfully"</span><span class="o">)</span>
    <span class="k">else</span>:
        app.logger.error<span class="o">(</span><span class="s2">"Failed to register user service"</span><span class="o">)</span>

<span class="k">if </span>__name__ <span class="o">==</span> <span class="s1">'__main__'</span>:
    <span class="c"># Configure logging</span>
    logstash_host <span class="o">=</span> os.getenv<span class="o">(</span><span class="s1">'LOGSTASH_HOST'</span>, <span class="s1">'localhost'</span><span class="o">)</span>
    handler <span class="o">=</span> GelfUdpHandler<span class="o">(</span><span class="nv">host</span><span class="o">=</span>logstash_host, <span class="nv">port</span><span class="o">=</span>12201<span class="o">)</span>
    app.logger.addHandler<span class="o">(</span>handler<span class="o">)</span>
    app.logger.setLevel<span class="o">(</span>logging.INFO<span class="o">)</span>
    
    register_service<span class="o">()</span>
    app.run<span class="o">(</span><span class="nv">host</span><span class="o">=</span><span class="s1">'0.0.0.0'</span>, <span class="nv">port</span><span class="o">=</span>5001<span class="o">)</span></code></pre></figure>

<p>Now Run docker-compose to bring all containers up and running. Should see all services with Prometheus and Grafana.</p>

<figure class="highlight"><pre><code class="language-shell" data-lang="shell">docker-compose up <span class="nt">--build</span>

Creating 06-with-monitoringstack_api-gateway_1   ... <span class="k">done
</span>Creating 06-with-monitoringstack_order-service_1 ... <span class="k">done
</span>Creating 06-with-monitoringstack_user-service_1  ... <span class="k">done
</span>Creating 06-with-monitoringstack_kibana_1        ... <span class="k">done
</span>Creating 06-with-monitoringstack_grafana_1       ... <span class="k">done
</span>Creating 06-with-monitoringstack_logstash_1      ... <span class="k">done
</span>Creating 06-with-monitoringstack_prometheus_1    ... <span class="k">done
</span>Creating 06-with-monitoringstack_elasticsearch_1 ... <span class="k">done
</span>Creating 06-with-monitoringstack_consul_1        ... <span class="k">done</span></code></pre></figure>

<p><b> Verify Prometheus and Grafana</b></p>

<p>Access Grafana via http://localhost:3000, log in with admin/admin.</p>

<p>Add Prometheus as a Data Source in Grafana by setting the URL to http://localhost:9090 and save.</p>

<p>Create Dashboards in Grafana to use the Prometheus data source to visualize metrics from user-service and order-service.</p>

<p><img src="/assets/flask10.png" alt="image tooltip here" /></p>

<p><img src="/assets/flask9.png" alt="image tooltip here" /></p>

<p><b> Conclusion</b></p>

<p>Now we can enable monitoring with Prometheus and Grafana.</p>

<p>In the next post, I will see how to depoly our Python Flask microservice into Kubernetes.</p>]]></content><author><name></name></author><category term="jekyll" /><category term="Cat2" /><summary type="html"><![CDATA[About Monitoring with Prometheus and Grafana]]></summary></entry><entry><title type="html">Python Flask Microservice: Logging with ELK</title><link href="http://localhost:4000/jekyll/cat2/2024/05/20/py-flask3.html" rel="alternate" type="text/html" title="Python Flask Microservice: Logging with ELK" /><published>2024-05-20T00:16:29+10:00</published><updated>2024-05-20T00:16:29+10:00</updated><id>http://localhost:4000/jekyll/cat2/2024/05/20/py-flask3</id><content type="html" xml:base="http://localhost:4000/jekyll/cat2/2024/05/20/py-flask3.html"><![CDATA[<p><b> About logging with ELK (Elasticsearch, Logstash, Kibana) Stack</b></p>

<p>ELK (Elasticsearch, Logstash, Kibana) is a popular log management solution. We will use the ELK Stack to collect and analyze logs.</p>

<p>Here I need to extend the current configuration by adding services in docker-compose file for <code class="language-plaintext highlighter-rouge">Elasticsearch</code>, <code class="language-plaintext highlighter-rouge">Logstash</code>, and <code class="language-plaintext highlighter-rouge">Kibana</code>, and configure the microservices to send logs to Logstash.</p>

<p>Also, I will need to configure the logging in both <code class="language-plaintext highlighter-rouge">user</code> and <code class="language-plaintext highlighter-rouge">order</code> Python application code to send logs to Logstash. By importing the built-in <code class="language-plaintext highlighter-rouge">logging</code> module and  <code class="language-plaintext highlighter-rouge">GelfUdpHandler</code> from the <code class="language-plaintext highlighter-rouge">pygelf</code> module, to provide a flexible framework for emitting log messages from Python programs to send log messages in the <code class="language-plaintext highlighter-rouge">GELF</code> (Graylog Extended Log Format) to a remote Graylog server, which is typically part of the ELK stack.</p>

<p>By adding log messages using <code class="language-plaintext highlighter-rouge">app.logger.info</code> and <code class="language-plaintext highlighter-rouge">app.logger.error</code>, together with the defined the logging level, I can set the logging level to <code class="language-plaintext highlighter-rouge">INFO</code>, which means all log messages at this level or higher will be emitted.</p>

<figure class="highlight"><pre><code class="language-shell" data-lang="shell"><span class="c"># folder structure </span>
05-with-ELK/
├── api_gateway/
│   └── Dockerfile
├── order_service/
│   └── Dockerfile
├── user_service/
│   └── Dockerfile
├── logstash.conf
└── docker-compose.yml

<span class="c"># create Logstash Configuration</span>
<span class="c"># vim logstash.conf</span>
input <span class="o">{</span>
 gelf <span class="o">{</span>
 port <span class="o">=&gt;</span> 12201
 <span class="o">}</span>
<span class="o">}</span>
output <span class="o">{</span>
 elasticsearch <span class="o">{</span>
 hosts <span class="o">=&gt;</span> <span class="o">[</span><span class="s2">"elasticsearch:9200"</span><span class="o">]</span>
 index <span class="o">=&gt;</span> <span class="s2">"%{[@metadata][beat]}-%{+YYYY.MM.dd}"</span>
 <span class="o">}</span>
<span class="o">}</span>
<span class="c"># vim user_service.py</span>

import logging
import requests
from flask import Flask, jsonify
from pygelf import GelfUdpHandler

app <span class="o">=</span> Flask<span class="o">(</span>__name__<span class="o">)</span>

@app.route<span class="o">(</span><span class="s1">'/users'</span><span class="o">)</span>
def get_users<span class="o">()</span>:
 <span class="nb">users</span> <span class="o">=</span> <span class="o">[</span>
 <span class="o">{</span><span class="s1">'id'</span>: 1, <span class="s1">'name'</span>: <span class="s1">'Alice'</span><span class="o">}</span>,
 <span class="o">{</span><span class="s1">'id'</span>: 2, <span class="s1">'name'</span>: <span class="s1">'Bob'</span><span class="o">}</span>
 <span class="o">]</span>
 app.logger.info<span class="o">(</span><span class="s2">"Fetched user data"</span><span class="o">)</span>
 <span class="k">return </span>jsonify<span class="o">(</span><span class="nb">users</span><span class="o">)</span>

def register_service<span class="o">()</span>:
 payload <span class="o">=</span> <span class="o">{</span>
 <span class="s2">"ID"</span>: <span class="s2">"user-service"</span>,
 <span class="s2">"Name"</span>: <span class="s2">"user-service"</span>,
 <span class="s2">"Address"</span>: <span class="s2">"user-service"</span>,
 <span class="s2">"Port"</span>: 5001
 <span class="o">}</span>
 response <span class="o">=</span> requests.put<span class="o">(</span><span class="s1">'http://consul:8500/v1/agent/service/register'</span>, <span class="nv">json</span><span class="o">=</span>payload<span class="o">)</span>
 <span class="k">if </span>response.status_code <span class="o">==</span> 200:
 app.logger.info<span class="o">(</span><span class="s2">"User service registered successfully"</span><span class="o">)</span>
 <span class="k">else</span>:
 app.logger.error<span class="o">(</span><span class="s2">"Failed to register user service"</span><span class="o">)</span>

<span class="k">if </span>__name__ <span class="o">==</span> <span class="s1">'__main__'</span>:
 <span class="c"># Configure logging</span>
 handler <span class="o">=</span> GelfUdpHandler<span class="o">(</span><span class="nv">host</span><span class="o">=</span><span class="s1">'logstash'</span>, <span class="nv">port</span><span class="o">=</span>12201<span class="o">)</span>
 app.logger.addHandler<span class="o">(</span>handler<span class="o">)</span>
 app.logger.setLevel<span class="o">(</span>logging.INFO<span class="o">)</span>
    
 register_service<span class="o">()</span>
 app.run<span class="o">(</span><span class="nv">host</span><span class="o">=</span><span class="s1">'0.0.0.0'</span>, <span class="nv">port</span><span class="o">=</span>5001<span class="o">)</span>

<span class="c"># vim order_service.py</span>

import logging
import requests
from flask import Flask, jsonify
from pygelf import GelfUdpHandler

app <span class="o">=</span> Flask<span class="o">(</span>__name__<span class="o">)</span>

@app.route<span class="o">(</span><span class="s1">'/orders'</span><span class="o">)</span>
def get_orders<span class="o">()</span>:
 orders <span class="o">=</span> <span class="o">[</span>
 <span class="o">{</span><span class="s1">'id'</span>: 1, <span class="s1">'item'</span>: <span class="s1">'Laptop'</span>, <span class="s1">'price'</span>: 1200<span class="o">}</span>,
 <span class="o">{</span><span class="s1">'id'</span>: 2, <span class="s1">'item'</span>: <span class="s1">'Phone'</span>, <span class="s1">'price'</span>: 800<span class="o">}</span>
 <span class="o">]</span>
 app.logger.info<span class="o">(</span><span class="s2">"Fetched order data"</span><span class="o">)</span>
 <span class="k">return </span>jsonify<span class="o">(</span>orders<span class="o">)</span>

def register_service<span class="o">()</span>:
 payload <span class="o">=</span> <span class="o">{</span>
 <span class="s2">"ID"</span>: <span class="s2">"order-service"</span>,
 <span class="s2">"Name"</span>: <span class="s2">"order-service"</span>,
 <span class="s2">"Address"</span>: <span class="s2">"order-service"</span>,
 <span class="s2">"Port"</span>: 5002
 <span class="o">}</span>
 response <span class="o">=</span> requests.put<span class="o">(</span><span class="s1">'http://consul:8500/v1/agent/service/register'</span>, <span class="nv">json</span><span class="o">=</span>payload<span class="o">)</span>
 <span class="k">if </span>response.status_code <span class="o">==</span> 200:
 app.logger.info<span class="o">(</span><span class="s2">"Order service registered successfully"</span><span class="o">)</span>
 <span class="k">else</span>:
 app.logger.error<span class="o">(</span><span class="s2">"Failed to register order service"</span><span class="o">)</span>

<span class="k">if </span>__name__ <span class="o">==</span> <span class="s1">'__main__'</span>:
 <span class="c"># Configure logging</span>
 handler <span class="o">=</span> GelfUdpHandler<span class="o">(</span><span class="nv">host</span><span class="o">=</span><span class="s1">'logstash'</span>, <span class="nv">port</span><span class="o">=</span>12201<span class="o">)</span>
 app.logger.addHandler<span class="o">(</span>handler<span class="o">)</span>
 app.logger.setLevel<span class="o">(</span>logging.INFO<span class="o">)</span>
    
 register_service<span class="o">()</span>
 app.run<span class="o">(</span><span class="nv">host</span><span class="o">=</span><span class="s1">'0.0.0.0'</span>, <span class="nv">port</span><span class="o">=</span>5002<span class="o">)</span>


<span class="c"># create user_service/requirements.txt for each service (user, order)</span>
flask
requests
pygelf

<span class="c"># modify each Dockerfile: Dockerfile-user</span>

<span class="c"># Use an official Python runtime as a parent image</span>
FROM python:3.9-slim

<span class="c"># Set the working directory in the container</span>
WORKDIR /app

<span class="c"># Copy the current directory contents into the container at /app</span>
COPY <span class="nb">.</span> /app

<span class="c"># Install any needed packages specified in requirements.txt</span>
RUN pip <span class="nb">install</span> <span class="nt">--no-cache-dir</span> <span class="nt">-r</span> requirements.txt

<span class="c"># Make port 5001 available to the world outside this container</span>
EXPOSE 5001

<span class="c"># Define environment variable</span>
ENV <span class="nv">FLASK_APP</span><span class="o">=</span>user_service.py

<span class="c"># Run user_service.py when the container launches</span>
CMD <span class="o">[</span><span class="s2">"flask"</span>, <span class="s2">"run"</span>, <span class="s2">"--host=0.0.0.0"</span>, <span class="s2">"--port=5001"</span><span class="o">]</span>


<span class="c"># vim Dockerfile-order</span>

<span class="c"># Use an official Python runtime as a parent image</span>
FROM python:3.9-slim

<span class="c"># Set the working directory in the container</span>
WORKDIR /app

<span class="c"># Copy the current directory contents into the container at /app</span>
COPY <span class="nb">.</span> /app

<span class="c"># Install any needed packages specified in requirements.txt</span>
RUN pip <span class="nb">install</span> <span class="nt">--no-cache-dir</span> <span class="nt">-r</span> requirements.txt

<span class="c"># Make port 5002 available to the world outside this container</span>
EXPOSE 5002

<span class="c"># Define environment variable</span>
ENV <span class="nv">FLASK_APP</span><span class="o">=</span>order_service.py

<span class="c"># Run order_service.py when the container launches</span>
CMD <span class="o">[</span><span class="s2">"flask"</span>, <span class="s2">"run"</span>, <span class="s2">"--host=0.0.0.0"</span>, <span class="s2">"--port=5002"</span><span class="o">]</span>

<span class="c"># modify docker-compose.yaml</span>

version: <span class="s1">'3'</span>
services:
 consul:
 image: consul:1.15.4
 ports:
 - <span class="s2">"8500:8500"</span>

 elasticsearch:
 image: docker.elastic.co/elasticsearch/elasticsearch:7.13.2
 environment:
 - discovery.type<span class="o">=</span>single-node
 ports:
 - <span class="s2">"9200:9200"</span>
 - <span class="s2">"9300:9300"</span>
 volumes:
 - esdata:/usr/share/elasticsearch/data

 logstash:
 image: docker.elastic.co/logstash/logstash:7.13.2
 volumes:
 - ./logstash.conf:/usr/share/logstash/pipeline/logstash.conf
 ports:
 - <span class="s2">"12201:12201/udp"</span>
 - <span class="s2">"5044:5044"</span>

 kibana:
 image: docker.elastic.co/kibana/kibana:7.13.2
 ports:
 - <span class="s2">"5601:5601"</span>
 depends_on:
 - elasticsearch

 user-service:
 build:
 context: ./user_service
 depends_on:
 - consul
 - logstash
 environment:
 - <span class="nv">CONSUL_HTTP_ADDR</span><span class="o">=</span>consul:8500
 ports:
 - <span class="s2">"5001:5001"</span>
 logging:
 driver: gelf
 options:
 gelf-address: udp://logstash:12201

 order-service:
 build:
 context: ./order_service
 depends_on:
 - consul
 - logstash
 environment:
 - <span class="nv">CONSUL_HTTP_ADDR</span><span class="o">=</span>consul:8500
 ports:
 - <span class="s2">"5002:5002"</span>
 logging:
 driver: gelf
 options:
 gelf-address: udp://logstash:12201

 api-gateway:
 build:
 context: ./api_gateway
 depends_on:
 - consul
 - user-service
 - order-service
 - logstash
 environment:
 - <span class="nv">CONSUL_HTTP_ADDR</span><span class="o">=</span>consul:8500
 ports:
 - <span class="s2">"5000:5000"</span>
 logging:
 driver: gelf
 options:
 gelf-address: udp://logstash:12201

volumes:
 esdata:</code></pre></figure>

<p>Now Run docker-compose to bring all containers up and running. Should see all services with ES, Logstash and Kibana populating logs on the screen.</p>

<figure class="highlight"><pre><code class="language-shell" data-lang="shell">docker-compose up <span class="nt">--build</span>

Creating 05-with-elk_logstash_1      ... <span class="k">done
</span>Creating 05-with-elk_consul_1        ... <span class="k">done
</span>Creating 05-with-elk_elasticsearch_1 ... <span class="k">done
</span>Creating 05-with-elk_kibana_1        ... <span class="k">done
</span>Creating 05-with-elk_user-service_1  ... <span class="k">done
</span>Creating 05-with-elk_order-service_1 ... <span class="k">done
</span>Creating 05-with-elk_api-gateway_1   ... <span class="k">done


</span>logstash_1       | <span class="o">[</span>2024-05-18T14:55:13,140][INFO <span class="o">][</span>logstash.inputs.udp      ][main][a30d8db137f99f1de18acbd53c081374cd720430a4dd0e752ff4a99c3005f9d0] Starting UDP listener <span class="o">{</span>:address<span class="o">=&gt;</span><span class="s2">"0.0.0.0:12201"</span><span class="o">}</span>
logstash_1       | <span class="o">[</span>2024-05-18T14:55:13,187][INFO <span class="o">][</span>logstash.inputs.udp      ][main][a30d8db137f99f1de18acbd53c081374cd720430a4dd0e752ff4a99c3005f9d0] UDP listener started <span class="o">{</span>:address<span class="o">=&gt;</span><span class="s2">"0.0.0.0:12201"</span>, :receive_buffer_bytes<span class="o">=&gt;</span><span class="s2">"106496"</span>, :queue_size<span class="o">=&gt;</span><span class="s2">"2000"</span><span class="o">}</span>
consul_1         | 2024-05-18T14:55:46.686Z <span class="o">[</span>DEBUG] agent: Skipping remote check since it is managed automatically: <span class="nv">check</span><span class="o">=</span>serfHealth
consul_1         | 2024-05-18T14:55:46.688Z <span class="o">[</span>DEBUG] agent: Node info <span class="k">in </span><span class="nb">sync
</span>logstash_1       | https://www.elastic.co/guide/en/logstash/current/monitoring-with-metricbeat.html
elasticsearch_1  | <span class="o">{</span><span class="s2">"type"</span>: <span class="s2">"deprecation.elasticsearch"</span>, <span class="s2">"timestamp"</span>: <span class="s2">"2024-05-18T14:55:09,016Z"</span>, <span class="s2">"level"</span>: <span class="s2">"DEPRECATION"</span>, <span class="s2">"component"</span>: <span class="s2">"o.e.d.r.RestController"</span>, <span class="s2">"cluster.name"</span>: <span class="s2">"docker-cluster"</span>, <span class="s2">"node.name"</span>: <span class="s2">"430bff78a529"</span>, <span class="s2">"message"</span>: <span class="s2">"Legacy index templates are deprecated in favor of composable templates."</span>, <span class="s2">"cluster.uuid"</span>: <span class="s2">"B9QKhgEGTA6Ot5auY9skQQ"</span>, <span class="s2">"node.id"</span>: <span class="s2">"QzKPL7DYSB2_CeWJpUaxXg"</span>  <span class="o">}</span>
kibana_1         | <span class="o">{</span><span class="s2">"type"</span>:<span class="s2">"log"</span>,<span class="s2">"@timestamp"</span>:<span class="s2">"2024-05-18T14:55:09+00:00"</span>,<span class="s2">"tags"</span>:[<span class="s2">"info"</span>,<span class="s2">"plugins"</span>,<span class="s2">"monitoring"</span>,<span class="s2">"monitoring"</span>,<span class="s2">"kibana-monitoring"</span><span class="o">]</span>,<span class="s2">"pid"</span>:952,<span class="s2">"message"</span>:<span class="s2">"Starting monitoring stats collection"</span><span class="o">}</span></code></pre></figure>

<p><img src="/assets/flask6.png" alt="image tooltip here" /></p>

<p><b> Verify ElasticSearch and Kibana</b></p>

<ul>
  <li>Validate ElasticSearch status via localhost:9200</li>
</ul>

<p><img src="/assets/flask7.png" alt="image tooltip here" /></p>

<ul>
  <li>Visit localhost:5601 to access Kibana dashboard, add Index Pattern “logs-*” to see data populated in the Discover tab</li>
</ul>

<p><img src="/assets/flask8.png" alt="image tooltip here" />
<b> Conclusion</b></p>

<p>Now we can enable logging with ELK stack, and use Logstash, ElasticSearch and Kibana.</p>

<p>In the next post, I will see how to enable monitoring with Prometheus and Grafana stack.</p>]]></content><author><name></name></author><category term="jekyll" /><category term="Cat2" /><summary type="html"><![CDATA[About logging with ELK (Elasticsearch, Logstash, Kibana) Stack]]></summary></entry><entry><title type="html">Python Flask Microservice: API Gateway &amp;amp; Consul</title><link href="http://localhost:4000/jekyll/cat2/2024/05/19/py-flask2.html" rel="alternate" type="text/html" title="Python Flask Microservice: API Gateway &amp;amp; Consul" /><published>2024-05-19T10:15:29+10:00</published><updated>2024-05-19T10:15:29+10:00</updated><id>http://localhost:4000/jekyll/cat2/2024/05/19/py-flask2</id><content type="html" xml:base="http://localhost:4000/jekyll/cat2/2024/05/19/py-flask2.html"><![CDATA[<p><b> About API Gateway</b></p>

<p>API Gateway acts as a single entry point for all clients and handles the request routing, composition, and protocol translation in a microservices architecture, here I will create a API Gateway using Python Flask and requests library, to route both “user” and “order” services.</p>

<p>Here I will create an API Gateway to handle the 2 services (user and order). By importing the <code class="language-plaintext highlighter-rouge">requests</code> module, which allows us to send HTTP requests in Python. It’s used for making API calls to other services.</p>

<p>Then with <code class="language-plaintext highlighter-rouge">route</code> decorator to specify that the <code class="language-plaintext highlighter-rouge">get_users</code> function should handle requests to the <code class="language-plaintext highlighter-rouge">/users</code> URL endpoint.</p>

<p>Then define <code class="language-plaintext highlighter-rouge">response</code> to send GET request to the user-service and order-service running on port 5001/5002 at each endpoint.</p>

<figure class="highlight"><pre><code class="language-shell" data-lang="shell"><span class="c"># Folder Structure</span>
03-with-api-gatway/
├── user_service/
│   ├── Dockerfile
│   └── user_service.py
├── order_service/
│   ├── Dockerfile
│   └── order_service.py
├── api_gateway/
│   ├── Dockerfile
│   └── api_gateway.py
├── docker-compose.yml

<span class="c"># api_gateway.py</span>
from flask import Flask, jsonify
import requests

app <span class="o">=</span> Flask<span class="o">(</span>__name__<span class="o">)</span>

@app.route<span class="o">(</span><span class="s1">'/users'</span><span class="o">)</span>
def get_users<span class="o">()</span>:
 response <span class="o">=</span> requests.get<span class="o">(</span><span class="s1">'http://user-service:5001/users'</span><span class="o">)</span>
 <span class="k">return </span>jsonify<span class="o">(</span>response.json<span class="o">())</span>

@app.route<span class="o">(</span><span class="s1">'/orders'</span><span class="o">)</span>
def get_orders<span class="o">()</span>:
 response <span class="o">=</span> requests.get<span class="o">(</span><span class="s1">'http://order-service:5002/orders'</span><span class="o">)</span>
 <span class="k">return </span>jsonify<span class="o">(</span>response.json<span class="o">())</span>

<span class="k">if </span>__name__ <span class="o">==</span> <span class="s1">'__main__'</span>:
 app.run<span class="o">(</span><span class="nv">host</span><span class="o">=</span><span class="s1">'0.0.0.0'</span>, <span class="nv">port</span><span class="o">=</span>5000<span class="o">)</span>

<span class="c"># Dockerfile_apigateway</span>

<span class="c"># Use an official Python runtime as a parent image</span>
FROM python:3.9-slim

<span class="c"># Set the working directory in the container</span>
WORKDIR /app

<span class="c"># Copy the current directory contents into the container at /app</span>
COPY <span class="nb">.</span> /app

<span class="c"># Install flask requests</span>
RUN pip <span class="nb">install</span> <span class="nt">--no-cache-dir</span> flask requests

<span class="c"># Make port 5000 available to the world outside this container</span>
EXPOSE 5000

<span class="c"># Define environment variable</span>
ENV <span class="nv">FLASK_APP</span><span class="o">=</span>api_gateway.py

<span class="c"># Run api_gateway.py when the container launches</span>
CMD <span class="o">[</span><span class="s2">"flask"</span>, <span class="s2">"run"</span>, <span class="s2">"--host=0.0.0.0"</span>, <span class="s2">"--port=5000"</span><span class="o">]</span>

<span class="c"># update docker-compose.yaml</span>

.....

 api-gateway:
 build:
 context: <span class="nb">.</span>
 dockerfile: Dockerfile_apigateway
 ports:
 - <span class="s2">"5000:5000"</span>

<span class="c"># run docker-compose up --build</span>

docker-compose up <span class="nt">--build</span></code></pre></figure>

<p>Verify the 2 services can be accessed via API Gateway address and port plus /users and /orders by defining request functions.</p>

<p><img src="/assets/flask4.png" alt="image tooltip here" />
<img src="/assets/flask5.png" alt="image tooltip here" /></p>

<p><b> About Consul</b></p>

<p>Consul is a popular open-source tool for service discovery and service registration, here I will update the py files to register both services with Consul</p>

<p>In both user_service.py and order_service.py, add service registration logic.</p>

<p>To import <code class="language-plaintext highlighter-rouge">time</code> module, also define function named <code class="language-plaintext highlighter-rouge">register_service</code> that will handle the service registration logic with Consul, use dictionary defines the <code class="language-plaintext highlighter-rouge">payload</code> for the service registration. It includes the service ID, name, address, and port.</p>

<p>I will use <code class="language-plaintext highlighter-rouge">while True</code> to start an infinite loop, which will keep trying to register the service with Consul until it succeeds, add <code class="language-plaintext highlighter-rouge">try</code>, <code class="language-plaintext highlighter-rouge">else</code>and <code class="language-plaintext highlighter-rouge">if</code> to handle exceptions during the registration process.</p>

<figure class="highlight"><pre><code class="language-shell" data-lang="shell"><span class="c"># vim order_service.py</span>
import requests
from flask import Flask, jsonify
import <span class="nb">time

</span>app <span class="o">=</span> Flask<span class="o">(</span>__name__<span class="o">)</span>

@app.route<span class="o">(</span><span class="s1">'/orders'</span><span class="o">)</span>
def get_orders<span class="o">()</span>:
 orders <span class="o">=</span> <span class="o">[</span>
 <span class="o">{</span><span class="s1">'id'</span>: 1, <span class="s1">'item'</span>: <span class="s1">'Laptop'</span>, <span class="s1">'price'</span>: 1200<span class="o">}</span>,
 <span class="o">{</span><span class="s1">'id'</span>: 2, <span class="s1">'item'</span>: <span class="s1">'Phone'</span>, <span class="s1">'price'</span>: 800<span class="o">}</span>
 <span class="o">]</span>
 <span class="k">return </span>jsonify<span class="o">(</span>orders<span class="o">)</span>

def register_service<span class="o">()</span>:
 payload <span class="o">=</span> <span class="o">{</span>
 <span class="s2">"ID"</span>: <span class="s2">"order-service"</span>,
 <span class="s2">"Name"</span>: <span class="s2">"order-service"</span>,
 <span class="s2">"Address"</span>: <span class="s2">"order-service"</span>,
 <span class="s2">"Port"</span>: 5002
 <span class="o">}</span>
 <span class="k">while </span>True:
 try:
 response <span class="o">=</span> requests.put<span class="o">(</span><span class="s1">'http://consul:8500/v1/agent/service/register'</span>, <span class="nv">json</span><span class="o">=</span>payload<span class="o">)</span>
 <span class="k">if </span>response.status_code <span class="o">==</span> 200:
 print<span class="o">(</span><span class="s2">"Successfully registered order-service with Consul"</span><span class="o">)</span>
 <span class="nb">break
 </span><span class="k">else</span>:
 print<span class="o">(</span>f<span class="s2">"Failed to register order-service with Consul, status code: {response.status_code}"</span><span class="o">)</span>
 except requests.exceptions.RequestException as e:
 print<span class="o">(</span>f<span class="s2">"Error registering order-service with Consul: {e}"</span><span class="o">)</span>
 time.sleep<span class="o">(</span>5<span class="o">)</span>

<span class="k">if </span>__name__ <span class="o">==</span> <span class="s1">'__main__'</span>:
 print<span class="o">(</span><span class="s2">"Registering order-service with Consul"</span><span class="o">)</span>
 register_service<span class="o">()</span>
 app.run<span class="o">(</span><span class="nv">host</span><span class="o">=</span><span class="s1">'0.0.0.0'</span>, <span class="nv">port</span><span class="o">=</span>5002<span class="o">)</span>


<span class="c"># vim user_service.py</span>
import requests
from flask import Flask, jsonify
import <span class="nb">time

</span>app <span class="o">=</span> Flask<span class="o">(</span>__name__<span class="o">)</span>

@app.route<span class="o">(</span><span class="s1">'/users'</span><span class="o">)</span>
def get_users<span class="o">()</span>:
 <span class="nb">users</span> <span class="o">=</span> <span class="o">[</span>
 <span class="o">{</span><span class="s1">'id'</span>: 1, <span class="s1">'name'</span>: <span class="s1">'Alice'</span><span class="o">}</span>,
 <span class="o">{</span><span class="s1">'id'</span>: 2, <span class="s1">'name'</span>: <span class="s1">'Bob'</span><span class="o">}</span>
 <span class="o">]</span>
 <span class="k">return </span>jsonify<span class="o">(</span><span class="nb">users</span><span class="o">)</span>

def register_service<span class="o">()</span>:
 payload <span class="o">=</span> <span class="o">{</span>
 <span class="s2">"ID"</span>: <span class="s2">"user-service"</span>,
 <span class="s2">"Name"</span>: <span class="s2">"user-service"</span>,
 <span class="s2">"Address"</span>: <span class="s2">"user-service"</span>,
 <span class="s2">"Port"</span>: 5001
 <span class="o">}</span>
 <span class="k">while </span>True:
 try:
 response <span class="o">=</span> requests.put<span class="o">(</span><span class="s1">'http://consul:8500/v1/agent/service/register'</span>, <span class="nv">json</span><span class="o">=</span>payload<span class="o">)</span>
 <span class="k">if </span>response.status_code <span class="o">==</span> 200:
 print<span class="o">(</span><span class="s2">"Successfully registered user-service with Consul"</span><span class="o">)</span>
 <span class="nb">break
 </span><span class="k">else</span>:
 print<span class="o">(</span>f<span class="s2">"Failed to register user-service with Consul, status code: {response.status_code}"</span><span class="o">)</span>
 except requests.exceptions.RequestException as e:
 print<span class="o">(</span>f<span class="s2">"Error registering user-service with Consul: {e}"</span><span class="o">)</span>
 time.sleep<span class="o">(</span>5<span class="o">)</span>

<span class="k">if </span>__name__ <span class="o">==</span> <span class="s1">'__main__'</span>:
 print<span class="o">(</span><span class="s2">"Registering user-service with Consul"</span><span class="o">)</span>
 register_service<span class="o">()</span>
 app.run<span class="o">(</span><span class="nv">host</span><span class="o">=</span><span class="s1">'0.0.0.0'</span>, <span class="nv">port</span><span class="o">=</span>5001<span class="o">)</span>

<span class="c"># update docker-compose.yaml</span>

version: <span class="s1">'3'</span>
services:
 consul:
 image: consul:1.15.4
 ports:
 - <span class="s2">"8500:8500"</span>

 user-service:
 build:
 context: ./user_service
 depends_on:
 - consul
 environment:
 - <span class="nv">CONSUL_HTTP_ADDR</span><span class="o">=</span>consul:8500
 ports:
 - <span class="s2">"5001:5001"</span>

 order-service:
 build:
 context: ./order_service
 depends_on:
 - consul
 environment:
 - <span class="nv">CONSUL_HTTP_ADDR</span><span class="o">=</span>consul:8500
 ports:
 - <span class="s2">"5002:5002"</span>

 api-gateway:
 build:
 context: ./api_gateway
 depends_on:
 - consul
 - user-service
 - order-service
 environment:
 - <span class="nv">CONSUL_HTTP_ADDR</span><span class="o">=</span>consul:8500
 ports:
 - <span class="s2">"5000:5000"</span></code></pre></figure>

<p>Now run the docker-compose and verify in Consul via localhost:</p>

<figure class="highlight"><pre><code class="language-shell" data-lang="shell">docker-compose up <span class="nt">--build</span>

Creating 04-with-consul_consul_1 ... <span class="k">done
</span>Creating 04-with-consul_user-service_1  ... <span class="k">done
</span>Creating 04-with-consul_order-service_1 ... <span class="k">done
</span>Creating 04-with-consul_api-gateway_1   ... <span class="k">done

</span>consul_1         | 2024-05-18T14:28:45.465Z <span class="o">[</span>DEBUG] agent: Node info <span class="k">in </span><span class="nb">sync
</span>consul_1         | 2024-05-18T14:28:45.465Z <span class="o">[</span>DEBUG] agent: Service <span class="k">in </span><span class="nb">sync</span>: <span class="nv">service</span><span class="o">=</span>order-service
consul_1         | 2024-05-18T14:28:45.465Z <span class="o">[</span>DEBUG] agent: Service <span class="k">in </span><span class="nb">sync</span>: <span class="nv">service</span><span class="o">=</span>user-service</code></pre></figure>

<p><img src="/assets/flask6.png" alt="image tooltip here" /></p>

<p><b> Conclusion</b></p>

<p>Now we can use API gateway and Consul to manage route and service discovery.</p>

<p>In the next post, I will see how to enable logging with ELK stack and monitoring with Prometheus and Grafana stack.</p>]]></content><author><name></name></author><category term="jekyll" /><category term="Cat2" /><summary type="html"><![CDATA[About API Gateway]]></summary></entry></feed>