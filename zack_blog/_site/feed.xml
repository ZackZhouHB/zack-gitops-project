<?xml version="1.0" encoding="utf-8"?><feed xmlns="http://www.w3.org/2005/Atom" ><generator uri="https://jekyllrb.com/" version="4.3.2">Jekyll</generator><link href="http://localhost:4000/feed.xml" rel="self" type="application/atom+xml" /><link href="http://localhost:4000/" rel="alternate" type="text/html" /><updated>2024-10-10T12:40:53+11:00</updated><id>http://localhost:4000/feed.xml</id><title type="html">Zack’s Blog</title><subtitle>## AWS   ## Jenkins  ## Microservices ## Automation ## K8S   ## CICD     ## Gitops </subtitle><entry><title type="html">MLOps - First Machine Learning Project</title><link href="http://localhost:4000/jekyll/cat2/2024/10/02/mlops2.html" rel="alternate" type="text/html" title="MLOps - First Machine Learning Project" /><published>2024-10-02T10:15:29+10:00</published><updated>2024-10-02T10:15:29+10:00</updated><id>http://localhost:4000/jekyll/cat2/2024/10/02/mlops2</id><content type="html" xml:base="http://localhost:4000/jekyll/cat2/2024/10/02/mlops2.html"><![CDATA[<p><b>MLOPS Project </b></p>

<p>In the last post <a href="https://zackz.site/jekyll/cat2/2024/10/01/mlops1.html">MLOPS - Lab Setup</a>, I was able to set the local ML lab env, and run validation in Jupyter Notebook to test the CODA device and performance on local PC.</p>

<p>Although <code class="language-plaintext highlighter-rouge">Jupyter Notebooks</code> can be user-friendly tools for ML practice, offering easy interaction and immediate feedback, which simplifies testing and debugging. However, it has limitations such as reproducibility issues, challenges in collaboration and version control, scalability concerns for larger projects, and a lack of automation for tasks like retraining.</p>

<p>In this post, I will try an ML project with tools like <code class="language-plaintext highlighter-rouge">DVC</code>, <code class="language-plaintext highlighter-rouge">MLflow</code>, <code class="language-plaintext highlighter-rouge">Docker</code>, <code class="language-plaintext highlighter-rouge">Apache Airflow</code>, and <code class="language-plaintext highlighter-rouge">CI/CD</code> frameworks to strengthen machine learning workflows. This way can ensure reproducibility by tracking data and code versions, while MLflow logs metrics for effective experiment tracking. Although their initial setup can be complex and resource-intensive, these tools automate processes, streamline workflows, and enhance collaboration and scalability, which could be excessive for smaller ML projects.</p>

<p><b>ML Tools explained </b></p>

<ul>
  <li>Data Versioning (<code class="language-plaintext highlighter-rouge">DVC</code>):</li>
</ul>

<p>DVC allows teams to manage and version datasets just like code. This ensures that data changes are tracked, making it easier to revert to previous versions if necessary.</p>

<ul>
  <li>Experiment Tracking (<code class="language-plaintext highlighter-rouge">MLflow</code>):</li>
</ul>

<p>MLflow tracks experiments, capturing metrics, parameters, and model versions in one centralized location. This makes it easier to compare different runs and select the best-performing model.</p>

<ul>
  <li>Containerization (<code class="language-plaintext highlighter-rouge">Docker</code>):</li>
</ul>

<p>Docker creates isolated environments, ensuring that code runs consistently across different platforms without dependency issues. This helps avoid the “it works on my machine” problem.</p>

<ul>
  <li>Workflow Orchestration (<code class="language-plaintext highlighter-rouge">Apache Airflow</code>):</li>
</ul>

<p>Airflow schedules and manages complex workflows, allowing for the automation of tasks such as data retrieval, preprocessing, model training, and evaluation.</p>

<ul>
  <li>CI/CD (<code class="language-plaintext highlighter-rouge">Jenkins</code>):</li>
</ul>

<p>I have a local Jenkins image to facilitate automatic testing and deployment of models and code changes. This ensures that new features or updates are quickly integrated without disrupting the existing workflow.</p>

<p>Combining these tools, to achieve a holistic pipeline enables reproducibility, scalability, and consistency in machine learning workflows.</p>

<p><b>Project Sturcture </b></p>

<ul>
  <li>Create a new project directory with the following structure:</li>
</ul>

<figure class="highlight"><pre><code class="language-shell" data-lang="shell"><span class="o">(</span>jupyter_env<span class="o">)</span> root@zackz:/mnt/mlops-project# tree
mlops-project/
├── data/                  # Data directory <span class="o">(</span><span class="k">for </span>DVC<span class="o">)</span>
├── models/                # Trained models
├── src/                   <span class="c"># Source code for the ML model</span>
├── notebooks/             <span class="c"># Jupyter notebooks for experimentation</span>
├── Dockerfile             <span class="c"># Docker config for packaging</span>
├── dvc.yaml               <span class="c"># DVC pipeline config</span>
├── airflow_dags/          # Airflow DAG <span class="k">for </span>automation
└── mlflow/                # MLflow tracking directory</code></pre></figure>

<p><b>Project Implementation </b></p>

<ul>
  <li>Step 1: Data Versioning with DVC</li>
</ul>

<p>Initialize Git &amp; DVC</p>

<figure class="highlight"><pre><code class="language-shell" data-lang="shell">pip <span class="nb">install </span>dvc
git init
dvc init <span class="nt">-f</span></code></pre></figure>

<p>Add the Iris Dataset:</p>

<figure class="highlight"><pre><code class="language-shell" data-lang="shell"><span class="nb">mkdir </span>data
curl <span class="nt">-o</span> data/iris.csv https://archive.ics.uci.edu/ml/machine-learning-databases/iris/iris.data
dvc add data/iris.csv</code></pre></figure>

<ul>
  <li>Step 2:Train the Model (Using MLflow)</li>
</ul>

<p>Install MLflow</p>

<figure class="highlight"><pre><code class="language-shell" data-lang="shell">pip <span class="nb">install </span>mlflow</code></pre></figure>

<p>Create a Training Script (src/train.py)</p>

<figure class="highlight"><pre><code class="language-shell" data-lang="shell">vim  src/train.py

import mlflow
import mlflow.sklearn
import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import accuracy_score

<span class="c"># Load the dataset</span>
data <span class="o">=</span> pd.read_csv<span class="o">(</span><span class="s1">'../data/iris.csv'</span>, <span class="nv">header</span><span class="o">=</span>None<span class="o">)</span>
X <span class="o">=</span> data.iloc[:, :-1]
y <span class="o">=</span> data.iloc[:, <span class="nt">-1</span><span class="o">]</span>

<span class="c"># Split data</span>
X_train, X_test, y_train, y_test <span class="o">=</span> train_test_split<span class="o">(</span>X, y, <span class="nv">test_size</span><span class="o">=</span>0.2, <span class="nv">random_state</span><span class="o">=</span>42<span class="o">)</span>

<span class="c"># Track experiment with MLflow</span>
with mlflow.start_run<span class="o">()</span>:
 <span class="c"># Train model</span>
 model <span class="o">=</span> RandomForestClassifier<span class="o">(</span><span class="nv">n_estimators</span><span class="o">=</span>100<span class="o">)</span>
 model.fit<span class="o">(</span>X_train, y_train<span class="o">)</span>

 <span class="c"># Make predictions</span>
 predictions <span class="o">=</span> model.predict<span class="o">(</span>X_test<span class="o">)</span>
 accuracy <span class="o">=</span> accuracy_score<span class="o">(</span>y_test, predictions<span class="o">)</span>

 <span class="c"># Log model and metrics to MLflow</span>
 mlflow.log_metric<span class="o">(</span><span class="s2">"accuracy"</span>, accuracy<span class="o">)</span>
 mlflow.sklearn.log_model<span class="o">(</span>model, <span class="s2">"model"</span><span class="o">)</span>
 print<span class="o">(</span>f<span class="s2">"Model accuracy: {accuracy}"</span><span class="o">)</span></code></pre></figure>

<p>Run the Training Script</p>

<figure class="highlight"><pre><code class="language-shell" data-lang="shell">python src/train.py

<span class="o">(</span>jupyter_env<span class="o">)</span> root@zackz:/mnt/f/1/mlops-project# python src/train.py
2024/10/05 13:33:39 WARNING mlflow.models.model: Model logged without a signature and input example. Please <span class="nb">set</span> <span class="sb">`</span>input_example<span class="sb">`</span> parameter when logging the model to auto infer the model signature.
Model accuracy: 1.0</code></pre></figure>

<p>Launch the MLflow UI</p>

<figure class="highlight"><pre><code class="language-shell" data-lang="shell">mlflow ui</code></pre></figure>

<p>Navigate to http://127.0.0.1:5000 to view the experiment</p>

<p><img src="/assets/mlops21.png" alt="image tooltip here" /></p>

<ul>
  <li>Step 3: Dockerize the Model for Deployment</li>
</ul>

<p>Create Dockerfile:</p>

<figure class="highlight"><pre><code class="language-shell" data-lang="shell">vim Dockerfile

FROM python:3.8-slim

WORKDIR /app

<span class="c"># Install dependencies</span>
COPY requirements.txt <span class="nb">.</span>
RUN pip <span class="nb">install</span> <span class="nt">--no-cache-dir</span> <span class="nt">-r</span> requirements.txt

<span class="c"># Copy the source code</span>
COPY <span class="nb">.</span> <span class="nb">.</span>

<span class="c"># Run the model training script</span>
CMD <span class="o">[</span><span class="s2">"python"</span>, <span class="s2">"src/train.py"</span><span class="o">]</span></code></pre></figure>

<p>Create a requirements.txt file and build the <code class="language-plaintext highlighter-rouge">mlops-local-model</code> Docker image:</p>

<figure class="highlight"><pre><code class="language-shell" data-lang="shell">vim requirements.txt

mlflow
scikit-learn
pandas
dvc

docker build <span class="nt">-t</span> mlops-local-model <span class="nb">.</span>
docker run mlops-local-model

<span class="o">(</span>jupyter_env<span class="o">)</span> root@zackz:~# docker run mlops-local-model
2024/10/05 02:50:58 WARNING mlflow.utils.git_utils: Failed to import Git <span class="o">(</span>the Git executable is probably not on your PATH<span class="o">)</span>, so Git SHA is not available. Error: Failed to initialize: Bad git executable.
The git executable must be specified <span class="k">in </span>one of the following ways:
 - be included <span class="k">in </span>your <span class="nv">$PATH</span>
 - be <span class="nb">set </span>via <span class="nv">$GIT_PYTHON_GIT_EXECUTABLE</span>
 - explicitly <span class="nb">set </span>via git.refresh<span class="o">(</span>&lt;full-path-to-git-executable&gt;<span class="o">)</span>

All git commands will error <span class="k">until </span>this is rectified.

This initial message can be silenced or aggravated <span class="k">in </span>the future by setting the
<span class="nv">$GIT_PYTHON_REFRESH</span> environment variable. Use one of the following values:
 - quiet|q|silence|s|silent|none|n|0: <span class="k">for </span>no message or exception
 - warn|w|warning|log|l|1: <span class="k">for </span>a warning message <span class="o">(</span>logging level CRITICAL, displayed by default<span class="o">)</span>
 - error|e|exception|raise|r|2: <span class="k">for </span>a raised exception

Example:
 <span class="nb">export </span><span class="nv">GIT_PYTHON_REFRESH</span><span class="o">=</span>quiet

2024/10/05 02:51:00 WARNING mlflow.models.model: Model logged without a signature and input example. Please <span class="nb">set</span> <span class="sb">`</span>input_example<span class="sb">`</span> parameter when logging the model to auto infer the model signature.
Model accuracy: 1.0</code></pre></figure>

<ul>
  <li>Step 4: Automate with Apache Airflow</li>
</ul>

<p>Install Apache Airflow:</p>

<figure class="highlight"><pre><code class="language-shell" data-lang="shell">pip <span class="nb">install </span>apache-airflow</code></pre></figure>

<p>Create an Airflow DAG (airflow_dags/ml_pipeline.py)</p>

<figure class="highlight"><pre><code class="language-shell" data-lang="shell">vim  airflow_dags/ml_pipeline.py

from airflow import DAG
from airflow.operators.python_operator import PythonOperator
from datetime import datetime
import os

<span class="c"># Define the DAG</span>
default_args <span class="o">=</span> <span class="o">{</span>
 <span class="s1">'owner'</span>: <span class="s1">'airflow'</span>,
 <span class="s1">'start_date'</span>: datetime<span class="o">(</span>2023, 1, 1<span class="o">)</span>,
 <span class="s1">'retries'</span>: 1,
<span class="o">}</span>

dag <span class="o">=</span> DAG<span class="o">(</span><span class="s1">'mlops_pipeline'</span>, <span class="nv">default_args</span><span class="o">=</span>default_args, <span class="nv">schedule_interval</span><span class="o">=</span><span class="s1">'@daily'</span><span class="o">)</span>

<span class="c"># Define the task to retrain the model</span>
def retrain_model<span class="o">()</span>:
 os.system<span class="o">(</span><span class="s1">'python src/train.py'</span><span class="o">)</span>

retrain_task <span class="o">=</span> PythonOperator<span class="o">(</span>
 <span class="nv">task_id</span><span class="o">=</span><span class="s1">'retrain_model'</span>,
 <span class="nv">python_callable</span><span class="o">=</span>retrain_model,
 <span class="nv">dag</span><span class="o">=</span>dag
<span class="o">)</span>

retrain_task</code></pre></figure>

<p>Run Airflow</p>

<figure class="highlight"><pre><code class="language-shell" data-lang="shell">airflow db init
airflow webserver <span class="nt">--port</span> 8080
airflow scheduler</code></pre></figure>

<p>Create airflow web ui Admin user</p>

<figure class="highlight"><pre><code class="language-shell" data-lang="shell">airflow <span class="nb">users </span>create <span class="se">\</span>
 <span class="nt">--username</span> admin <span class="se">\</span>
 <span class="nt">--firstname</span> Admin <span class="se">\</span>
 <span class="nt">--lastname</span> User <span class="se">\</span>
 <span class="nt">--role</span> Admin <span class="se">\</span>
 <span class="nt">--email</span> admin@xxx.com <span class="se">\</span>
 <span class="nt">--password</span> the_password</code></pre></figure>

<p>Navigate to http://127.0.0.1:8080/to view the Airflow
<img src="/assets/mlops22.png" alt="image tooltip here" /></p>

<ul>
  <li>Step 5: CICD with Jenkins</li>
</ul>

<p>Create Jenkins pipeline for continuous model training with bellow stages:</p>

<ol>
  <li>
    <p>Fetch Data: Executes the <code class="language-plaintext highlighter-rouge">fetch_data.py</code> script to fetch and process new data.</p>
  </li>
  <li>
    <p>Build Docker Image: Build the Docker image using the Dockerfile in the current directory.</p>
  </li>
  <li>
    <p>Run Model Training: Run the Docker container to train the model.</p>
  </li>
  <li>
    <p>Validate Model: Runs the validation script <code class="language-plaintext highlighter-rouge">validate_model.py</code> to validate the trained model.</p>
  </li>
  <li>
    <p>Deploy Model: Pushes the Docker image to a specified Docker registry and executes the deployment script  <code class="language-plaintext highlighter-rouge">deploy-model-script.sh</code>.</p>
  </li>
</ol>

<figure class="highlight"><pre><code class="language-shell" data-lang="shell"><span class="c"># vim Jenkinsfile</span>

pipeline <span class="o">{</span>
    agent any

    stages <span class="o">{</span>
        stage<span class="o">(</span><span class="s1">'Fetch Data'</span><span class="o">)</span> <span class="o">{</span>
            steps <span class="o">{</span>
                script <span class="o">{</span>
                    // Fetch and process new data
                    sh <span class="s1">'python scripts/fetch_data.py'</span>
                <span class="o">}</span>
            <span class="o">}</span>
        <span class="o">}</span>

        stage<span class="o">(</span><span class="s1">'Build Docker Image'</span><span class="o">)</span> <span class="o">{</span>
            steps <span class="o">{</span>
                script <span class="o">{</span>
                    // Build the Docker image
                    sh <span class="s1">'docker build -t mlops-local-model .'</span>
                <span class="o">}</span>
            <span class="o">}</span>
        <span class="o">}</span>

        stage<span class="o">(</span><span class="s1">'Run Model Training'</span><span class="o">)</span> <span class="o">{</span>
            steps <span class="o">{</span>
                script <span class="o">{</span>
                    // Run the Docker container <span class="k">for </span>training
                    sh <span class="s1">'docker run mlops-local-model'</span>
                <span class="o">}</span>
            <span class="o">}</span>
        <span class="o">}</span>

        stage<span class="o">(</span><span class="s1">'Validate Model'</span><span class="o">)</span> <span class="o">{</span>
            steps <span class="o">{</span>
                script <span class="o">{</span>
                    // Validate the trained model
                    sh <span class="s1">'python scripts/validate_model.py'</span>
                <span class="o">}</span>
            <span class="o">}</span>
        <span class="o">}</span>

        stage<span class="o">(</span><span class="s1">'Deploy Model'</span><span class="o">)</span> <span class="o">{</span>
            steps <span class="o">{</span>
                script <span class="o">{</span>
                    // Push the Docker image to the registry
                    sh <span class="s1">'docker push my-repo/mlops-local-model:latest'</span>
                    
                    // Deploy script to update the production environment
                    sh <span class="s1">'deploy-model-script.sh'</span>
                <span class="o">}</span>
            <span class="o">}</span>
        <span class="o">}</span>
    <span class="o">}</span>

    // Optional: Post Actions
    post <span class="o">{</span>
        always <span class="o">{</span>
            <span class="nb">echo</span> <span class="s1">'Pipeline finished.'</span>
        <span class="o">}</span>
        success <span class="o">{</span>
            <span class="nb">echo</span> <span class="s1">'Pipeline completed successfully!'</span>
        <span class="o">}</span>
        failure <span class="o">{</span>
            <span class="nb">echo</span> <span class="s1">'Pipeline failed. Check the logs!'</span>
        <span class="o">}</span>
    <span class="o">}</span>
<span class="o">}</span></code></pre></figure>

<p><b>Conclusion</b></p>

<p>By integrating DVC, MLflow, Docker, Airflow, and CI/CD into a cohesive ML project environment, we can achieve enhanced efficiency, greater automation, and improved collaboration. This synergy not only streamlines the development process but also ensures that machine learning models are robust, reproducible, and ready for production deployment.</p>

<p>In summary, a production-level ML workflow integrates new data, automates model training and deployment, and continuously monitors model performance. By utilizing CI/CD pipelines, Docker for containerization, and tools for versioning and tracking, we can create a robust and efficient machine learning system that can adapt to changing data and business requirements.</p>

<p>In the next post, I will refactor the local tools into AWS ML services, to move the ML pipeline and deployment to the cloud.</p>]]></content><author><name></name></author><category term="jekyll" /><category term="Cat2" /><summary type="html"><![CDATA[MLOPS Project]]></summary></entry><entry><title type="html">MLOps - Lab Setup</title><link href="http://localhost:4000/jekyll/cat2/2024/10/01/mlops1.html" rel="alternate" type="text/html" title="MLOps - Lab Setup" /><published>2024-10-01T10:15:29+10:00</published><updated>2024-10-01T10:15:29+10:00</updated><id>http://localhost:4000/jekyll/cat2/2024/10/01/mlops1</id><content type="html" xml:base="http://localhost:4000/jekyll/cat2/2024/10/01/mlops1.html"><![CDATA[<p><b>Move to MLOPS </b></p>

<p>Transitioning from DevOps to MLOps can be achieved by leveraging existing DevOps expertise by adding new layers specific to machine learning.</p>

<ul>
  <li>Key Differences:</li>
</ul>

<p><code class="language-plaintext highlighter-rouge">Model Lifecycle Management</code>: MLOps handles model training, deployment, and retraining.</p>

<p><code class="language-plaintext highlighter-rouge">Data Versioning</code>: Tools like DVC ensure dataset version control.</p>

<p><code class="language-plaintext highlighter-rouge">Experiment Tracking</code>: MLflow and Weights &amp; Biases track model training parameters and results.</p>

<p><code class="language-plaintext highlighter-rouge">Model Serving</code>: Deploy models with TensorFlow Serving or TorchServe.</p>

<p><code class="language-plaintext highlighter-rouge">Model Drift</code>: Monitor data changes over time to trigger retraining.</p>

<ul>
  <li>Core MLOps Tools:</li>
</ul>

<p><code class="language-plaintext highlighter-rouge">Model Training &amp; Experimentation</code>: Tools like DVC, MLflow, and Kubeflow for managing data, tracking experiments, and distributed training.</p>

<p><code class="language-plaintext highlighter-rouge">Model Deployment &amp; Serving</code>: Use CI/CD pipelines, Docker, Kubernetes, and frameworks like ONNX for deploying models at scale.</p>

<p><code class="language-plaintext highlighter-rouge">Monitoring &amp; Retraining</code>: Use Prometheus, Grafana, and Seldon for monitoring performance and retraining pipelines.</p>

<p><code class="language-plaintext highlighter-rouge">Data Pipelines</code>: Automate feature engineering with Apache Airflow, Dagster, or Kubeflow.</p>

<ul>
  <li>Leverage DevOps Skills for MLOps:</li>
</ul>

<p><code class="language-plaintext highlighter-rouge">CI/CD Pipelines</code>: Automate model training, testing, and deployment with Jenkins or cloud solutions.</p>

<p><code class="language-plaintext highlighter-rouge">Infrastructure as Code</code>: Use Terraform or Ansible for cloud-based ML infrastructure.</p>

<p><code class="language-plaintext highlighter-rouge">Containerization &amp; Orchestration</code>: Deploy ML models with Docker and Kubernetes.</p>

<p><code class="language-plaintext highlighter-rouge">Monitoring</code>: Track both infrastructure and model-specific metrics like accuracy and drift.</p>

<p><b>Local Lab ML practise</b></p>

<p>I will start the local lab by:  </p>

<ul>
  <li>
    <p>Setting up a local ML env</p>
  </li>
  <li>
    <p>Install ML-focused tools (Nvidia Cuda, Python3 and pip Virtual ENV, PyTorch and Jupyter Notebook)</p>
  </li>
  <li>
    <p>Build and version simple ML models locally with tools like DVC, MLflow, and Docker.</p>
  </li>
</ul>

<p>Next stages I will try:</p>

<ul>
  <li>
    <p>Provision AWS Sagemaker using terraform or Cloudformation.</p>
  </li>
  <li>
    <p>Implement CI pipelines for Model training and continuous packaging.</p>
  </li>
  <li>
    <p>CD pipelines to provision AWS ECS or EKS to deploy models.</p>
  </li>
</ul>

<p><b>Prerequisites</b></p>

<ul>
  <li>
    <p>Windows 10 with Powershell and Windows Terminal installed</p>
  </li>
  <li>
    <p>CPU Virtulization enabled in BIOS</p>
  </li>
  <li>
    <p>WSL2 with Ubuntu LTS installed</p>
  </li>
  <li>
    <p>Docker Desktop</p>
  </li>
</ul>

<p><b>Install WSL with Ubuntu</b></p>

<p>First, we need to configure local WSL to install Ubuntu.</p>

<figure class="highlight"><pre><code class="language-shell" data-lang="shell">C:<span class="se">\U</span>sers<span class="se">\z</span>ack&gt;wsl <span class="nt">--list</span> <span class="nt">--online</span>
Use <span class="s1">'wsl.exe --install &lt;Distro&gt;'</span> to <span class="nb">install

</span>NAME                            FRIENDLY NAME
Ubuntu                          Ubuntu
Debian                          Debian GNU/Linux
kali-linux                      Kali Linux Rolling
Ubuntu-18.04                    Ubuntu 18.04 LTS
Ubuntu-20.04                    Ubuntu 20.04 LTS
Ubuntu-22.04                    Ubuntu 22.04 LTS
Ubuntu-24.04                    Ubuntu 24.04 LTS
OracleLinux_7_9                 Oracle Linux 7.9
OracleLinux_8_7                 Oracle Linux 8.7
OracleLinux_9_1                 Oracle Linux 9.1
openSUSE-Leap-15.6              openSUSE Leap 15.6
SUSE-Linux-Enterprise-15-SP5    SUSE Linux Enterprise 15 SP5
SUSE-Linux-Enterprise-15-SP6    SUSE Linux Enterprise 15 SP6
openSUSE-Tumbleweed             openSUSE Tumbleweed

C:<span class="se">\U</span>sers<span class="se">\z</span>ack&gt;wsl <span class="nt">--install</span> <span class="nt">-d</span> Ubuntu-24.04
Installing: Ubuntu 24.04 LTS
Installed Ubuntu 24.04 LTS。
Launching Ubuntu 24.04 LTS...
Installing, this may take a few minutes...
Installation successful!

ubuntu@zackz:~<span class="nv">$ </span><span class="nb">cat</span> /etc/os-release
<span class="nv">PRETTY_NAME</span><span class="o">=</span><span class="s2">"Ubuntu 24.04.1 LTS"</span>
<span class="nv">NAME</span><span class="o">=</span><span class="s2">"Ubuntu"</span>
<span class="nv">VERSION_ID</span><span class="o">=</span><span class="s2">"24.04"</span>
<span class="nv">VERSION</span><span class="o">=</span><span class="s2">"24.04.1 LTS (Noble Numbat)"</span>
<span class="nv">VERSION_CODENAME</span><span class="o">=</span>noble
<span class="nv">ID</span><span class="o">=</span>ubuntu
<span class="nv">ID_LIKE</span><span class="o">=</span>debian
<span class="nv">HOME_URL</span><span class="o">=</span><span class="s2">"https://www.ubuntu.com/"</span>
<span class="nv">SUPPORT_URL</span><span class="o">=</span><span class="s2">"https://help.ubuntu.com/"</span>
<span class="nv">BUG_REPORT_URL</span><span class="o">=</span><span class="s2">"https://bugs.launchpad.net/ubuntu/"</span>
<span class="nv">PRIVACY_POLICY_URL</span><span class="o">=</span><span class="s2">"https://www.ubuntu.com/legal/terms-and-policies/privacy-policy"</span>
<span class="nv">UBUNTU_CODENAME</span><span class="o">=</span>noble
<span class="nv">LOGO</span><span class="o">=</span>ubuntu-logo</code></pre></figure>

<p><b>Install Nvidia CUDA</b></p>

<ul>
  <li>CUDA works with C. Thus, we need to install the gcc compiler first, then install CUDA from <a href="https://developer.nvidia.com/cuda-downloads">the official website of Nvidia</a>, then configure environment variable for post-installation  <a href="https://docs.nvidia.com/cuda/cuda-installation-guide-linux/index.html">The official CUDA installation guide from Nvidia</a></li>
</ul>

<p><img src="/assets/mlops1.png" alt="image tooltip here" /></p>

<p><img src="/assets/mlops2.png" alt="image tooltip here" /></p>

<figure class="highlight"><pre><code class="language-shell" data-lang="shell"><span class="nb">sudo </span>apt <span class="nb">install </span>gcc <span class="nt">--fix-missing</span>

wget https://developer.download.nvidia.com/compute/cuda/repos/wsl-ubuntu/x86_64/cuda-wsl-ubuntu.pin
<span class="nb">sudo mv </span>cuda-wsl-ubuntu.pin /etc/apt/preferences.d/cuda-repository-pin-600
wget https://developer.download.nvidia.com/compute/cuda/12.6.2/local_installers/cuda-repo-wsl-ubuntu-12-6-local_12.6.2-1_amd64.deb
<span class="nb">sudo </span>dpkg <span class="nt">-i</span> cuda-repo-wsl-ubuntu-12-6-local_12.6.2-1_amd64.deb
<span class="nb">sudo cp</span> /var/cuda-repo-wsl-ubuntu-12-6-local/cuda-<span class="k">*</span><span class="nt">-keyring</span>.gpg /usr/share/keyrings/
<span class="nb">sudo </span>apt-get update
<span class="nb">sudo </span>apt-get <span class="nt">-y</span> <span class="nb">install </span>cuda-toolkit-12-6

vim .bashrc
<span class="nb">export </span><span class="nv">PATH</span><span class="o">=</span>/usr/local/cuda-12.6/bin<span class="k">${</span><span class="nv">PATH</span>:+:<span class="k">${</span><span class="nv">PATH</span><span class="k">}}</span>

<span class="c"># To apply and validate the changes, </span>
<span class="nb">source</span> ~/.bashrc
<span class="nb">echo</span> <span class="nv">$PATH</span>
root@zackz:~# <span class="nb">echo</span> <span class="nv">$PATH</span>
/root/jupyter_env/bin:/usr/local/cuda-12.6/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/usr/games:/usr/local/games:/usr/lib/wsl/lib:/mnt/c/Program Files/Amazon Corretto/jdk11.0.23_9/bin:/mnt/c/Python313/Scripts/:/mnt/c/Python313/:/mnt/d/Ruby32/bin:/mnt/f/VM workstation pro 16/bin/:/mnt/c/Windows/system32:/mnt/c/Windows:/mnt/c/Windows/System32/Wbem:/mnt/c/Windows/System32/WindowsPowerShell/v1.0/:/mnt/c/Windows/System32/OpenSSH/:/mnt/c/Program Files <span class="o">(</span>x86<span class="o">)</span>/NVIDIA Corporation/PhysX/Common:/mnt/c/Program Files/NVIDIA Corporation/NVIDIA NvDLISR:/mnt/c/ProgramData/chocolatey/bin:/mnt/d/Program Files/Git/cmd:/mnt/c/Program Files/Java/jdk1.8.0_211/bin:/mnt/c/Program Files/dotnet/:/mnt/d/Program Files <span class="o">(</span>x86<span class="o">)</span>/NetSarang/Xshell 7/:/mnt/c/ProgramData/chocolatey/bin/Minikube:/mnt/c/ProgramData/chocolatey/bin/kubectl:/mnt/c/Program Files/Amazon/AWSCLIV2/:/mnt/c/ProgramData/chocolatey/lib/maven/apache-maven-3.9.6/bin:/mnt/c/Program Files/Docker/Docker/resources/bin:/mnt/c/Users/zack/AppData/Local/Microsoft/WindowsApps:/mnt/d/Microsoft VS Code/bin:/mnt/c/Python313:/mnt/c/Python313/Scripts:/mnt/c/Program Files/Oracle/VirtualBox:/snap/bin</code></pre></figure>

<ul>
  <li>Install the Nvidia Cuda Toolkit, check the Driver and CUDA versions, validate Nvidia Cuda Compiler Driver has been installed.</li>
</ul>

<figure class="highlight"><pre><code class="language-shell" data-lang="shell"><span class="nb">sudo </span>apt <span class="nb">install </span>nvidia-cuda-toolkit

root@zackz:~# nvidia-smi
Wed Oct  9 10:53:26 2024
+---------------------------------------------------------------------------------------+
| NVIDIA-SMI 535.112                Driver Version: 537.42       CUDA Version: 12.2     |
|-----------------------------------------+----------------------+----------------------+
| GPU  Name                 Persistence-M | Bus-Id        Disp.A | Volatile Uncorr. ECC |
| Fan  Temp   Perf          Pwr:Usage/Cap |         Memory-Usage | GPU-Util  Compute M. |
|                                         |                      |               MIG M. |
|<span class="o">=========================================</span>+<span class="o">======================</span>+<span class="o">======================</span>|
|   0  NVIDIA GeForce RTX 3070 Ti     On  | 00000000:01:00.0  On |                  N/A |
|  0%   55C    P0              80W / 148W |   1635MiB /  8192MiB |      1%      Default |
|                                         |                      |                  N/A |
+-----------------------------------------+----------------------+----------------------+

+---------------------------------------------------------------------------------------+
| Processes:                                                                            |
|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |
|        ID   ID                                                             Usage      |
|<span class="o">=======================================================================================</span>|
|    0   N/A  N/A        27      G   /Xwayland                                 N/A      |
|    0   N/A  N/A        30      G   /Xwayland                                 N/A      |
|    0   N/A  N/A        37      G   /Xwayland                                 N/A      |
+---------------------------------------------------------------------------------------+

root@zackz:~# nvcc <span class="nt">-V</span>
nvcc: NVIDIA <span class="o">(</span>R<span class="o">)</span> Cuda compiler driver
Copyright <span class="o">(</span>c<span class="o">)</span> 2005-2024 NVIDIA Corporation
Built on Thu_Sep_12_02:18:05_PDT_2024
Cuda compilation tools, release 12.6, V12.6.77
Build cuda_12.6.r12.6/compiler.34841621_0</code></pre></figure>

<p><b>Install Python3 and PIP Virtual ENV</b></p>

<p>Ensure that python3 and PIP are installed, and create virtual env for Pytorch and Jupyter Notebook</p>

<figure class="highlight"><pre><code class="language-shell" data-lang="shell">root@zackz:~# python3 <span class="nt">--version</span>
Python 3.12.3

<span class="nb">sudo </span>apt-get <span class="nb">install </span>python3-pip

apt <span class="nb">install </span>python3.12-venv

python3 <span class="nt">-m</span> venv jupyter_env

<span class="nb">source </span>jupyter_env/bin/activate

<span class="o">(</span>jupyter_env<span class="o">)</span>root@zackz:~# </code></pre></figure>

<p><b>Install PyTorch</b></p>

<p>Installing the PyTorch <a href="https://pytorch.org/get-started/locally/">the official website of PyTorch</a>, and enable the Nvidia Developer Settings for using CUDA via WSL, then validate CUDA from Torch.</p>

<p><img src="/assets/mlops3.png" alt="image tooltip here" /></p>

<p><img src="/assets/mlops4.png" alt="image tooltip here" /></p>

<figure class="highlight"><pre><code class="language-shell" data-lang="shell"><span class="o">(</span>jupyter_env<span class="o">)</span>root@zackz:~# pip3 <span class="nb">install </span>torch torchvision torchaudio <span class="nt">--index-url</span> https://download.pytorch.org/whl/cu124 

<span class="o">(</span>jupyter_env<span class="o">)</span>root@zackz:~#  python3
Python 3.12.3 <span class="o">(</span>main, Sep 11 2024, 14:17:37<span class="o">)</span> <span class="o">[</span>GCC 13.2.0] on linux
Type <span class="s2">"help"</span>, <span class="s2">"copyright"</span>, <span class="s2">"credits"</span> or <span class="s2">"license"</span> <span class="k">for </span>more information.
<span class="o">&gt;&gt;&gt;</span> import torch
ch.cuda.is_available<span class="o">()</span>

True
<span class="o">&gt;&gt;&gt;</span></code></pre></figure>

<p><b>Install Jupyter Notebook</b></p>

<ul>
  <li>Installing Jupyter Notebook and run in the virtual env, create the first notebook to verify if it is using CPU or CUDA from GPU, then run a simple notebook to have a performance comparison between CPU and GPU.</li>
</ul>

<figure class="highlight"><pre><code class="language-shell" data-lang="shell"><span class="c"># install jupyter notebook</span>

pip <span class="nb">install </span>jupyter notebook 

<span class="c"># run  jupyter notebook in the virtual env</span>

<span class="o">(</span>jupyter_env<span class="o">)</span> root@zackz:~# jupyter notebook  --allow-root</code></pre></figure>

<ul>
  <li>Verify Torch with CUDA device</li>
</ul>

<figure class="highlight"><pre><code class="language-shell" data-lang="shell">import torch

<span class="k">if </span>torch.cuda.is_available<span class="o">()</span>:
 device <span class="o">=</span> torch.device<span class="o">(</span><span class="s2">"cuda"</span><span class="o">)</span>
<span class="k">else</span>:
 device <span class="o">=</span> torch.device<span class="o">(</span><span class="s2">"cpu"</span><span class="o">)</span>
print<span class="o">(</span><span class="s2">"using"</span>, device, <span class="s2">"device"</span><span class="o">)</span> </code></pre></figure>

<p><img src="/assets/mlops5.png" alt="image tooltip here" /></p>

<ul>
  <li>Run performance comparison between my CPU and GPU (CUDA)</li>
</ul>

<figure class="highlight"><pre><code class="language-shell" data-lang="shell">import <span class="nb">time

</span>matrix_size <span class="o">=</span> 32<span class="k">*</span>512

x <span class="o">=</span> torch.randn<span class="o">(</span>matrix_size, matrix_size<span class="o">)</span>
y <span class="o">=</span> torch.randn<span class="o">(</span>matrix_size, matrix_size<span class="o">)</span>

print<span class="o">(</span><span class="s2">"************* CPU SPEED *******************"</span><span class="o">)</span>
start <span class="o">=</span> time.time<span class="o">()</span>
result <span class="o">=</span> torch.matmul<span class="o">(</span>x, y<span class="o">)</span>
print<span class="o">(</span>time.time<span class="o">()</span> - start<span class="o">)</span>
print<span class="o">(</span><span class="s2">"verify device:"</span>, result.device<span class="o">)</span>

x_gpu <span class="o">=</span> x.to<span class="o">(</span>device<span class="o">)</span>
y_gpu <span class="o">=</span> y.to<span class="o">(</span>device<span class="o">)</span>
torch.cuda.synchronize<span class="o">()</span>

<span class="k">for </span>i <span class="k">in </span>range<span class="o">(</span>3<span class="o">)</span>:
 print<span class="o">(</span><span class="s2">"************* GPU SPEED *******************"</span><span class="o">)</span>
 start <span class="o">=</span> time.time<span class="o">()</span>
 result_gpu <span class="o">=</span> torch.matmul<span class="o">(</span>x_gpu, y_gpu<span class="o">)</span>
 torch.cuda.synchronize<span class="o">()</span>
 print<span class="o">(</span>time.time<span class="o">()</span> - start<span class="o">)</span>
 print<span class="o">(</span><span class="s2">"verify device:"</span>, result_gpu.device<span class="o">)</span></code></pre></figure>

<p><img src="/assets/mlops6.png" alt="image tooltip here" /></p>

<p><b>Conclusion</b></p>

<p>Here I have successfully set up a local machine learning lab env, and installed ML tools on local Windows using WSL2. Next stage we will try to run a local ML module and containerize it into a docker image.</p>]]></content><author><name></name></author><category term="jekyll" /><category term="Cat2" /><summary type="html"><![CDATA[Move to MLOPS]]></summary></entry><entry><title type="html">EKS Security Practise with Kube-Bench and OPA Gatekeeper</title><link href="http://localhost:4000/jekyll/cat2/2024/09/13/eks2.html" rel="alternate" type="text/html" title="EKS Security Practise with Kube-Bench and OPA Gatekeeper" /><published>2024-09-13T10:15:29+10:00</published><updated>2024-09-13T10:15:29+10:00</updated><id>http://localhost:4000/jekyll/cat2/2024/09/13/eks2</id><content type="html" xml:base="http://localhost:4000/jekyll/cat2/2024/09/13/eks2.html"><![CDATA[<p><b>About kube-bench and OPA Gatekeeper </b></p>

<p>In the last post, I was able to implement <a href="https://zackz.site/jekyll/cat2/2024/09/12/eks1.html">EKS cluster autoscaler and Horizontal Pod Autoscaler (HPA)</a>, in this post I will continue with EKS security practice with Kube-Bench and OPA Gatekeeper.</p>

<ul>
  <li>kube-bench:</li>
</ul>

<p><code class="language-plaintext highlighter-rouge">kube-bench</code> is a tool that checks Kubernetes clusters against the CIS (Center for Internet Security) benchmarks, a set of best practices for securing Kubernetes. It is critical to ensure that a cluster complies with these security guidelines, helping identify potential vulnerabilities and misconfigurations. Key features include generating detailed audit reports, performing automated compliance checks, and easily integrating into existing CI/CD pipelines for continuous security assessments</p>

<ul>
  <li>OPA Gatekeeper</li>
</ul>

<p>OPA (Open Policy Agent) is a policy engine that allows to define and enforce policies across various services, including Kubernetes. <code class="language-plaintext highlighter-rouge">OPA Gatekeeper</code> extends OPA’s functionality specifically for Kubernetes by providing admission control, enabling the enforcement of custom policies on resources before they are created or modified. The benefits of using OPA Gatekeeper include consistent policy enforcement across the cluster, fine-grained control over resource configurations, and reducing the risk of misconfigurations by ensuring compliance with defined rules.</p>

<p><b>kube-bench in EKS</b></p>

<p>We will be based on <a href="https://github.com/aquasecurity/kube-bench/blob/main/docs/platforms.md#cis-kubernetes-benchmark-support">official cis-kubernetes-benchmark-support webpage</a>, to apply the kube-bench job yaml for EKS, when the job completed, the results are held in the pod’s logs.</p>

<figure class="highlight"><pre><code class="language-shell" data-lang="shell"><span class="nv">$ </span>kubectl.exe get node
NAME                                               STATUS   ROLES    AGE     VERSION
ip-172-31-37-215.ap-southeast-2.compute.internal   Ready    &lt;none&gt;   2m29s   v1.31.0-eks-a737599

<span class="c"># apply the job yaml for EKS</span>
kubectl apply <span class="nt">-f</span> https://raw.githubusercontent.com/aquasecurity/kube-bench/refs/heads/main/job-eks.yaml

<span class="c"># check  the job status</span>
<span class="nv">$ </span>kubectl get pods
NAME                      READY   STATUS              RESTARTS   AGE
kube-bench-j76s9   0/1     ContainerCreating   0          3s

<span class="c"># Wait for a few seconds for the job to complete</span>
<span class="nv">$ </span>kubectl get pods
NAME                      READY   STATUS      RESTARTS   AGE
kube-bench-j76s9   0/1 Completed   0          11s

<span class="c"># The results are held in the pod's logs</span>
kubectl logs kube-bench-j76s9

<span class="o">[</span>INFO] 3 Worker Node Security Configuration
<span class="o">[</span>INFO] 3.1 Worker Node Configuration Files
<span class="o">[</span>PASS] 3.1.1 Ensure that the kubeconfig file permissions are <span class="nb">set </span>to 644 or more restrictive <span class="o">(</span>Manual<span class="o">)</span>
<span class="o">[</span>PASS] 3.1.2 Ensure that the kubelet kubeconfig file ownership is <span class="nb">set </span>to root:root <span class="o">(</span>Manual<span class="o">)</span>
<span class="o">[</span>PASS] 3.1.3 Ensure that the kubelet configuration file has permissions <span class="nb">set </span>to 644 or more restrictive <span class="o">(</span>Manual<span class="o">)</span>
<span class="o">[</span>PASS] 3.1.4 Ensure that the kubelet configuration file ownership is <span class="nb">set </span>to root:root <span class="o">(</span>Manual<span class="o">)</span>
<span class="o">[</span>INFO] 3.2 Kubelet
<span class="o">[</span>PASS] 3.2.1 Ensure that the Anonymous Auth is Not Enabled <span class="o">(</span>Automated<span class="o">)</span>
<span class="o">[</span>PASS] 3.2.2 Ensure that the <span class="nt">--authorization-mode</span> argument is not <span class="nb">set </span>to AlwaysAllow <span class="o">(</span>Automated<span class="o">)</span>
<span class="o">[</span>PASS] 3.2.3 Ensure that a Client CA File is Configured <span class="o">(</span>Manual<span class="o">)</span>
<span class="o">[</span>PASS] 3.2.4 Ensure that the <span class="nt">--read-only-port</span> is disabled <span class="o">(</span>Manual<span class="o">)</span>
<span class="o">[</span>PASS] 3.2.5 Ensure that the <span class="nt">--streaming-connection-idle-timeout</span> argument is not <span class="nb">set </span>to 0 <span class="o">(</span>Automated<span class="o">)</span>
<span class="o">[</span>PASS] 3.2.6 Ensure that the <span class="nt">--protect-kernel-defaults</span> argument is <span class="nb">set </span>to <span class="nb">true</span> <span class="o">(</span>Automated<span class="o">)</span>
<span class="o">[</span>PASS] 3.2.7 Ensure that the <span class="nt">--make-iptables-util-chains</span> argument is <span class="nb">set </span>to <span class="nb">true</span> <span class="o">(</span>Automated<span class="o">)</span> 
<span class="o">[</span>WARN] 3.2.8 Ensure that the <span class="nt">--hostname-override</span> argument is not <span class="nb">set</span> <span class="o">(</span>Manual<span class="o">)</span>
<span class="o">[</span>WARN] 3.2.9 Ensure that the <span class="nt">--eventRecordQPS</span> argument is <span class="nb">set </span>to 0 or a level which ensures appropriate event capture <span class="o">(</span>Automated<span class="o">)</span>
<span class="o">[</span>PASS] 3.2.10 Ensure that the <span class="nt">--rotate-certificates</span> argument is not present or is <span class="nb">set </span>to <span class="nb">true</span> <span class="o">(</span>Manual<span class="o">)</span>
<span class="o">[</span>PASS] 3.2.11 Ensure that the RotateKubeletServerCertificate argument is <span class="nb">set </span>to <span class="nb">true</span> <span class="o">(</span>Manual<span class="o">)</span>
<span class="o">[</span>INFO] 3.3 Container Optimized OS
<span class="o">[</span>WARN] 3.3.1 Prefer using a container-optimized OS when possible <span class="o">(</span>Manual<span class="o">)</span>

<span class="o">==</span> Remediations node <span class="o">==</span>
3.2.8 Edit the kubelet service file /etc/systemd/system/kubelet.service
on each worker node and remove the <span class="nt">--hostname-override</span> argument from the
KUBELET_SYSTEM_PODS_ARGS variable.
Based on your system, restart the kubelet service. For example:
systemctl daemon-reload
systemctl restart kubelet.service

3.2.9 If using a Kubelet config file, edit the file to <span class="nb">set </span>eventRecordQPS: to an appropriate level.
If using <span class="nb">command </span>line arguments, edit the kubelet service file
/etc/systemd/system/kubelet.service on each worker node and
<span class="nb">set </span>the below parameter <span class="k">in </span>KUBELET_SYSTEM_PODS_ARGS variable.
Based on your system, restart the kubelet service. For example:
systemctl daemon-reload
systemctl restart kubelet.service

3.3.1 audit <span class="nb">test </span>did not run: No tests defined

<span class="o">==</span> Summary node <span class="o">==</span>
13 checks PASS
0 checks FAIL
3 checks WARN
0 checks INFO

<span class="o">==</span> Summary total <span class="o">==</span>
13 checks PASS
0 checks FAIL
3 checks WARN
0 checks INFO</code></pre></figure>

<p>Based on the scan result, the EKS managed workder node can be secure will 13 check pass and 0 check fail, by following the remediation suggestion we can set the EKS cluster compliant with the CIS benchmark.</p>

<p><b>OPA Gatekeeper in EKS</b></p>

<ul>
  <li>Install the OPA Gatekeeper</li>
</ul>

<p>We will first install Gatekeeper in EKS cluster by applying the Gatekeeper installation manifests from <a href="https://open-policy-agent.github.io/gatekeeper/website/docs/install/">the official repository</a>.</p>

<figure class="highlight"><pre><code class="language-shell" data-lang="shell"><span class="nv">$ </span>kubectl apply <span class="nt">-f</span> https://raw.githubusercontent.com/open-policy-agent/gatekeeper/v3.12.0/deploy/gatekeeper.yaml
namespace/gatekeeper-system created
resourcequota/gatekeeper-critical-pods created
customresourcedefinition.apiextensions.k8s.io/assign.mutations.gatekeeper.sh created
customresourcedefinition.apiextensions.k8s.io/assignimage.mutations.gatekeeper.sh created
customresourcedefinition.apiextensions.k8s.io/assignmetadata.mutations.gatekeeper.sh created
customresourcedefinition.apiextensions.k8s.io/configs.config.gatekeeper.sh created
customresourcedefinition.apiextensions.k8s.io/constraintpodstatuses.status.gatekeeper.sh created
customresourcedefinition.apiextensions.k8s.io/constrainttemplatepodstatuses.status.gatekeeper.sh created
customresourcedefinition.apiextensions.k8s.io/constrainttemplates.templates.gatekeeper.sh created
customresourcedefinition.apiextensions.k8s.io/expansiontemplate.expansion.gatekeeper.sh created
customresourcedefinition.apiextensions.k8s.io/modifyset.mutations.gatekeeper.sh created
customresourcedefinition.apiextensions.k8s.io/mutatorpodstatuses.status.gatekeeper.sh created
customresourcedefinition.apiextensions.k8s.io/providers.externaldata.gatekeeper.sh created
serviceaccount/gatekeeper-admin created
role.rbac.authorization.k8s.io/gatekeeper-manager-role created
clusterrole.rbac.authorization.k8s.io/gatekeeper-manager-role created
rolebinding.rbac.authorization.k8s.io/gatekeeper-manager-rolebinding created
clusterrolebinding.rbac.authorization.k8s.io/gatekeeper-manager-rolebinding created
secret/gatekeeper-webhook-server-cert created
service/gatekeeper-webhook-service created
deployment.apps/gatekeeper-audit created
deployment.apps/gatekeeper-controller-manager created
poddisruptionbudget.policy/gatekeeper-controller-manager created
mutatingwebhookconfiguration.admissionregistration.k8s.io/gatekeeper-mutating-webhook-configuration created
validatingwebhookconfiguration.admissionregistration.k8s.io/gatekeeper-validating-webhook-configuration created

<span class="nv">$ </span>kubectl.exe get all <span class="nt">-n</span> gatekeeper-system
NAME                                                 READY   STATUS    RESTARTS        AGE
pod/gatekeeper-audit-777f449c79-h7lzn                1/1 Running   1 <span class="o">(</span>3m35s ago<span class="o">)</span>   3m42s
pod/gatekeeper-controller-manager-84bf857ff7-rzlb8   1/1 Running   0               3m42s

NAME                                 TYPE        CLUSTER-IP      EXTERNAL-IP   PORT<span class="o">(</span>S<span class="o">)</span>   AGE
service/gatekeeper-webhook-service   ClusterIP   10.100.126.57 &lt;none&gt;        443/TCP   3m42s

NAME                                            READY   UP-TO-DATE   AVAILABLE   AGE
deployment.apps/gatekeeper-audit                1/1     1            1           3m42s
deployment.apps/gatekeeper-controller-manager   1/1     1            1           3m42s

NAME                                                       DESIRED   CURRENT   READY   AGE
replicaset.apps/gatekeeper-audit-777f449c79                1         1         1       3m42s
replicaset.apps/gatekeeper-controller-manager-84bf857ff7   1         1         1       3m42s</code></pre></figure>

<ul>
  <li>OPA Gatekeeper works with two main components:</li>
</ul>

<p><code class="language-plaintext highlighter-rouge">ConstraintTemplate</code>: Defines a reusable logic for policies.</p>

<p><code class="language-plaintext highlighter-rouge">Constraint</code>: Applies specific policies based on the logic defined in the ConstraintTemplate.</p>

<p>Here we will create a <code class="language-plaintext highlighter-rouge">ConstraintTemplate</code> and <code class="language-plaintext highlighter-rouge">required-label-policy</code> to enforce required labels during pod creation, and run a test pod with and without required labels to test the policy enforcement.</p>

<figure class="highlight"><pre><code class="language-shell" data-lang="shell"><span class="c"># Create a ConstraintTemplate and policy to enforce require-labels for pod creation</span>
vim required-label-template.yaml 

apiVersion: templates.gatekeeper.sh/v1
kind: ConstraintTemplate
metadata:
 name: k8srequiredlabels
spec:
 crd:
 spec:
 names:
 kind: K8sRequiredLabels
 targets:
 - target: admission.k8s.gatekeeper.sh
 rego: |
 package k8srequiredlabels

 violation[<span class="o">{</span><span class="s2">"msg"</span>: msg<span class="o">}]</span> <span class="o">{</span>
 required_label :<span class="o">=</span> <span class="s2">"required-label"</span>
 not input.review.object.metadata.labels[required_label]
 msg :<span class="o">=</span> sprintf<span class="o">(</span><span class="s2">"You must provide the '%s' label on every resource."</span>, <span class="o">[</span>required_label]<span class="o">)</span>
 <span class="o">}</span>
<span class="nt">---</span>
apiVersion: constraints.gatekeeper.sh/v1beta1
kind: K8sRequiredLabels
metadata:
 name: require-labels
spec:
 match:
 kinds:
 - apiGroups: <span class="o">[</span><span class="s2">""</span><span class="o">]</span>
 kinds: <span class="o">[</span><span class="s2">"Pod"</span><span class="o">]</span>

<span class="c">#  Apply the ConstraintTemplate and policy</span>
<span class="nv">$ </span>kubectl.exe apply <span class="nt">-f</span> required-label-template.yaml 
constrainttemplate.templates.gatekeeper.sh/k8srequiredlabels configured
k8srequiredlabels.constraints.gatekeeper.sh/require-labels created

<span class="c"># Validate constraint templates</span>
<span class="nv">$ </span>kubectl get constrainttemplates
NAME                AGE
k8srequiredlabels   15s</code></pre></figure>

<p>Then we need to create a test pod with and without required labels to test the policy enforcement</p>

<figure class="highlight"><pre><code class="language-shell" data-lang="shell"><span class="nv">$ </span>vim test-pod.yaml

apiVersion: v1
kind: Pod
metadata:
 name: test-pod
spec:
 containers:
 - name: test-container
 image: nginx

<span class="nv">$ </span>kubectl apply <span class="nt">-f</span> test-pod.yaml
Error from server <span class="o">(</span>Forbidden<span class="o">)</span>: error when creating <span class="s2">"test-pod.yaml"</span>: admission webhook <span class="s2">"validation.gatekeeper.sh"</span> denied the request: <span class="o">[</span>require-labels] You must provide the <span class="s1">'required-label'</span> label on every resource.

<span class="nv">$ </span>vim test-pod-labeled.yaml

apiVersion: v1
kind: Pod
metadata:
 name: test-pod-labeled
 labels:
 required-label: <span class="s2">"true"</span>
spec:
 containers:
 - name: test-container
 image: nginx

<span class="nv">$ </span>kubectl apply <span class="nt">-f</span> test-pod-labeled.yaml
pod/test-pod-labeled created

zack@zackz MINGW64 /f/1/terraform-eks <span class="o">(</span>master<span class="o">)</span>
<span class="nv">$ </span>kubectl.exe get po
NAME               READY   STATUS              RESTARTS   AGE
kube-bench-xrx8g   0/1     Completed           0          21m
test-pod-labeled   0/1     ContainerCreating   0          5s

<span class="nv">$ </span>kubectl.exe get po
NAME               READY   STATUS      RESTARTS   AGE
kube-bench-xrx8g   0/1 Completed   0          22m
test-pod-labeled   1/1 Running     0          24s</code></pre></figure>

<p>Based on the constraint we created before, the policy prevents the pod from being created with</p>

<p><code class="language-plaintext highlighter-rouge">Error from server (Forbidden): error when creating "test-pod.yaml": admission webhook "validation.gatekeeper.sh" denied the request: [require-labels] You must provide the 'required-label' label on every resource</code></p>

<p>this can be expanded to more strict rules to enforce k8s cluster to achieve the desired control.</p>

<p><b>Conclusion</b></p>

<p>In this post, we dive into the process of enhancing the security of an AWS EKS cluster by implementing and validating two critical security tools: Kube-bench and OPA Gatekeeper to get some hands-on to achieve a secure EKS environment by ensuring compliance with best practices and enforcing security policies at runtime.</p>]]></content><author><name></name></author><category term="jekyll" /><category term="Cat2" /><summary type="html"><![CDATA[About kube-bench and OPA Gatekeeper]]></summary></entry><entry><title type="html">EKS Cluster Autoscaler and Horizontal Pod Autoscaler (HPA)</title><link href="http://localhost:4000/jekyll/cat2/2024/09/12/eks1.html" rel="alternate" type="text/html" title="EKS Cluster Autoscaler and Horizontal Pod Autoscaler (HPA)" /><published>2024-09-12T10:15:29+10:00</published><updated>2024-09-12T10:15:29+10:00</updated><id>http://localhost:4000/jekyll/cat2/2024/09/12/eks1</id><content type="html" xml:base="http://localhost:4000/jekyll/cat2/2024/09/12/eks1.html"><![CDATA[<p><b>Autoscaler and Horizontal Pod Autoscaler (HPA) Practice on EKS </b></p>

<p>In last post, I was able to deploy EKS cluster via Jenkins and Terraform:</p>

<ul>
  <li><a href="https://zackz.site/jekyll/cat2/2024/08/15/Jenkins-redo2-copy.html">Jenkins - Multi-Destnation Continuse Deployment with Terraform</a></li>
</ul>

<p>This post walks through the process of setting up an Autoscaler and Horizontal Pod Autoscaler (HPA) in an Amazon EKS cluster. We will explore how to dynamically scale the number of nodes in EKS cluster and how to autoscale K8S pods based on CPU utilization using HPA.</p>

<p>Prerequisites:</p>

<ul>
  <li>Use the <code class="language-plaintext highlighter-rouge">AWS CLI</code> to update kubeconfig so that kubectl can communicate with the EKS cluster</li>
</ul>

<figure class="highlight"><pre><code class="language-shell" data-lang="shell"><span class="nv">$ </span>aws eks <span class="nt">--region</span> ap-southeast-2 update-kubeconfig <span class="nt">--name</span> module-eks-cluster
Updated context arn:aws:eks:ap-southeast-2:851725491342:cluster/module-eks-cluster <span class="k">in </span>C:<span class="se">\U</span>sers<span class="se">\z</span>ack<span class="se">\.</span>kube<span class="se">\c</span>onfig

Verify that the nodes are ready:
<span class="nv">$ </span>kubectl.exe get node
NAME                                              STATUS   ROLES    AGE     VERSION
ip-172-31-37-57.ap-southeast-2.compute.internal   Ready    &lt;none&gt;   2m40s   v1.31.0-eks-a737599</code></pre></figure>

<ul>
  <li>Deploy the <code class="language-plaintext highlighter-rouge">Cluster Autoscaler</code> from the official Kubernetes Autoscaler GitHub repository, The Cluster Autoscaler automatically adjusts the number of nodes in eks cluster based on the resource requirements of the workloads.</li>
</ul>

<figure class="highlight"><pre><code class="language-shell" data-lang="shell"><span class="nv">$ </span>kubectl.exe apply <span class="nt">-f</span> https://raw.githubusercontent.com/kubernetes/autoscaler/refs/heads/master/cluster-autoscaler/cloudprovider/aws/examples/cluster-autoscaler-one-asg.yaml
serviceaccount/cluster-autoscaler created
clusterrole.rbac.authorization.k8s.io/cluster-autoscaler created
role.rbac.authorization.k8s.io/cluster-autoscaler created
clusterrolebinding.rbac.authorization.k8s.io/cluster-autoscaler created
rolebinding.rbac.authorization.k8s.io/cluster-autoscaler created
deployment.apps/cluster-autoscaler created</code></pre></figure>

<ul>
  <li>Modify the Autoscaler Parameters to tuning Scale-Up and Down Behavior.</li>
</ul>

<p>Customized Autoscaler parameters to add arguments to control the scaling behavior, such as the <code class="language-plaintext highlighter-rouge">minimum and maximum node counts</code>, the <code class="language-plaintext highlighter-rouge">time between scale-down events</code>, <code class="language-plaintext highlighter-rouge">stabilization window</code> and <code class="language-plaintext highlighter-rouge">cooldown period</code>.</p>

<figure class="highlight"><pre><code class="language-shell" data-lang="shell"><span class="nv">$ </span>kubectl <span class="nt">-n</span> kube-system edit deployment.apps/cluster-autoscaler
deployment.apps/cluster-autoscaler edited

      labels:
        app: cluster-autoscaler
    spec:
      containers:
      - <span class="nb">command</span>:
        - ./cluster-autoscaler
        - <span class="nt">--cluster-name</span><span class="o">=</span>module-eks-cluster
        - <span class="nt">--v</span><span class="o">=</span>4
        - <span class="nt">--stderrthreshold</span><span class="o">=</span>info
        - <span class="nt">--cloud-provider</span><span class="o">=</span>aws
        - <span class="nt">--skip-nodes-with-local-storage</span><span class="o">=</span><span class="nb">false</span>
        - <span class="nt">--balance-similar-node-groups</span>
        - <span class="nt">--skip-nodes-with-system-pods</span><span class="o">=</span><span class="nb">false</span>
        - <span class="nt">--scale-down-unneeded-time</span><span class="o">=</span>1m
        - <span class="nt">--scale-down-delay-after-add</span><span class="o">=</span>1m
        - <span class="nt">--nodes</span><span class="o">=</span>1:3:eks-module-eks-cluster-node-group-5ec93604-4bdc-a740-1fcc-707afc8431b</code></pre></figure>

<p><b>HPA testing based on Pod CPU utilization metric </b></p>

<ul>
  <li>Now, let’s deploy zackweb and set up an <code class="language-plaintext highlighter-rouge">Horizontal Pod Autoscaler (HPA)</code> to scale the number of pods based on CPU utilization.</li>
</ul>

<figure class="highlight"><pre><code class="language-shell" data-lang="shell"><span class="nv">$ </span><span class="nb">cat </span>deployment.yaml

apiVersion: apps/v1
kind: Deployment
metadata:
  name: zackblog
spec:
  replicas: 1  <span class="c"># Start with 1 replica</span>
  selector:
    matchLabels:
      app: zackblog
  template:
    metadata:
      labels:
        app: zackblog
    spec:
      containers:
      - name: zackblog
        image: zackz001/gitops-jekyll:latest
        resources:
          requests:
            cpu: <span class="s2">"500m"</span>  <span class="c"># 0.5 vCPU</span>
            memory: <span class="s2">"512Mi"</span>  <span class="c"># 0.5 GiB</span>
          limits:
            cpu: <span class="s2">"1"</span>  <span class="c"># 1 vCPU</span>
            memory: <span class="s2">"1Gi"</span>  <span class="c"># 1 GiB</span>
<span class="nt">---</span>
apiVersion: v1
kind: Service
metadata:
  name: zackblog
spec:
  selector:
    app: zackblog  <span class="c"># This must match the labels in the Deployment</span>
  ports:
    - protocol: TCP
      port: 80        <span class="c"># Port that the service will expose</span>
      targetPort: 80 <span class="c"># Port that the container listens on</span>
  <span class="nb">type</span>: LoadBalancer

kubectl.exe apply <span class="nt">-f</span> deployment.yaml
deployment.apps/zackblog created
service/zackblog created</code></pre></figure>

<ul>
  <li>Set Resource Requests and Limits, and Configure Horizontal Pod Autoscaler (HPA) to automatically scale the deployment based on CPU usage</li>
</ul>

<figure class="highlight"><pre><code class="language-shell" data-lang="shell"><span class="nv">$ </span>kubectl <span class="nb">set </span>resources deployment zackblog <span class="nt">--limits</span><span class="o">=</span><span class="nv">cpu</span><span class="o">=</span>200m,memory<span class="o">=</span>200Mi <span class="nt">--requests</span><span class="o">=</span><span class="nv">cpu</span><span class="o">=</span>100m,memory<span class="o">=</span>100Mi
deployment.apps/zackblog resource requirements updated

kubectl autoscale deployment zackblog <span class="nt">--cpu-percent</span><span class="o">=</span>50 <span class="nt">--min</span><span class="o">=</span>1 <span class="nt">--max</span><span class="o">=</span>3

<span class="nv">$ </span>kubectl get hpa zackblog
NAME       REFERENCE             TARGETS              MINPODS   MAXPODS   REPLICAS   AGE
zackblog   Deployment/zackblog   cpu: &lt;unknown&gt;/50%   1         3         1          18s</code></pre></figure>

<ul>
  <li>Generate CPU Load to Test the HPA</li>
</ul>

<p>To test the HPA, we need to generate CPU load by runing a busybox container to repeatedly request the zackblog service.</p>

<figure class="highlight"><pre><code class="language-shell" data-lang="shell">kubectl run <span class="nt">-i</span> <span class="nt">--tty</span> load-generator <span class="nt">--image</span><span class="o">=</span>busybox /bin/sh
<span class="c"># Inside the busybox shell, run this:</span>
<span class="k">while </span><span class="nb">true</span><span class="p">;</span> <span class="k">do </span>wget <span class="nt">-q</span> <span class="nt">-O-</span> http://zackblog <span class="o">&gt;</span> /dev/null<span class="p">;</span> <span class="nb">sleep </span>0.5<span class="p">;</span> <span class="k">done</span></code></pre></figure>

<ul>
  <li>Monitor the HPA and Scaling Events, As CPU utilization increases, the HPA will automatically scale the number of pods:</li>
</ul>

<figure class="highlight"><pre><code class="language-shell" data-lang="shell"><span class="nv">$ </span>kubectl.exe get po
NAME                       READY   STATUS             RESTARTS      AGE
load-generator             1/1     Running            0             2m6s
zackblog-95f746486-wlmgx   1/1     Running            0             6m20s

kubectl get hpa zackblog <span class="nt">-w</span>
NAME       REFERENCE             TARGETS       MINPODS   MAXPODS   REPLICAS   AGE
zackblog   Deployment/zackblog   cpu: 0%/50%   1         10        1          12m
zackblog   Deployment/zackblog   cpu: 92%/50%  1         10        2          5m
zackblog   Deployment/zackblog   cpu: 52%/50%  1         10        3          2m

kubectl get hpa zackblog <span class="nt">-w</span>
zackblog   Deployment/zackblog   cpu: 37%/50%   1         10        3          27m
zackblog   Deployment/zackblog   cpu: 38%/50%   1         10        3          27m
zackblog   Deployment/zackblog   cpu: 6%/50%    1         10        3          27m
zackblog   Deployment/zackblog   cpu: 0%/50%    1         10        3          27m
zackblog   Deployment/zackblog   cpu: 0%/50%    1         10        1          28m</code></pre></figure>

<p>It can be seen that pods got  scaled up to 3 when CPU utilization reached 92% and scaled down to 1 when CPU utilization dropped below 50%.</p>

<p><b>Testing EKS Cluster Autoscaler by changing deployment replicas: </b></p>

<p><code class="language-plaintext highlighter-rouge">EKS Cluster Autoscaler</code> comes with scale-in and scale-out policies, which define when nodes should be added or removed. The Cluster Autoscaler adds nodes when there aren’t enough resources to schedule pending pods and removes nodes when they are underutilized.</p>

<ul>
  <li>Change the resource limitation for zackblog deployment for EKS node autoscaler testing, Set zackweb deployment with requests cpu 500m. As the EKS node group with a t3.small instance type (2c2g), which means one node can only handle one pod, so to make the Autoscaler testing easier to achieve.</li>
</ul>

<figure class="highlight"><pre><code class="language-shell" data-lang="shell"><span class="nv">$ </span>vim deployment.yaml

        resources:
          requests:
            cpu: <span class="s2">"500m"</span>  <span class="c"># 0.5 vCPU</span>
            memory: <span class="s2">"512Mi"</span>  <span class="c"># 0.5 GiB</span>
          limits:
            cpu: <span class="s2">"1"</span>  <span class="c"># 1 vCPU</span>
            memory: <span class="s2">"1Gi"</span>  <span class="c"># 1 GiB</span></code></pre></figure>

<ul>
  <li>Gracefully increase the number of deployment replicas to 2, to test EKS node scale up</li>
</ul>

<figure class="highlight"><pre><code class="language-shell" data-lang="shell"><span class="nv">$ </span>kubectl scale deployment zackblog <span class="nt">--replicas</span><span class="o">=</span>2
deployment.apps/zackblog scaled

<span class="nv">$ </span>kubectl.exe get po
NAME                        READY   STATUS             RESTARTS      AGE
load-generator              1/1     Running            0             7m39s
zackblog-7f67584fbd-47jvt   1/1     Running            0             31s
zackblog-7f67584fbd-9gtfn   0/1     Pending            0             6s

<span class="nv">$ </span>kubectl.exe describe po zackblog-7f67584fbd-9gtfn

Events:
  Type     Reason            Age   From                Message
  <span class="nt">----</span>     <span class="nt">------</span>            <span class="nt">----</span>  <span class="nt">----</span>                <span class="nt">-------</span>
  Warning  FailedScheduling  18s   default-scheduler   0/1 nodes are available: 1 Insufficient memory. preemption: 0/1 nodes are available: 1 No preemption victims found <span class="k">for </span>incoming pod.
  Normal   TriggeredScaleUp  9s    cluster-autoscaler  pod triggered scale-up: <span class="o">[{</span>eks-module-eks-cluster-node-group-5ec93604-4bdc-a740-1fcc-707afc8431b3 1-&gt;2 <span class="o">(</span>max: 3<span class="o">)}]</span>

<span class="nv">$ </span>kubectl.exe get node
NAME                                               STATUS   ROLES    AGE   VERSION
ip-172-31-15-152.ap-southeast-2.compute.internal   Ready    &lt;none&gt;   31s   v1.31.0-eks-a737599
ip-172-31-37-57.ap-southeast-2.compute.internal    Ready    &lt;none&gt;   37m   v1.31.0-eks-a737599

<span class="nv">$ </span>kubectl.exe get po
NAME                        READY   STATUS             RESTARTS        AGE
load-generator              1/1     Running            0               9m14s
zackblog-7f67584fbd-47jvt   1/1     Running            0               2m6s
zackblog-7f67584fbd-9gtfn   1/1     Running            0               101s</code></pre></figure>

<p>It can be seen that pod <code class="language-plaintext highlighter-rouge">zackblog-7f67584fbd-9gtfn</code> was in pending state due to waiting for node to be scale-up, once we have 2 nodes in EKS cluster, that pod can be scheduled and run.</p>

<ul>
  <li>Increase the number of deployment replicas to 3, to trigger EKS node scale up again</li>
</ul>

<figure class="highlight"><pre><code class="language-shell" data-lang="shell"><span class="nv">$ </span>kubectl scale deployment zackblog <span class="nt">--replicas</span><span class="o">=</span>3
deployment.apps/zackblog scaled

<span class="nv">$ </span>kubectl.exe get po
NAME                        READY   STATUS             RESTARTS        AGE
load-generator              1/1     Running            0               9m44s
zackblog-7f67584fbd-47jvt   1/1     Running            0               2m36s
zackblog-7f67584fbd-9gtfn   1/1     Running            0               2m11s
zackblog-7f67584fbd-f5s9d   1/1     Running            0               3s


<span class="nv">$ </span>kubectl.exe get po <span class="nt">-o</span> wide
NAME                        READY   STATUS    RESTARTS   AGE     IP              NODE                                               NOMINATED NODE   READINESS GATES
zackblog-7f67584fbd-47jvt   1/1     Running   0          5m58s   172.31.37.227   ip-172-31-37-57.ap-southeast-2.compute.internal    &lt;none&gt;           &lt;none&gt;
zackblog-7f67584fbd-9gtfn   1/1     Running   0          5m33s   172.31.5.139    ip-172-31-15-152.ap-southeast-2.compute.internal   &lt;none&gt;           &lt;none&gt;
zackblog-7f67584fbd-vzcx4   1/1     Running   0          2m3s    172.31.18.111   ip-172-31-20-24.ap-southeast-2.compute.internal    &lt;none&gt;           &lt;none&gt;</code></pre></figure>

<p>Now EKS scale up to 3 nodes to handle the replica increase again.</p>

<ul>
  <li>Change the number of deployment replicas down to 1, to trigger EKS node scale down, and monitor by autoscaler log file to see the scale down behavior:</li>
</ul>

<figure class="highlight"><pre><code class="language-shell" data-lang="shell"><span class="nv">$ </span>kubectl scale deployment zackblog <span class="nt">--replicas</span><span class="o">=</span>1

<span class="nv">$ </span>kubectl <span class="nt">-n</span> kube-system logs <span class="nt">-f</span> deployment/cluster-autoscaler

I1008 12:53:22.686377       1 static_autoscaler.go:598] Starting scale down
I1008 12:53:22.686430       1 nodes.go:123] ip-172-31-15-152.ap-southeast-2.compute.internal was unneeded <span class="k">for </span>40.253885622s
I1008 12:53:22.686452       1 nodes.go:123] ip-172-31-37-57.ap-southeast-2.compute.internal was unneeded <span class="k">for </span>1m0.362059191s
I1008 12:53:22.686502       1 cluster.go:153] ip-172-31-37-57.ap-southeast-2.compute.internal <span class="k">for </span>removal
I1008 12:53:22.686644       1 hinting_simulator.go:77] Pod kube-system/cluster-autoscaler-5767f77d77-xgfjq can be moved to ip-172-31-20-24.ap-southeast-2.compute.internal
I1008 12:53:22.686717       1 hinting_simulator.go:77] Pod kube-system/coredns-7575495454-9n6kd can be moved to ip-172-31-15-152.ap-southeast-2.compute.internal
I1008 12:53:22.686832       1 hinting_simulator.go:77] Pod kube-system/coredns-7575495454-dxzdc can be moved to ip-172-31-15-152.ap-southeast-2.compute.internal
I1008 12:53:22.686875       1 cluster.go:176] node ip-172-31-37-57.ap-southeast-2.compute.internal may be removed
I1008 12:53:22.705270       1 delete.go:103] Successfully added ToBeDeletedTaint on node ip-172-31-37-57.ap-southeast-2.compute.internal
I1008 12:53:22.705367       1 actuator.go:212] Scale-down: removing node ip-172-31-37-57.ap-southeast-2.compute.internal, utilization: <span class="o">{</span>0.23316062176165803 0.49755477462428627 0 memory 0.49755477462428627<span class="o">}</span>, pods to reschedule: cluster-autoscaler-5767f77d77-xgfjq,coredns-7575495454-9n6kd,coredns-7575495454-dxzdc

<span class="nv">$ </span>kubectl.exe get node
NAME                                               STATUS                        ROLES    AGE     VERSION
ip-172-31-15-152.ap-southeast-2.compute.internal   NotReady,SchedulingDisabled   &lt;none&gt;   9m10s   v1.31.0-eks-a737599
ip-172-31-20-24.ap-southeast-2.compute.internal    Ready                         &lt;none&gt;   6m59s   v1.31.0-eks-a737599
ip-172-31-37-57.ap-southeast-2.compute.internal    Ready,SchedulingDisabled      &lt;none&gt;   45m     v1.31.0-eks-a737599

<span class="nv">$ </span>kubectl.exe get node
NAME                                              STATUS   ROLES    AGE     VERSION
ip-172-31-20-24.ap-southeast-2.compute.internal   Ready    &lt;none&gt;   7m58s   v1.31.0-eks-a737599</code></pre></figure>

<p>It can be seen that Cluster Autoscaler identified nodes that were underutilized or idle and marked them as “unneeded.”
It simulated moving the existing pods to other nodes. Once it determined that the pods could be rescheduled, it marked the node for deletion (using a ToBeDeletedTaint), preventing new workloads from being scheduled. Finally, the node was removed from the cluster, and the pods were successfully rescheduled on other nodes.</p>

<p>This behavior ensures that the cluster’s resources are used efficiently, scaling down when there is no workload, thereby reducing costs.</p>

<p><img src="/assets/eks1.png" alt="image tooltip here" /></p>

<p><b> Conclusion: </b></p>

<p>By following these steps, we can effectively manage the scaling of k8s applications and nodes in an EKS cluster using both the Cluster Autoscaler and Horizontal Pod Autoscaler (HPA). These tools ensure that the infrastructure adapts to varying workloads, optimizing resource utilization and costs.</p>]]></content><author><name></name></author><category term="jekyll" /><category term="Cat2" /><summary type="html"><![CDATA[Autoscaler and Horizontal Pod Autoscaler (HPA) Practice on EKS]]></summary></entry><entry><title type="html">Jenkins - Multi-Destination Continuous Deployment with Terraform</title><link href="http://localhost:4000/jekyll/cat2/2024/08/15/Jenkins-redo2-copy.html" rel="alternate" type="text/html" title="Jenkins - Multi-Destination Continuous Deployment with Terraform" /><published>2024-08-15T10:15:29+10:00</published><updated>2024-08-15T10:15:29+10:00</updated><id>http://localhost:4000/jekyll/cat2/2024/08/15/Jenkins-redo2%20copy</id><content type="html" xml:base="http://localhost:4000/jekyll/cat2/2024/08/15/Jenkins-redo2-copy.html"><![CDATA[<p><b>Jenkins CD Pipeline Design</b></p>

<p>In last post, I was able to create a Jenkins Universal CI Pipeline to create blog docker image and push to DockerHub:</p>

<p><a href="https://zackz.site/jekyll/cat2/2024/08/02/Jenkins-redo1-copy.html">Jenkins - Universal CI Pipeline with Ansible &amp; Terraform</a></p>

<p>Now it is time to design the continuous deployment pipeline with Ansible and Terrofrm for infrustructure provision and application configration and deployment.</p>

<ul>
  <li>Continuous Deployment Consideration</li>
</ul>

<p>Continuous deployment will be more terraform focused. Starting Jenkins CD pipeline with single EC2 instance deployment for Blog website.  The pipeline can be reusable for multiple destinations in later design (EC2, ECS, EKS). At the moment, this EC2 deployment can be achieved via bellow folder structure:</p>

<ol>
  <li>Jenkins CD pipeline with muti-stage</li>
  <li>Terraform to provision AWS EC2</li>
  <li>Ansible to configure docker and deploy blog</li>
  <li>Validate Web Blog Access:</li>
  <li>Delete Terraform Resources</li>
</ol>

<figure class="highlight"><pre><code class="language-shell" data-lang="shell"><span class="c"># Tree</span>
terraform-ec2# tree
<span class="nb">.</span>
├── Jenkinsfile  <span class="c"># the CD pipeline file </span>
├── deploy-docker-playbook.yml <span class="c"># the Ansible playbook for ec2 webblog deployment </span>
├── hosts <span class="c"># the Ansible inventory file</span>
├── main.tf <span class="c"># the terraform file to provison AWS EC2 </span>
├── test-playbook.yaml <span class="c"># the playbook for Ansible testing and validation </span>
└── variables.tf the terraform var file to provison AWS EC2 </code></pre></figure>

<ul>
  <li>The CD pipeline design</li>
</ul>

<p>This Jenkins CD (Continuous Deployment) pipeline covers the following task:</p>

<ol>
  <li>Jenkins Cred and Environment Setup</li>
  <li>Check Installed Package Versions (AWSCli, Ansible, Terraform)</li>
  <li>Validate Ansible and AWS credential</li>
  <li>Run Terraform Initialization and Apply</li>
  <li>Validate EC2 Readiness and then Deploy Docker Using Ansible</li>
  <li>Validate Web Blog Access by extract EC2 public IP</li>
  <li>Delete Terraform Resources</li>
</ol>

<p>Jenkinsfile</p>

<figure class="highlight"><pre><code class="language-shell" data-lang="shell"><span class="c">#  Jenkinsfile</span>
pipeline <span class="o">{</span>
    agent any
    environment <span class="o">{</span>
        IMAGE_NAME <span class="o">=</span> <span class="s2">"zackz001/jenkins"</span>
        IMAGE_TAG <span class="o">=</span> <span class="s2">"</span><span class="k">${</span><span class="nv">env</span><span class="p">.BUILD_NUMBER</span><span class="k">}</span><span class="s2">"</span>
        LATEST_TAG <span class="o">=</span> <span class="s2">"latest"</span>
        EMAIL_RECIPIENT <span class="o">=</span> <span class="s2">"zhbsoftboy1@gmail.com"</span>
        GIT_REPO_URL <span class="o">=</span> <span class="s1">'https://github.com/ZackZhouHB/zack-gitops-project.git'</span>  // Git repository URL
        GIT_BRANCH <span class="o">=</span> <span class="s1">'jenkins-cd'</span>  // Git branch
        DOCKERHUB_CREDENTIALS_ID <span class="o">=</span> <span class="s1">'dockerhub'</span> // Docker Hub credentials
        REGION <span class="o">=</span> <span class="s1">'ap-southeast-2'</span>  // AWS region
    <span class="o">}</span>
    stages <span class="o">{</span>
        stage<span class="o">(</span><span class="s1">'Clean Workspace'</span><span class="o">)</span> <span class="o">{</span>
            steps <span class="o">{</span>
                cleanWs<span class="o">()</span>
            <span class="o">}</span>
       <span class="o">}</span>
        stage<span class="o">(</span><span class="s1">'Checkout Code'</span><span class="o">)</span> <span class="o">{</span>
            steps <span class="o">{</span>
                git branch: <span class="s2">"</span><span class="k">${</span><span class="nv">GIT_BRANCH</span><span class="k">}</span><span class="s2">"</span>,
                    credentialsId: <span class="s1">'gittoken'</span>,
                    url: <span class="s2">"</span><span class="k">${</span><span class="nv">GIT_REPO_URL</span><span class="k">}</span><span class="s2">"</span>
            <span class="o">}</span>
        <span class="o">}</span>
        stage<span class="o">(</span><span class="s1">'Check Installed Package Versions'</span><span class="o">)</span> <span class="o">{</span>
            steps <span class="o">{</span>
                script <span class="o">{</span>
                    try <span class="o">{</span>
                        // Check Docker version
                        sh <span class="s1">'''
                            if command -v docker &gt;/dev/null 2&gt;&amp;1; then
                                echo "Docker Version: $(docker --version)"
                            else
                                echo "Docker is not installed"
                                exit 1
                            fi
                        '''</span>
                    <span class="o">}</span> catch <span class="o">(</span>Exception e<span class="o">)</span> <span class="o">{</span>
                        <span class="nb">echo</span> <span class="s2">"Error: Docker not found. </span><span class="k">${</span><span class="nv">e</span><span class="p">.message</span><span class="k">}</span><span class="s2">"</span>
                    <span class="o">}</span>

                    try <span class="o">{</span>
                        // Check Terraform version
                        sh <span class="s1">'''
                            if command -v terraform &gt;/dev/null 2&gt;&amp;1; then
                                echo "Terraform Version: $(terraform -version)"
                            else
                                echo "Terraform is not installed"
                                exit 1
                            fi
                        '''</span>
                    <span class="o">}</span> catch <span class="o">(</span>Exception e<span class="o">)</span> <span class="o">{</span>
                        <span class="nb">echo</span> <span class="s2">"Error: Terraform not found. </span><span class="k">${</span><span class="nv">e</span><span class="p">.message</span><span class="k">}</span><span class="s2">"</span>
                    <span class="o">}</span>

                    try <span class="o">{</span>
                        // Check Kubectl version
                        sh <span class="s1">'''
                            if command -v kubectl &gt;/dev/null 2&gt;&amp;1; then
                                echo "Kubectl Version: $(kubectl version --client)"
                            else
                                echo "Kubectl is not installed"
                                exit 1
                            fi
                        '''</span>
                    <span class="o">}</span> catch <span class="o">(</span>Exception e<span class="o">)</span> <span class="o">{</span>
                        <span class="nb">echo</span> <span class="s2">"Error: Kubectl not found. </span><span class="k">${</span><span class="nv">e</span><span class="p">.message</span><span class="k">}</span><span class="s2">"</span>
                    <span class="o">}</span>

                    try <span class="o">{</span>
                        // Check Trivy version
                        sh <span class="s1">'''
                            if command -v trivy &gt;/dev/null 2&gt;&amp;1; then
                                echo "Trivy Version: $(trivy --version)"
                            else
                                echo "Trivy is not installed"
                                exit 1
                            fi
                        '''</span>
                    <span class="o">}</span> catch <span class="o">(</span>Exception e<span class="o">)</span> <span class="o">{</span>
                        <span class="nb">echo</span> <span class="s2">"Error: Trivy not found. </span><span class="k">${</span><span class="nv">e</span><span class="p">.message</span><span class="k">}</span><span class="s2">"</span>
                    <span class="o">}</span>

                    try <span class="o">{</span>
                        // Check Ansible version
                        sh <span class="s1">'''
                            if command -v ansible &gt;/dev/null 2&gt;&amp;1; then
                                echo "Ansible Version: $(ansible --version)"
                            else
                                echo "Ansible is not installed"
                                exit 1
                            fi
                        '''</span>
                    <span class="o">}</span> catch <span class="o">(</span>Exception e<span class="o">)</span> <span class="o">{</span>
                        <span class="nb">echo</span> <span class="s2">"Error: Ansible not found. </span><span class="k">${</span><span class="nv">e</span><span class="p">.message</span><span class="k">}</span><span class="s2">"</span>
                    <span class="o">}</span>

                    try <span class="o">{</span>
                        // Check AWS CLI version
                        sh <span class="s1">'''
                            if command -v aws &gt;/dev/null 2&gt;&amp;1; then
                                echo "AWS CLI Version: $(aws --version)"
                            else
                                echo "AWS CLI is not installed"
                                exit 1
                            fi
                        '''</span>
                    <span class="o">}</span> catch <span class="o">(</span>Exception e<span class="o">)</span> <span class="o">{</span>
                        <span class="nb">echo</span> <span class="s2">"Error: AWS CLI not found. </span><span class="k">${</span><span class="nv">e</span><span class="p">.message</span><span class="k">}</span><span class="s2">"</span>
                    <span class="o">}</span>
                <span class="o">}</span>
            <span class="o">}</span>
        <span class="o">}</span>
        stage<span class="o">(</span><span class="s1">'Run a testing Ansible Playbook'</span><span class="o">)</span> <span class="o">{</span>
            steps <span class="o">{</span>
                script <span class="o">{</span>
                    // Run the Ansible playbook using the hosts file from the repo
                    sh <span class="s1">'''
                        echo "Running Ansible playbook:"
                        ansible-playbook -i "${WORKSPACE}/jenkins/terraform-ec2/hosts" "${WORKSPACE}/jenkins/terraform-ec2/test-playbook.yaml"
                    '''</span>
                <span class="o">}</span>
            <span class="o">}</span>
        <span class="o">}</span>
        stage<span class="o">(</span><span class="s1">'Verify AWS credential'</span><span class="o">)</span> <span class="o">{</span>
            steps <span class="o">{</span>
                withAWS<span class="o">(</span>credentials: <span class="s1">'aws'</span>, region: <span class="s1">'ap-southeast-2'</span><span class="o">)</span> <span class="o">{</span> // Replace with correct AWS credentials ID
                    script <span class="o">{</span>
                        // List all existing S3 buckets and output the result to the Jenkins console
                        sh <span class="s1">'''
                            echo "Listing all S3 buckets:"
                            aws s3 ls
                        '''</span>
                    <span class="o">}</span>
                <span class="o">}</span>
            <span class="o">}</span>
        <span class="o">}</span>
        stage<span class="o">(</span><span class="s1">'Terraform Init and Apply'</span><span class="o">)</span> <span class="o">{</span>
            steps <span class="o">{</span>
                withCredentials<span class="o">([[</span><span class="nv">$class</span>: <span class="s1">'AmazonWebServicesCredentialsBinding'</span>, credentialsId: <span class="s1">'aws'</span><span class="o">]])</span> <span class="o">{</span>
                    sh <span class="s1">'''
                        export AWS_ACCESS_KEY_ID=${AWS_ACCESS_KEY_ID}
                        export AWS_SECRET_ACCESS_KEY=${AWS_SECRET_ACCESS_KEY}
                        cd jenkins/terraform-ec2

                        # Check if Terraform has been initialized
                        if [ ! -d ".terraform" ]; then
                            echo "Terraform not initialized. Running '</span>terraform init<span class="s1">'..."
                            terraform init
                        else
                            echo "Terraform already initialized. Skipping '</span>terraform init<span class="s1">'."
                        fi

                        terraform apply -auto-approve -var "aws_region=${REGION}"
                    '''</span>
                <span class="o">}</span>
            <span class="o">}</span>
        <span class="o">}</span>
        // Stage to extract EC2 public IP
        stage<span class="o">(</span><span class="s1">'Extract EC2 Public IP'</span><span class="o">)</span> <span class="o">{</span>
            steps <span class="o">{</span>
                withCredentials<span class="o">([[</span><span class="nv">$class</span>: <span class="s1">'AmazonWebServicesCredentialsBinding'</span>, credentialsId: <span class="s1">'aws'</span><span class="o">]])</span> <span class="o">{</span>
                    script <span class="o">{</span>
                        def ec2Ip <span class="o">=</span> sh<span class="o">(</span>script: <span class="s1">'''
                            cd jenkins/terraform-ec2
                            terraform output -raw ec2_public_ip
                        '''</span>, returnStdout: <span class="nb">true</span><span class="o">)</span>.trim<span class="o">()</span>
                        <span class="nb">echo</span> <span class="s2">"EC2 Public IP: </span><span class="k">${</span><span class="nv">ec2Ip</span><span class="k">}</span><span class="s2">"</span>
                        // Set the environment variable <span class="k">for </span>the next stages explicitly
                        env.EC2_PUBLIC_IP <span class="o">=</span> ec2Ip
                    <span class="o">}</span>
                <span class="o">}</span>
            <span class="o">}</span>
        <span class="o">}</span>

        // <span class="k">**</span>Fix: Adding a small <span class="nb">sleep </span>to ensure <span class="nb">env </span>is populated<span class="k">**</span>
        stage<span class="o">(</span><span class="s1">'Validate EC2 Public IP'</span><span class="o">)</span> <span class="o">{</span>
            steps <span class="o">{</span>
                script <span class="o">{</span>
                    <span class="nb">sleep </span>2 // Ensure enough <span class="nb">time </span><span class="k">for </span>variable propagation
                    <span class="k">if</span> <span class="o">(</span>env.EC2_PUBLIC_IP <span class="o">==</span> null <span class="o">||</span> env.EC2_PUBLIC_IP <span class="o">==</span> <span class="s2">""</span><span class="o">)</span> <span class="o">{</span>
                        error <span class="s2">"EC2 Public IP is not available or failed to fetch."</span>
                    <span class="o">}</span> <span class="k">else</span> <span class="o">{</span>
                        <span class="nb">echo</span> <span class="s2">"EC2 Public IP is successfully fetched: </span><span class="k">${</span><span class="nv">env</span><span class="p">.EC2_PUBLIC_IP</span><span class="k">}</span><span class="s2">"</span>
                    <span class="o">}</span>
                <span class="o">}</span>
            <span class="o">}</span>
        <span class="o">}</span>

        // Wait <span class="k">for </span>EC2 Readiness <span class="o">(</span>SSH Validation<span class="o">)</span>
        stage<span class="o">(</span><span class="s1">'Wait for EC2 Readiness'</span><span class="o">)</span> <span class="o">{</span>
            steps <span class="o">{</span>
                retry<span class="o">(</span>20<span class="o">)</span> <span class="o">{</span> // Retry up to 4 <span class="nb">times </span><span class="k">in case</span> EC2 is not immediately ready
                    <span class="nb">sleep </span>2  // Wait <span class="k">for </span>a bit before checking readiness
                    withCredentials<span class="o">([</span>sshUserPrivateKey<span class="o">(</span>credentialsId: <span class="s1">'sshkey'</span>, keyFileVariable: <span class="s1">'SSH_KEY'</span><span class="p">)</span><span class="o">])</span> <span class="o">{</span>
                        script <span class="o">{</span>
                            sh <span class="s2">"ssh -o StrictHostKeyChecking=no -i </span><span class="k">${</span><span class="nv">SSH_KEY</span><span class="k">}</span><span class="s2"> ubuntu@</span><span class="k">${</span><span class="nv">env</span><span class="p">.EC2_PUBLIC_IP</span><span class="k">}</span><span class="s2"> 'echo EC2 is ready for deployment'"</span>
                        <span class="o">}</span>
                    <span class="o">}</span>
                <span class="o">}</span>
            <span class="o">}</span>
        <span class="o">}</span>

        // Deploy Docker using Ansible
        stage<span class="o">(</span><span class="s1">'Deploy Docker with Ansible'</span><span class="o">)</span> <span class="o">{</span>
            steps <span class="o">{</span>
                withCredentials<span class="o">([</span>sshUserPrivateKey<span class="o">(</span>credentialsId: <span class="s1">'sshkey'</span>, keyFileVariable: <span class="s1">'SSH_KEY'</span><span class="o">)])</span> <span class="o">{</span>
                    script <span class="o">{</span>
                        sh <span class="s1">'''
                            echo "Running Ansible Playbook for Docker Deployment..."
                            ansible-playbook -i "${EC2_PUBLIC_IP}," "${WORKSPACE}/jenkins/terraform-ec2/deploy-docker-playbook.yml" \
                            --user ubuntu \
                            --private-key ${SSH_KEY} \
                            --extra-vars "ansible_ssh_private_key_file=${SSH_KEY} ec2_ip=${EC2_PUBLIC_IP}"
                        '''</span>
                    <span class="o">}</span>
                <span class="o">}</span>
            <span class="o">}</span>
        <span class="o">}</span>
        // New stage: Validate web blog accessibility
        stage<span class="o">(</span><span class="s1">'Validate Web Blog Access'</span><span class="o">)</span> <span class="o">{</span>
            steps <span class="o">{</span>
                script <span class="o">{</span>
                    <span class="nb">echo</span> <span class="s2">"Validating web blog access via http://</span><span class="k">${</span><span class="nv">env</span><span class="p">.EC2_PUBLIC_IP</span><span class="k">}</span><span class="s2">..."</span>

                    // Use curl to validate HTTP response from the web blog
                    def response <span class="o">=</span> sh<span class="o">(</span>script: <span class="s2">"curl -o /dev/null -s -w '%{http_code}' http://</span><span class="k">${</span><span class="nv">env</span><span class="p">.EC2_PUBLIC_IP</span><span class="k">}</span><span class="s2">"</span>, returnStdout: <span class="nb">true</span><span class="o">)</span>.trim<span class="o">()</span>

                    <span class="k">if</span> <span class="o">(</span>response <span class="o">==</span> <span class="s1">'200'</span><span class="o">)</span> <span class="o">{</span>
                        <span class="nb">echo</span> <span class="s2">"Web blog is accessible and returned HTTP status code 200."</span>
                    <span class="o">}</span> <span class="k">else</span> <span class="o">{</span>
                        error <span class="s2">"Web blog is not accessible. HTTP status code: </span><span class="k">${</span><span class="nv">response</span><span class="k">}</span><span class="s2">"</span>
                    <span class="o">}</span>
                <span class="o">}</span>
            <span class="o">}</span>
        <span class="o">}</span> 
        stage<span class="o">(</span><span class="s1">'delete terraform resource'</span><span class="o">)</span> <span class="o">{</span>
            steps <span class="o">{</span>
                withCredentials<span class="o">([[</span><span class="nv">$class</span>: <span class="s1">'AmazonWebServicesCredentialsBinding'</span>, credentialsId: <span class="s1">'aws'</span><span class="o">]])</span> <span class="o">{</span>
                    sh <span class="s1">'''
                        export AWS_ACCESS_KEY_ID=${AWS_ACCESS_KEY_ID}
                        export AWS_SECRET_ACCESS_KEY=${AWS_SECRET_ACCESS_KEY}
                        cd jenkins/terraform-ec2

                        # Check if Terraform has been initialized
                        if [ ! -d ".terraform" ]; then
                            echo "Terraform not initialized. Running '</span>terraform init<span class="s1">'..."
                            terraform init
                        else
                            echo "Terraform already initialized. Skipping '</span>terraform init<span class="s1">'."
                        fi

                        terraform destroy -auto-approve -var "aws_region=${REGION}"
                    '''</span>
                <span class="o">}</span>
            <span class="o">}</span>
        <span class="o">}</span>                   
    <span class="o">}</span>
    post <span class="o">{</span>
        success <span class="o">{</span>
            <span class="nb">echo</span> <span class="s2">"Pipeline completed successfully."</span>
        <span class="o">}</span>
        failure <span class="o">{</span>
            <span class="nb">echo</span> <span class="s2">"Pipeline failed."</span>
        <span class="o">}</span>
    <span class="o">}</span>
<span class="o">}</span></code></pre></figure>

<p>Terraform main.tf</p>

<figure class="highlight"><pre><code class="language-shell" data-lang="shell"><span class="c"># Terraform main.tf</span>

provider <span class="s2">"aws"</span> <span class="o">{</span>
  region <span class="o">=</span> <span class="s2">"ap-southeast-2"</span>
<span class="o">}</span>

terraform <span class="o">{</span>
  backend <span class="s2">"s3"</span> <span class="o">{</span>
    bucket         <span class="o">=</span> <span class="s2">"zz-lambda-tag"</span>
    key            <span class="o">=</span> <span class="s2">"terraform/state/terraform.tfstate"</span>
    region         <span class="o">=</span> <span class="s2">"ap-southeast-2"</span>
    encrypt        <span class="o">=</span> <span class="nb">true</span>
  <span class="o">}</span>
<span class="o">}</span>

<span class="c"># Security Group Data</span>
data <span class="s2">"aws_security_group"</span> <span class="s2">"existing_sg"</span> <span class="o">{</span>
  filter <span class="o">{</span>
    name   <span class="o">=</span> <span class="s2">"group-name"</span>
    values <span class="o">=</span> <span class="o">[</span><span class="s2">"launch-wizard-1"</span><span class="o">]</span>
  <span class="o">}</span>
<span class="o">}</span>

<span class="c"># Key Pair Data</span>
data <span class="s2">"aws_key_pair"</span> <span class="s2">"existing_key"</span> <span class="o">{</span>
  key_name <span class="o">=</span> <span class="s2">"zzzzzzzzzzzz"</span>
<span class="o">}</span>

<span class="c"># EC2 Instance Definition</span>
resource <span class="s2">"aws_instance"</span> <span class="s2">"web"</span> <span class="o">{</span>
  ami           <span class="o">=</span> <span class="s2">"ami-040e71e7b8391cae4"</span> <span class="c"># Choose AMI</span>
  instance_type <span class="o">=</span> <span class="s2">"t2.micro"</span>
  key_name      <span class="o">=</span> data.aws_key_pair.existing_key.key_name
  security_groups <span class="o">=</span> <span class="o">[</span>
    data.aws_security_group.existing_sg.name
  <span class="o">]</span>

  tags <span class="o">=</span> <span class="o">{</span>
    Name <span class="o">=</span> <span class="s2">"Jenkins-EC2"</span>
  <span class="o">}</span>
<span class="o">}</span>

<span class="c"># Output EC2 Public IP</span>
output <span class="s2">"ec2_public_ip"</span> <span class="o">{</span>
  value <span class="o">=</span> aws_instance.web.public_ip
<span class="o">}</span></code></pre></figure>

<p>Ansible Playbook deploy-docker-playbook.yml</p>

<figure class="highlight"><pre><code class="language-shell" data-lang="shell"><span class="c"># Ansible Playbook for EC2 web blog deployment</span>
<span class="nt">---</span>
- hosts: all
  become: <span class="nb">yes
  </span>tasks:
  
    - name: Check <span class="k">if </span>Docker is already installed
      <span class="nb">command</span>: docker <span class="nt">--version</span>
      register: docker_installed
      ignore_errors: <span class="nb">yes
      </span>changed_when: <span class="nb">false</span>

    - name: Install required packages <span class="o">(</span><span class="k">if </span>Docker is not installed<span class="o">)</span>
      apt:
        name: 
          - apt-transport-https
          - ca-certificates
          - curl
          - software-properties-common
        state: present
        update_cache: <span class="nb">yes
      </span>when: docker_installed.rc <span class="o">!=</span> 0

    - name: Add Docker<span class="s1">'s official GPG key (if Docker is not installed)
      apt_key:
        url: https://download.docker.com/linux/ubuntu/gpg
        state: present
      when: docker_installed.rc != 0

    - name: Add Docker'</span>s official APT repository <span class="o">(</span><span class="k">if </span>Docker is not installed<span class="o">)</span>
      apt_repository:
        repo: deb <span class="o">[</span><span class="nb">arch</span><span class="o">=</span>amd64] https://download.docker.com/linux/ubuntu  stable
        state: present
      when: docker_installed.rc <span class="o">!=</span> 0

    - name: Update APT cache <span class="o">(</span><span class="k">if </span>Docker is not installed<span class="o">)</span>
      apt:
        update_cache: <span class="nb">yes
      </span>when: docker_installed.rc <span class="o">!=</span> 0

    - name: Install Docker CE <span class="o">(</span><span class="k">if </span>Docker is not installed<span class="o">)</span>
      apt:
        name: docker-ce
        state: present
        update_cache: <span class="nb">yes
      </span>when: docker_installed.rc <span class="o">!=</span> 0

    - name: Start and <span class="nb">enable </span>Docker service
      systemd:
        name: docker
        enabled: <span class="nb">yes
        </span>state: started

    - name: Stop all running containers
      shell: docker stop <span class="si">$(</span>docker ps <span class="nt">-q</span><span class="si">)</span>
      ignore_errors: <span class="nb">true
      </span>register: stopped_containers

    - name: Remove all stopped containers
      shell: docker <span class="nb">rm</span> <span class="si">$(</span>docker ps <span class="nt">-a</span> <span class="nt">-q</span><span class="si">)</span>
      when: stopped_containers.rc <span class="o">==</span> 0
      ignore_errors: <span class="nb">true</span>

    - name: Pull Docker image
      docker_image:
        name: zackz001/gitops-jekyll
        tag: latest
        <span class="nb">source</span>: pull

    - name: Run Docker container
      docker_container:
        name: zackblog
        image: zackz001/gitops-jekyll:latest
        state: started
        restart_policy: unless-stopped
        published_ports:
          - <span class="s2">"80:80"</span></code></pre></figure>

<ul>
  <li>Pipeline debug and testing</li>
</ul>

<p>After thorough testing and validation, the CD pipeline also works like a charm.</p>

<p><img src="/assets/jenkins2.png" alt="image tooltip here" /></p>

<p><b>Terraform Modularization for Multi-Destination Deployment</b></p>

<p>The folder structure bellow is designed to organize Infrastructure as Code (IaC) using Terraform, breaking down the configuration into reusable modules for ECS, EKS, and EC2 deployments, along with different environments (production, stage, etc.). So The Jenkins reusable CD pipeline can manage multi-destination deployments based on this structure.</p>

<ol>
  <li>Single EC2 deployment</li>
  <li>Single ECS deployment</li>
  <li>Terraform ECS Module with multi-environment deployment (production and stage)</li>
  <li>Terraform single EKS deployment</li>
  <li>Terraform EKS Module with multi-environment deployment (production and stage)</li>
</ol>

<figure class="highlight"><pre><code class="language-shell" data-lang="shell">root@zackz:~/zack-gitops-project/jenkins# tree

├── terraform-ec2
│   ├── Jenkinsfile
│   ├── deploy-docker-playbook.yml
│   ├── hosts
│   ├── main.tf
│   ├── test-playbook.yaml
│   └── variables.tf

├── module-ecs-cluster
│   ├── Jenkinsfile
│   ├── main.tf
│   ├── modules
│   │   ├── alb
│   │   │   ├── main.tf
│   │   │   ├── outputs.tf
│   │   │   └── variables.tf
│   │   ├── ecs_cluster
│   │   │   ├── main.tf
│   │   │   ├── outputs.tf
│   │   │   └── variables.tf
│   │   ├── ecs_service
│   │   │   ├── main.tf
│   │   │   ├── outputs.tf
│   │   │   └── variables.tf
│   │   ├── iam
│   │   │   ├── main.tf
│   │   │   ├── outputs.tf
│   │   │   └── variables.tf
│   │   ├── security_groups
│   │   │   ├── main.tf
│   │   │   ├── outputs.tf
│   │   │   └── variables.tf
│   │   └── task_definition
│   │       ├── main.tf
│   │       ├── outputs.tf
│   │       └── variables.tf
│   ├── outputs.tf
│   ├── terraform.tfstate
│   ├── terraform.tfstate.backup
│   ├── terraform.tfvars
│   └── variables.tf

├── module-ecs-env
│   ├── environments
│   │   ├── production
│   │   │   ├── Jenkinsfile
│   │   │   ├── backend.tf
│   │   │   ├── main.tf
│   │   │   ├── outputs.tf
│   │   │   ├── terraform.tfvars
│   │   │   └── variables.tf
│   │   └── stage
│   │       ├── Jenkinsfile
│   │       ├── backend.tf
│   │       ├── main.tf
│   │       ├── outputs.tf
│   │       ├── terraform.tfvars
│   │       └── variables.tf
│   └── modules
│       ├── alb
│       │   ├── main.tf
│       │   ├── outputs.tf
│       │   └── variables.tf
│       ├── ecs_cluster
│       │   ├── main.tf
│       │   ├── outputs.tf
│       │   └── variables.tf
│       ├── ecs_service
│       │   ├── main.tf
│       │   ├── outputs.tf
│       │   └── variables.tf
│       ├── iam
│       │   ├── main.tf
│       │   ├── outputs.tf
│       │   └── variables.tf
│       ├── security_groups
│       │   ├── main.tf
│       │   ├── outputs.tf
│       │   └── variables.tf
│       └── task_definition
│           ├── main.tf
│           ├── outputs.tf
│           └── variables.tf

└── terraform-eks
    ├── Jenkinsfile
    ├── argo-setup.sh
    ├── backend.tf
    ├── deployment.yaml
    ├── iam.tf
    ├── main.tf
    ├── output.tf
    ├── terraform.tfvars
    └── variables.tf

├── module-eks-env
│   ├── environments
│   │   ├── prod
│   │   │   ├── backend.tf
│   │   │   ├── main.tf
│   │   │   ├── output.tf
│   │   │   ├── provider.tf
│   │   │   └── variables.tf
│   │   └── stage
│   │       ├── backend.tf
│   │       ├── main.tf
│   │       ├── output.tf
│   │       ├── provider.tf
│   │       └── variables.tf
│   └── modules
│       └── eks
│           ├── main.tf
│           ├── output.tf
│           └── variables.tf</code></pre></figure>

<p><img src="/assets/jenkins3.png" alt="image tooltip here" /></p>

<p><b>Conclusion</b></p>

<p>Using Terraform and Jenkins practices enables efficient management of complex, multi-environment, and multi-service deployments, which are crucial for cloud-native CI/CD processes to achieve:</p>

<ol>
  <li>
    <p>Version Control: Allows tracking and managing infrastructure changes across different environments.</p>
  </li>
  <li>
    <p>Multi-Destination Deployment with Jenkins: Enables dynamic deployments to different environments (e.g., production, stage) by passing environment-specific parameters in the pipeline.</p>
  </li>
  <li>
    <p>Environment Separation: Each environment (production, stage) has its own Terraform configuration, ensuring proper isolation and customization.</p>
  </li>
  <li>
    <p>Terraform Modules Reusability: Reusable modules for infrastructure components (ECS, EKS, etc.) reduce code duplication and simplify updates.</p>
  </li>
  <li>
    <p>Multi-Environment and Multi-Component Deployment: Jenkins pipelines can deploy multiple services and environments concurrently by leveraging modular infrastructure and dynamic inputs.</p>
  </li>
</ol>

<p><b>Jenkins Recap Summary</b></p>

<p>Over this recap for Jenkins, I believe I had achieved :</p>

<ul>
  <li>
    <p><b>Multi-Stage, Multi-Environment Pipelines: </b>
These handle conditional execution using when blocks, try-catch for error handling, and post sections for notifications and cleanup.</p>
  </li>
  <li>
    <p><b>Integration with IaC Tools: </b>
Seamlessly provisions AWS resources using Terraform or CloudFormation within the pipeline.</p>
  </li>
  <li>
    <p><b>Security and Compliance: </b>
Integrates tools like Snyk, Trivy, and SonarQube to perform vulnerability scanning and code quality checks during the build.</p>
  </li>
  <li>
    <p><b>Secret Management: </b>
Securely manages sensitive data using AWS Secrets Manager, HashiCorp Vault, or Jenkins credentials plugin.</p>
  </li>
  <li>
    <p><b>Real-World Automation: </b>
Solves complex problems and improves efficiency, reducing build times and increasing deployment reliability.</p>
  </li>
</ul>]]></content><author><name></name></author><category term="jekyll" /><category term="Cat2" /><summary type="html"><![CDATA[Jenkins CD Pipeline Design]]></summary></entry><entry><title type="html">Jenkins - Universal CI Pipeline with Ansible &amp;amp; Terraform</title><link href="http://localhost:4000/jekyll/cat2/2024/08/02/Jenkins-redo1-copy.html" rel="alternate" type="text/html" title="Jenkins - Universal CI Pipeline with Ansible &amp;amp; Terraform" /><published>2024-08-02T10:15:29+10:00</published><updated>2024-08-02T10:15:29+10:00</updated><id>http://localhost:4000/jekyll/cat2/2024/08/02/Jenkins-redo1%20copy</id><content type="html" xml:base="http://localhost:4000/jekyll/cat2/2024/08/02/Jenkins-redo1-copy.html"><![CDATA[<p><b>Jenkins recap</b></p>

<p>It has been some time since I adapted CI/CD pipelines from Jenkins to AWS CodePipeline and GitHub Actions workflows. Now, it’s time to recap and improve some of my previous Jenkins practices.</p>

<ul>
  <li>Universal Jenkins Docker image design</li>
</ul>

<p>This time, instead of installing Jenkins on a server, I prefer to containerize a universal Jenkins Docker image with the necessary packages installed, so it provides consistency and reproducibility, portability, and easy updates and rollbacks.</p>

<ol>
  <li>Docker CLI</li>
  <li>Terraform</li>
  <li>Kubectl</li>
  <li>Trivy</li>
  <li>AWS CLI</li>
  <li>Ansible </li>
</ol>

<figure class="highlight"><pre><code class="language-shell" data-lang="shell"><span class="c"># Dockerfile</span>

FROM jenkins/jenkins:lts

USER root

<span class="c"># Install necessary packages, Docker CLI, Terraform, Kubectl, Trivy, AWS CLI, and Ansible</span>
RUN apt-get update <span class="o">&amp;&amp;</span> <span class="se">\</span>
    apt-get <span class="nb">install</span> <span class="nt">-y</span> <span class="se">\</span>
        curl <span class="se">\</span>
        wget <span class="se">\</span>
        unzip <span class="se">\</span>
        gnupg2 <span class="se">\</span>
        apt-transport-https <span class="se">\</span>
        lsb-release <span class="se">\</span>
        ca-certificates <span class="se">\</span>
        software-properties-common <span class="se">\</span>
        python3 <span class="se">\</span>
        python3-venv <span class="se">\</span>
        python3-pip <span class="o">&amp;&amp;</span> <span class="se">\</span>

    <span class="c"># Install Docker CLI</span>
    curl <span class="nt">-fsSL</span> https://download.docker.com/linux/debian/gpg | apt-key add - <span class="o">&amp;&amp;</span> <span class="se">\</span>
    <span class="nb">echo</span> <span class="s2">"deb [arch=amd64] https://download.docker.com/linux/debian </span><span class="si">$(</span>lsb_release <span class="nt">-cs</span><span class="si">)</span><span class="s2"> stable"</span> <span class="o">&gt;</span> /etc/apt/sources.list.d/docker.list <span class="o">&amp;&amp;</span> <span class="se">\</span>
    apt-get update <span class="o">&amp;&amp;</span> <span class="se">\</span>
    apt-get <span class="nb">install</span> <span class="nt">-y</span> docker-ce-cli <span class="o">&amp;&amp;</span> <span class="se">\</span>

    <span class="c"># Install Terraform</span>
    wget <span class="nt">-O-</span> https://apt.releases.hashicorp.com/gpg | gpg <span class="nt">--dearmor</span> <span class="o">&gt;</span> /usr/share/keyrings/hashicorp-archive-keyring.gpg <span class="o">&amp;&amp;</span> <span class="se">\</span>
    <span class="nb">echo</span> <span class="s2">"deb [signed-by=/usr/share/keyrings/hashicorp-archive-keyring.gpg] https://apt.releases.hashicorp.com </span><span class="si">$(</span>lsb_release <span class="nt">-cs</span><span class="si">)</span><span class="s2"> main"</span> <span class="o">&gt;</span> /etc/apt/sources.list.d/hashicorp.list <span class="o">&amp;&amp;</span> <span class="se">\</span>
    apt-get update <span class="o">&amp;&amp;</span> <span class="se">\</span>
    apt-get <span class="nb">install</span> <span class="nt">-y</span> terraform <span class="o">&amp;&amp;</span> <span class="se">\</span>

    <span class="c"># Install Kubectl</span>
    curl <span class="nt">-LO</span> <span class="s2">"https://dl.k8s.io/release/</span><span class="si">$(</span>curl <span class="nt">-L</span> <span class="nt">-s</span> https://dl.k8s.io/release/stable.txt<span class="si">)</span><span class="s2">/bin/linux/amd64/kubectl"</span> <span class="o">&amp;&amp;</span> <span class="se">\</span>
    <span class="nb">chmod</span> +x kubectl <span class="o">&amp;&amp;</span> <span class="se">\</span>
    <span class="nb">mv </span>kubectl /usr/local/bin/ <span class="o">&amp;&amp;</span> <span class="se">\</span>

    <span class="c"># Install Trivy</span>
    wget https://github.com/aquasecurity/trivy/releases/download/v0.56.0/trivy_0.56.0_Linux-64bit.deb <span class="o">&amp;&amp;</span> <span class="se">\</span>
    dpkg <span class="nt">-i</span> trivy_0.56.0_Linux-64bit.deb <span class="o">&amp;&amp;</span> <span class="se">\</span>
    <span class="nb">rm </span>trivy_0.56.0_Linux-64bit.deb <span class="o">&amp;&amp;</span> <span class="se">\</span>

    <span class="c"># Install AWS CLI</span>
    curl <span class="s2">"https://awscli.amazonaws.com/awscli-exe-linux-x86_64.zip"</span> <span class="nt">-o</span> <span class="s2">"awscliv2.zip"</span> <span class="o">&amp;&amp;</span> <span class="se">\</span>
    unzip awscliv2.zip <span class="o">&amp;&amp;</span> <span class="se">\</span>
    ./aws/install <span class="o">&amp;&amp;</span> <span class="se">\</span>
    <span class="nb">rm</span> <span class="nt">-rf</span> awscliv2.zip aws/ <span class="o">&amp;&amp;</span> <span class="se">\</span>

    <span class="c"># Create a virtual environment for Python and Ansible</span>
    python3 <span class="nt">-m</span> venv /opt/ansible_venv <span class="o">&amp;&amp;</span> <span class="se">\</span>
    /opt/ansible_venv/bin/pip <span class="nb">install</span> <span class="nt">--upgrade</span> pip <span class="o">&amp;&amp;</span> <span class="se">\</span>
    /opt/ansible_venv/bin/pip <span class="nb">install </span>ansible <span class="o">&amp;&amp;</span> <span class="se">\</span>

    <span class="c"># Create symlinks to make Ansible easily accessible</span>
    <span class="nb">ln</span> <span class="nt">-s</span> /opt/ansible_venv/bin/ansible /usr/local/bin/ansible <span class="o">&amp;&amp;</span> <span class="se">\</span>
    <span class="nb">ln</span> <span class="nt">-s</span> /opt/ansible_venv/bin/ansible-playbook /usr/local/bin/ansible-playbook <span class="o">&amp;&amp;</span> <span class="se">\</span>

    <span class="c"># Clean up</span>
    apt-get clean <span class="o">&amp;&amp;</span> <span class="se">\</span>
    <span class="nb">rm</span> <span class="nt">-rf</span> /var/lib/apt/lists/<span class="k">*</span>

USER jenkins</code></pre></figure>

<p>Build and run this universal Jenkins image to mount Jenkins home directory and Docker socket from the host to the container, also add Docker group to the container so Jenkins can run Docker commands inside the container without needing root privileges.</p>

<figure class="highlight"><pre><code class="language-shell" data-lang="shell">docker build <span class="nt">-t</span> jenkins-all <span class="nb">.</span>

docker run <span class="nt">-d</span> <span class="nt">--name</span> jenkins <span class="nt">-p</span> 8080:8080 <span class="nt">-p</span> 50000:50000 <span class="se">\</span>
<span class="nt">-v</span> /var/run/docker.sock:/var/run/docker.sock <span class="se">\</span>
<span class="nt">-v</span> /var/jenkins_home:/var/jenkins_home <span class="se">\</span>
<span class="nt">--group-add</span> <span class="si">$(</span>getent group docker | <span class="nb">cut</span> <span class="nt">-d</span>: <span class="nt">-f3</span><span class="si">)</span> <span class="se">\ </span>
jenkins-all</code></pre></figure>

<ul>
  <li>Universal Jenkins CI pipeline design</li>
</ul>

<p>After installing a list of plugins and configuring all credentials and the GitHub webhook, the CI pipeline is designed bellow and can be triggered by a Git push event and will run automatically:</p>

<ol>
  <li>Enable multi-language artifact build support.</li>
  <li>Integrate testing of Java versions.</li>
  <li>Enable security checks for static code analysis and Docker image scanning.</li>
  <li>Implement advanced Jenkins pipeline structuring using <b>try-catch</b>, <b>if-else</b>, <b>timeouts</b>,<b>environment variables</b>,<b>post actions</b> and <b>error handling</b>.</li>
</ol>

<figure class="highlight"><pre><code class="language-shell" data-lang="shell"><span class="c">#  Jenkinsfile</span>

// Define the detectJavaVersion <span class="k">function </span>outside of the pipeline block
def detectJavaVersion<span class="o">()</span> <span class="o">{</span>
    def javaVersionOutput <span class="o">=</span> sh<span class="o">(</span>script: <span class="s1">'java -version 2&gt;&amp;1'</span>, returnStatus: <span class="nb">false</span>, returnStdout: <span class="nb">true</span><span class="o">)</span>.trim<span class="o">()</span>
    def javaVersionMatch <span class="o">=</span> javaVersionOutput <span class="o">=</span>~ /openjdk version <span class="s2">"(</span><span class="se">\d</span><span class="s2">+</span><span class="se">\.\d</span><span class="s2">+)/

    if (javaVersionMatch) {
        def javaVersion = javaVersionMatch[0][1]

        if (javaVersion.startsWith("</span>1.8<span class="s2">")) {
            return '8'
        } else if (javaVersion.startsWith("</span>11<span class="s2">")) {
            return '11'
        } else if (javaVersion.startsWith("</span>17<span class="s2">")) {
            return '17'
        } else {
            error("</span>Unsupported Java version detected: <span class="k">${</span><span class="nv">javaVersion</span><span class="k">}</span><span class="s2">")
        }
    } else {
        error("</span>Java version information not found <span class="k">in </span>output.<span class="s2">")
    }
}

pipeline {
    agent any
    environment {
        REGISTRY_URL = 'https://index.docker.io/v1/'
        IMAGE_NAME = "</span>zackz001/jenkins<span class="s2">"
        IMAGE_TAG = "</span><span class="k">${</span><span class="nv">env</span><span class="p">.BUILD_NUMBER</span><span class="k">}</span><span class="s2">"
        LATEST_TAG = "</span>latest<span class="s2">"
        TRIVY_OUTPUT = "</span>trivy-report.txt<span class="s2">"
        EMAIL_RECIPIENT = "</span>zhbsoftboy1@gmail.com<span class="s2">"
        GIT_REPO_URL = 'https://github.com/ZackZhouHB/zack-gitops-project.git'  // Git repository URL
        GIT_BRANCH = 'jenkins'  // Git branch
        DOCKERHUB_CREDENTIALS_ID = 'dockerhub' // Docker Hub credentials
        SONAR_TOKEN = 'sonar'  // Fetch Sonar token securely
        SNYK_INSTALLATION = 'snyk' // Replace with your Snyk installation
        SNYK_TOKEN = 'snyktoken'  // Fetch Snyk token securely
    }
    stages {
        stage('Clean Workspace') {
            steps {
                cleanWs()
            }
        }   
        stage('Checkout Code') {
            steps {
                git branch: "</span><span class="k">${</span><span class="nv">GIT_BRANCH</span><span class="k">}</span><span class="s2">",
                    credentialsId: 'gittoken',
                    url: "</span><span class="k">${</span><span class="nv">GIT_REPO_URL</span><span class="k">}</span><span class="s2">"
            }   
        }
        stage('Detect and Set Java') {
            steps {
                script {
                    try {
                        def javaVersion = detectJavaVersion()  // Detect the Java version, e.g., "</span>17<span class="s2">"
                        def javaToolName = "</span>Java_<span class="k">${</span><span class="nv">javaVersion</span><span class="k">}</span><span class="s2">"  // Expected tool name

                        // Try to set the Java version; fallback if the specific version isn't found
                        try {
                            tool name: javaToolName, type: 'jdk'
                            echo "</span>Using Java version <span class="k">${</span><span class="nv">javaVersion</span><span class="k">}</span>.<span class="s2">"
                        } catch (Exception toolError) {
                            echo "</span>No JDK named <span class="k">${</span><span class="nv">javaToolName</span><span class="k">}</span> found. Using default JDK.<span class="s2">"
                        }

                        // Verify Java version, regardless of whether the specific version was found
                        sh 'java --version'

                    } catch (Exception e) {
                        echo "</span>Error during Java version detection: <span class="k">${</span><span class="nv">e</span><span class="p">.message</span><span class="k">}</span><span class="s2">"
                        // Continue pipeline even if Java detection fails
                    }
                }
            }
        }
        // for Code Security Analysis and Fixes
        stage('snyk_analysis') {
            steps {
                script {
                    echo 'Running Snyk security analysis...'
                    timeout(time: 5, unit: 'MINUTES') {  // Adjust the timeout value as necessary
                        try {
                            snykSecurity(
                                snykInstallation: SNYK_INSTALLATION,
                                snykTokenId: SNYK_TOKEN,
                                failOnIssues: false,
                                monitorProjectOnBuild: true,
                                additionalArguments: '--severity-threshold=low'
                            )
                       } catch (Exception e) {
                            currentBuild.result = 'FAILURE'
                            error("</span>Error during snyk_analysis: <span class="k">${</span><span class="nv">e</span><span class="p">.message</span><span class="k">}</span><span class="s2">")
                        }
                    }
                }
            }
        }
        
        // Language-specific build and test stages
        stage('Frontend Build and Test') {
            steps {
                script {
                    try {
                        if (fileExists('package.json')) {
                            sh 'npm install --force'
                            sh 'npm test'
                        } else {
                            echo 'No package.json found, skipping Frontend build and test.'
                        }
                    } catch (Exception e) {
                        currentBuild.result = 'FAILURE'
                        error("</span>Error during Frontend build and <span class="nb">test</span>: <span class="k">${</span><span class="nv">e</span><span class="p">.message</span><span class="k">}</span><span class="s2">")
                    }
                }
            }
        }

        stage('Java Spring Boot Build and Test') {
            steps {
                script {
                    try {
                        if (fileExists('pom.xml')) {
                            sh 'mvn clean package'
                            sh 'mvn test'
                        } else {
                            echo 'No pom.xml found, skipping Java Spring Boot build and test.'
                        }
                    } catch (Exception e) {
                        currentBuild.result = 'FAILURE'
                        error("</span>Error during Java Spring Boot build and <span class="nb">test</span>: <span class="k">${</span><span class="nv">e</span><span class="p">.message</span><span class="k">}</span><span class="s2">")
                    }
                }
            }
        }

        stage('.NET Build and Test') {
            steps {
                script {
                    try {
                        if (fileExists('YourSolution.sln')) {
                            sh 'dotnet build'
                            sh 'dotnet test'
                        } else {
                            echo 'No YourSolution.sln found, skipping .NET build and test.'
                        }
                    } catch (Exception e) {
                        currentBuild.result = 'FAILURE'
                        error("</span>Error during .NET build and <span class="nb">test</span>: <span class="k">${</span><span class="nv">e</span><span class="p">.message</span><span class="k">}</span><span class="s2">")
                    }
                }
            }
        }

        stage('PHP Build and Test') {
            steps {
                script {
                    try {
                        if (fileExists('composer.json')) {
                            sh 'composer install'
                            sh 'phpunit'
                        } else {
                            echo 'No composer.json found, skipping PHP build and test.'
                        }
                    } catch (Exception e) {
                        currentBuild.result = 'FAILURE'
                        error("</span>Error during PHP build and <span class="nb">test</span>: <span class="k">${</span><span class="nv">e</span><span class="p">.message</span><span class="k">}</span><span class="s2">")
                    }
                }
            }
        }

        stage('iOS Build and Test') {
            steps {
                script {
                    try {
                        if (fileExists('YourProject.xcodeproj')) {
                            xcodebuild(buildDir: 'build', scheme: 'YourScheme')
                        } else {
                            echo 'No YourProject.xcodeproj found, skipping iOS build and test.'
                        }
                    } catch (Exception e) {
                        currentBuild.result = 'FAILURE'
                        error("</span>Error during iOS build and <span class="nb">test</span>: <span class="k">${</span><span class="nv">e</span><span class="p">.message</span><span class="k">}</span><span class="s2">")
                    }
                }
            }
        }

        stage('Android Build and Test') {
            steps {
                script {
                    try {
                        if (fileExists('build.gradle')) {
                            sh './gradlew build'
                            sh './gradlew test'
                        } else {
                            echo 'No build.gradle found, skipping Android build and test.'
                        }
                    } catch (Exception e) {
                        currentBuild.result = 'FAILURE'
                        error("</span>Error during Android build and <span class="nb">test</span>: <span class="k">${</span><span class="nv">e</span><span class="p">.message</span><span class="k">}</span><span class="s2">")
                    }
                }
            }
        }

        stage('Ruby on Rails Build and Test') {
            steps {
                script {
                    try {
                        if (fileExists('Gemfile.lock')) {
                            sh 'bundle install'
                            sh 'bundle exec rake db:migrate'
                            sh 'bundle exec rails test'
                        } else {
                            echo 'No Gemfile.lock found, skipping Ruby on Rails build and test.'
                        }
                    } catch (Exception e) {
                        currentBuild.result = 'FAILURE'
                        error("</span>Error during Ruby on Rails build and <span class="nb">test</span>: <span class="k">${</span><span class="nv">e</span><span class="p">.message</span><span class="k">}</span><span class="s2">")
                    }
                }
            }
        }

        stage('Flask Build and Test') {
            steps {
                script {
                    try {
                        if (fileExists('app.py')) {
                            sh 'pip install -r requirements.txt'
                            sh 'python -m unittest discover'
                        } else {
                            echo 'No app.py found, skipping Flask build and test.'
                        }
                    } catch (Exception e) {
                        currentBuild.result = 'FAILURE'
                        error("</span>Error during Flask build and <span class="nb">test</span>: <span class="k">${</span><span class="nv">e</span><span class="p">.message</span><span class="k">}</span><span class="s2">")
                    }
                }
            }
        }

        stage('Django Build and Test') {
            steps {
                script {
                    try {
                        if (fileExists('manage.py')) {
                            sh 'pip install -r requirements.txt'
                            sh 'python manage.py migrate'
                            sh 'python manage.py test'
                        } else {
                            echo 'No manage.py found, skipping Django build and test.'
                        }
                    } catch (Exception e) {
                        currentBuild.result = 'FAILURE'
                        error("</span>Error during Django build and <span class="nb">test</span>: <span class="k">${</span><span class="nv">e</span><span class="p">.message</span><span class="k">}</span><span class="s2">")
                    }
                }
            }
        }

        stage('Rust Build and Test') {
            steps {
                script {
                    try {
                        if (fileExists('Cargo.toml')) {
                            env.RUST_BACKTRACE = 'full'
                            sh 'cargo build'
                            sh 'cargo test'
                        } else {
                            echo "</span>No Cargo.toml file found. Skipping Rust build and test.<span class="s2">"
                        }
                    } catch (Exception e) {
                        currentBuild.result = 'FAILURE'
                        error("</span>Error during Rust build and <span class="nb">test</span>: <span class="k">${</span><span class="nv">e</span><span class="p">.message</span><span class="k">}</span><span class="s2">")
                    }
                }
            }
        }

        stage('Ruby Sinatra Build and Test') {
            steps {
                script {
                    try {
                        if (fileExists('app.rb')) {
                            sh 'gem install bundler'
                            sh 'bundle install'
                            sh 'bundle exec rake test'
                        } else {
                            echo "</span>No app.rb file found. Skipping Ruby Sinatra build and test.<span class="s2">"
                        }
                    } catch (Exception e) {
                        currentBuild.result = 'FAILURE'
                        error("</span>Error during Ruby Sinatra build and <span class="nb">test</span>: <span class="k">${</span><span class="nv">e</span><span class="p">.message</span><span class="k">}</span><span class="s2">")
                    }
                }
            }
        }
        // Build ZackBlog docker image 
        stage('Check and Build Docker Image') {
            steps {
                script {
                    try {
                        // Check if Docker is available
                        sh 'docker --version'
                        echo "</span>Docker is installed. Proceeding to build the Docker image...<span class="s2">"
                        
                        // Build the Docker image from the 'zack_blog' folder
                        dockerImage = docker.build("</span><span class="k">${</span><span class="nv">IMAGE_NAME</span><span class="k">}</span>:<span class="k">${</span><span class="nv">IMAGE_TAG</span><span class="k">}</span><span class="s2">", "</span>zack_blog/<span class="s2">")
                    } catch (Exception e) {
                        // Handle the error if Docker is not available
                        error("</span>Docker is not installed or accessible. Cannot proceed with the build.<span class="s2">")
                    }
                }
            }
        }
        // Scan docker image with Trivy
        stage('Docker Image Scan') {
            steps {
                // Use Trivy to scan the built Docker image
                sh "</span>trivy image <span class="nt">--severity</span> HIGH,CRITICAL <span class="k">${</span><span class="nv">IMAGE_NAME</span><span class="k">}</span>:<span class="k">${</span><span class="nv">IMAGE_TAG</span><span class="k">}</span> <span class="o">&gt;</span> <span class="k">${</span><span class="nv">TRIVY_OUTPUT</span><span class="k">}</span><span class="s2">"
            }
        }
        //Push to Dockerhub
        stage('Push Docker Image to DockerHub') {
            steps {
                script {
                    docker.withRegistry("</span><span class="k">${</span><span class="nv">REGISTRY_URL</span><span class="k">}</span><span class="s2">", "</span><span class="k">${</span><span class="nv">DOCKERHUB_CREDENTIALS_ID</span><span class="k">}</span><span class="s2">") {
                        dockerImage.push("</span><span class="k">${</span><span class="nv">IMAGE_TAG</span><span class="k">}</span><span class="s2">")
                        dockerImage.push("</span><span class="k">${</span><span class="nv">LATEST_TAG</span><span class="k">}</span><span class="s2">") // Push 'latest' tag
                    }
                }
            }
        }
        //Output image scan result
        stage('Display Trivy Scan Results') {
            steps {
                script {
                    // Display the contents of the Trivy report
                    def scanReport = readFile("</span><span class="k">${</span><span class="nv">TRIVY_OUTPUT</span><span class="k">}</span><span class="s2">")
                    echo "</span>Trivy Scan Report:<span class="se">\n</span><span class="k">${</span><span class="nv">scanReport</span><span class="k">}</span><span class="s2">"
                }
            }
        }
        // Additional stages like Docker build, image scan, etc.
    }
    // Post Build Emailing 
    post {
        success {
            script {
                def scanReport = readFile("</span><span class="k">${</span><span class="nv">TRIVY_OUTPUT</span><span class="k">}</span><span class="s2">")
                emailext(
                    to: "</span><span class="k">${</span><span class="nv">EMAIL_RECIPIENT</span><span class="k">}</span><span class="s2">",
                    subject: "</span>CI Pipeline Success: Build <span class="k">${</span><span class="nv">IMAGE_TAG</span><span class="k">}</span><span class="s2">",
                    body: """</span>
                    The pipeline has successfully completed.

                    Docker image <span class="k">${</span><span class="nv">IMAGE_NAME</span><span class="k">}</span>:<span class="k">${</span><span class="nv">IMAGE_TAG</span><span class="k">}</span> has been built and pushed to DockerHub.

                    Trivy Scan Report:
                    <span class="k">${</span><span class="nv">scanReport</span><span class="k">}</span>
                    <span class="s2">"""
                )
            }
        }
        failure {
            emailext(
                to: "</span><span class="k">${</span><span class="nv">EMAIL_RECIPIENT</span><span class="k">}</span><span class="s2">",
                subject: "</span>CI Pipeline Failed: Build <span class="k">${</span><span class="nv">IMAGE_TAG</span><span class="k">}</span><span class="s2">",
                body: """</span>
                The pipeline has failed at some stage.

                Please check the Jenkins console logs <span class="k">for </span>more details.
                <span class="s2">"""
            )
        }
    }
}</span></code></pre></figure>

<ul>
  <li>Pipeline test and debug</li>
</ul>

<p>After thorough testing and validation, the CI pipeline finally works like a charm.</p>

<p><img src="/assets/jenkins1.png" alt="image tooltip here" /></p>

<p>Next, I will create a CD pipeline to integrate with Ansible, AWS, and Terraform to deploy the blog onto AWS EC2, ECS, and EKS.</p>]]></content><author><name></name></author><category term="jekyll" /><category term="Cat2" /><summary type="html"><![CDATA[Jenkins recap]]></summary></entry><entry><title type="html">RedHat Identity Management (IdM) with AD Intergration</title><link href="http://localhost:4000/jekyll/cat2/2024/07/13/Redhatidm.html" rel="alternate" type="text/html" title="RedHat Identity Management (IdM) with AD Intergration" /><published>2024-07-13T10:15:29+10:00</published><updated>2024-07-13T10:15:29+10:00</updated><id>http://localhost:4000/jekyll/cat2/2024/07/13/Redhatidm</id><content type="html" xml:base="http://localhost:4000/jekyll/cat2/2024/07/13/Redhatidm.html"><![CDATA[<p><b> About Linux Identity Management </b></p>

<p>When a company faces challenge to manage its Linux environments across local and public cloud, RedHat Identity management can be the solution to achieve:</p>

<ul>
  <li>
    <p>With Local AD and Azure AD (AAD) Integration</p>
  </li>
  <li>
    <p>With AWS SSO Integration as externel identity provider</p>
  </li>
  <li>
    <p>LDAP, Kerberos and NTP</p>
  </li>
  <li>
    <p>A web-based management front-end running on Apache</p>
  </li>
</ul>

<p><b> A Typical AD User Authentication Flow End-to-End: </b></p>

<p>User Creation and Management:</p>

<ul>
  <li>
    <p>Azure AD / Local AD: Users are created in the Azure Active Directory or local Active Directory.</p>
  </li>
  <li>
    <p>Synchronization to RedHat IdM: The users are synchronized from AD to RedHat IdM using the two-way trust established between AD and IdM.</p>
  </li>
</ul>

<p>Accessing EC2 Instances via SSH:</p>

<ul>
  <li>User Sync to RedHat IdM: Users synchronized to RedHat IdM are assigned roles and permissions, including SSH access to specific EC2 instances.</li>
</ul>

<p>Host-Based Access Control (HBAC):</p>

<ul>
  <li>
    <p>HBAC Rules: RedHat IdM enforces HBAC rules to control which users can access specific EC2 instances.</p>
  </li>
  <li>
    <p>SSH Access Control: When a user attempts to SSH into an EC2 instance, RedHat IdM verifies the user’s identity and permissions, allowing or denying access based on the defined HBAC rules.</p>
  </li>
</ul>

<p><b> The design:</b></p>

<p>For Idm on AWS, configure the security groups to allow ports required by IdM. IdM desires below to be open:</p>

<p>HTTP/HTTPS — 80, 443 — TCP</p>

<p>LDAP/LDAPS — 389, 636 — TCP</p>

<p>Kerberos — 88, 464 — Both TCP and UDP</p>

<p>DNS — 53 — Both TCP and UDP</p>

<p>NTP — 123 — UDP</p>

<p>Here I am going to:</p>

<ul>
  <li>
    <p>install and configure a local freeIPA server</p>
  </li>
  <li>
    <p>enroll 2 Linux client machines (both CentOS and Ubuntu)</p>
  </li>
  <li>
    <p>Setup a local AD,</p>
  </li>
  <li>
    <p>build a 2 way trust between idm and AD</p>
  </li>
  <li>
    <p>Validate IDM and AD user to ssh into idm client machines.</p>
  </li>
</ul>

<p><b> Prerequisites: </b></p>

<ul>
  <li>
    <p>Windows AD Domain <b> ad.zack.world</b> and Idm Domain <b> ipa.zack.world</b></p>
  </li>
  <li>
    <p>Windows AD: 11.0.1.181 dc01.ad.zack.world (win server 2019)</p>
  </li>
  <li>
    <p>Windows client1: 11.0.1.182 win-client.ad.zack.world (win server 2019)</p>
  </li>
  <li>
    <p>idm Server: 11.0.1.180 server1.ipa.zack.world (CentOS 9)</p>
  </li>
  <li>
    <p>idm Client2: 11.0.1.184 ubt-client02.ipa.zack.world (Ubuntu 24.04)</p>
  </li>
  <li>
    <p>idm Client3: 11.0.1.185 idm-client3-centos7.ipa.zack.world (CentOS 9)</p>
  </li>
</ul>

<p><b> FreeIPA Installation </b></p>

<p>On freeIPA Server server1.ipa.zack.world 11.0.1.180 (CentOS 9):</p>

<figure class="highlight"><pre><code class="language-shell" data-lang="shell"><span class="c"># set hostname, IP and DNS</span>
hostnamectl set-hostname server1.ipa.zack.world

<span class="c"># add 3 hosts to /etc/hosts</span>
<span class="nb">echo </span>11.0.1.180 server1.ipa.zack.world  ipa <span class="o">&gt;&gt;</span> /etc/hosts
<span class="nb">echo </span>11.0.1.184 ubt-client02.ipa.zack.world ipa <span class="o">&gt;&gt;</span> /etc/hosts
<span class="nb">echo </span>11.0.1.185  idm-client3-centos7.ipa.zack.world  ipa <span class="o">&gt;&gt;</span> /etc/hosts
<span class="nb">echo </span>11.0.1.181  dc01.ad.zack.world ipa <span class="o">&gt;&gt;</span> /etc/hosts

<span class="c"># install ipa-server</span>
dnf <span class="nt">-y</span> <span class="nb">install </span>freeipa-server freeipa-server-dns freeipa-client

<span class="c"># Configure ipa-server and DNS, here set ipa console and domain admin password</span>
ipa-server-install <span class="nt">--setup-dns</span>

<span class="c"># confirm or change NetBIOS domain name</span>
NetBIOS domain name <span class="o">[</span>IPA]: IPA01

The ipa-server-install <span class="nb">command </span>was successful.

<span class="c"># Configure firewall rules and services</span>
firewall-cmd <span class="nt">--add-service</span><span class="o">={</span>freeipa-ldap,freeipa-ldaps,dns,ntp<span class="o">}</span>
firewall-cmd <span class="nt">--runtime-to-permanent</span>
firewall-cmd <span class="nt">--reload</span> 

<span class="c"># check ipastatus</span>
<span class="o">[</span>root@freeipa ~]# ipactl status
Directory Service: RUNNING
krb5kdc Service: RUNNING
kadmin Service: RUNNING
httpd Service: RUNNING
ipa-custodia Service: RUNNING
ntpd Service: RUNNING
pki-tomcatd Service: RUNNING
ipa-otpd Service: RUNNING
ipa: INFO: The ipactl <span class="nb">command </span>was successful

<span class="c"># Obtain a Kerberos ticket for the Kerberos admin user and Verify the ticket</span>
kinit admin
klist

Ticket cache: KEYRING:persistent:0:0
Default principal: admin@ZACKZ.OONLINE

Valid starting     Expires            Service principal
07/13/24 22:17:29  07/14/24 22:02:43  HTTP/server1.ipa.zack.world@IPA.ZACK.WORLD

<span class="c"># check content of /etc/resolv.conf</span>
<span class="nb">cat</span> /etc/resolv.conf
search ipa.zack.world
nameserver 127.0.0.1

<span class="c"># Configure default login shell to Bash and Create User tina</span>
ipa config-mod <span class="nt">--defaultshell</span><span class="o">=</span>/bin/bash
ipa user-add tina <span class="nt">--first</span><span class="o">=</span>tina <span class="nt">--last</span><span class="o">=</span>qi <span class="nt">--password</span></code></pre></figure>

<p><img src="/assets/idm3.png" alt="image tooltip here" /></p>

<p><b> Idm client Enrollment </b></p>

<p>Now the idm web portal should be accessible, by adding “11.0.1.180 server1.ipa.zack.world” into local “c:/wondows/system32/drivers/etc/hosts.</p>

<p>Then enrol both centos and Ubuntu IDM client machines</p>

<ul>
  <li>On FreeIPA Server, add DNS entry for FreeIPA Client machines</li>
</ul>

<figure class="highlight"><pre><code class="language-shell" data-lang="shell"><span class="c"># ipa dnsrecord-add [domain name] [record name] [record type] [record]</span>
ipa dnsrecord-add ipa.zack.world idm-client3-centos7 <span class="nt">--a-rec</span> 11.0.1.185
ipa dnsrecord-add ipa.zack.world ubt-client02 <span class="nt">--a-rec</span> 11.0.1.184

- <span class="nb">set </span>IP, <span class="nb">hostname</span>, DNS on idm client
<span class="c"># set idm server ID as client DNS</span>
nmcli connection modify ens33 ipv4.dns 11.0.1.180
nmcli connection up ens33

<span class="c"># Install FreeIPA Client packages.</span>
dnf <span class="nt">-y</span> <span class="nb">install </span>freeipa-client

<span class="c"># enrol client to idm server with domain name</span>
ipa-client-install <span class="nt">--server</span><span class="o">=</span>server1.ipa.zack.world <span class="nt">--domain</span> ipa.zack.world

Enrolled <span class="k">in </span>IPA realm IPA.ZACK.WORLD
Configuring ipa.zack.world as NIS domain.
Client configuration complete.
The ipa-client-install <span class="nb">command </span>was successful

<span class="c"># set create home directory at initial login</span>
authselect enable-feature with-mkhomedir
systemctl <span class="nb">enable</span> <span class="nt">--now</span> oddjobd

<span class="c"># same as Ubuntu client</span>
<span class="nb">echo </span>11.0.1.180 server1.ipa.zack.world server1 <span class="o">&gt;&gt;</span> /etc/hosts
<span class="nb">echo </span>11.0.1.184 ubt-client02.ipa.zack.world ubt-client02 <span class="o">&gt;&gt;</span> /etc/hosts
<span class="nb">echo </span>11.0.1.185 idm-client3-centos7.ipa.zack.world idm-client3-centos7 <span class="o">&gt;&gt;</span> /etc/hosts

<span class="c"># Edit host file and install client, then enrol into idm server domain</span>
apt update <span class="o">&amp;&amp;</span> apt <span class="nb">install </span>freeipa-client oddjob-mkhomedir <span class="nt">-y</span>
ipa-client-install <span class="nt">--server</span><span class="o">=</span>server1.ipa.zack.world <span class="nt">--domain</span> ipa.zack.world

Client configuration complete.
The ipa-client-install <span class="nb">command </span>was successful</code></pre></figure>

<p><img src="/assets/idm2.png" alt="image tooltip here" /></p>

<p><b> Setup idm and AD trust</b></p>

<p>On Windows DC, setup AD</p>

<ul>
  <li>
    <p>install ADDC role and feature</p>
  </li>
  <li>
    <p>create forest “ad.zack.world”</p>
  </li>
  <li>
    <p>promote to primary DC</p>
  </li>
  <li>
    <p>test AD to join Windows client machine to domain</p>
  </li>
  <li>
    <p>create AD user joez@ad.zack.world</p>
  </li>
  <li>
    <p>add idm domain to Windows AD zones</p>
  </li>
</ul>

<figure class="highlight"><pre><code class="language-shell" data-lang="shell"><span class="c"># dnscmd 127.0.0.1 /ZoneAdd [FreeIPA domain name] /Secondary [FreeIPA IP address]</span>
C:<span class="se">\U</span>sers<span class="se">\A</span>dministrator&gt;dnscmd 127.0.0.1 /ZoneAdd ipa.zack.world /Secondary 11.0.1.180
DNS Server 127.0.0.1 created zone ipa.zack.world:

Command completed successfully.

<span class="c"># Verify both AD and Idm DNS resolution, then setup trust</span>
dig SRV _ldap._tcp.ipa.zack.world
dig SRV _ldap._tcp.ad.zack.world</code></pre></figure>

<p><img src="/assets/idm1.png" alt="image tooltip here" /></p>

<ul>
  <li>Install required packages then setup trust on FreeIPA Server</li>
</ul>

<figure class="highlight"><pre><code class="language-shell" data-lang="shell"><span class="c"># Install packages</span>
dnf <span class="nt">-y</span> <span class="nb">install </span>ipa-server-trust-ad
<span class="c"># setup ad trust</span>
ipa-adtrust-install

<span class="c"># FreeIPA admin password</span>
admin password:
<span class="o">=============================================================================</span>
Setup <span class="nb">complete</span>

<span class="c"># add firewall service and ports for ad trust</span>
firewall-cmd <span class="nt">--add-service</span><span class="o">=</span>freeipa-trust

firewall-cmd <span class="nt">--permanent</span> <span class="nt">--add-port</span><span class="o">=</span>135/tcp
firewall-cmd <span class="nt">--permanent</span> <span class="nt">--add-port</span><span class="o">=</span>138/tcp
firewall-cmd <span class="nt">--permanent</span> <span class="nt">--add-port</span><span class="o">=</span>139/tcp
firewall-cmd <span class="nt">--permanent</span> <span class="nt">--add-port</span><span class="o">=</span>445/tcp
firewall-cmd <span class="nt">--permanent</span> <span class="nt">--add-port</span><span class="o">=</span>1024-1300/tcp
firewall-cmd <span class="nt">--permanent</span> <span class="nt">--add-port</span><span class="o">=</span>3268/tcp
<span class="c"># Open UDP ports</span>
firewall-cmd <span class="nt">--permanent</span> <span class="nt">--add-port</span><span class="o">=</span>138/udp
firewall-cmd <span class="nt">--permanent</span> <span class="nt">--add-port</span><span class="o">=</span>139/udp
firewall-cmd <span class="nt">--permanent</span> <span class="nt">--add-port</span><span class="o">=</span>389/udp
firewall-cmd <span class="nt">--permanent</span> <span class="nt">--add-port</span><span class="o">=</span>445/udp
<span class="c"># Open TCP ports</span>
firewall-cmd <span class="nt">--permanent</span> <span class="nt">--add-port</span><span class="o">=</span>80/tcp
firewall-cmd <span class="nt">--permanent</span> <span class="nt">--add-port</span><span class="o">=</span>443/tcp
firewall-cmd <span class="nt">--permanent</span> <span class="nt">--add-port</span><span class="o">=</span>389/tcp
firewall-cmd <span class="nt">--permanent</span> <span class="nt">--add-port</span><span class="o">=</span>636/tcp
firewall-cmd <span class="nt">--permanent</span> <span class="nt">--add-port</span><span class="o">=</span>88/tcp
<span class="nb">sudo </span>firewall-cmd <span class="nt">--permanent</span> <span class="nt">--add-port</span><span class="o">=</span>464/tcp
<span class="nb">sudo </span>firewall-cmd <span class="nt">--permanent</span> <span class="nt">--add-port</span><span class="o">=</span>53/tcp
<span class="c"># Open UDP ports</span>
firewall-cmd <span class="nt">--permanent</span> <span class="nt">--add-port</span><span class="o">=</span>88/udp
firewall-cmd <span class="nt">--permanent</span> <span class="nt">--add-port</span><span class="o">=</span>464/udp
firewall-cmd <span class="nt">--permanent</span> <span class="nt">--add-port</span><span class="o">=</span>53/udp
firewall-cmd <span class="nt">--permanent</span> <span class="nt">--add-port</span><span class="o">=</span>123/udp

firewall-cmd <span class="nt">--reload</span>

<span class="c"># Configure DNS Setting on FreeIPA Server</span>
<span class="c"># ipa dnsforwardzone-add [AD domain name] --forwarder=[AD IP address] --forward-policy=only</span>
ipa dnsforwardzone-add ad.zack.world <span class="nt">--forwarder</span><span class="o">=</span>11.0.1.181 <span class="nt">--forward-policy</span><span class="o">=</span>only
<span class="c"># ipa dnszone-mod [IPA domain name] --allow-transfer=[AD IP address]</span>
ipa dnszone-mod ipa.zack.world <span class="nt">--allow-transfer</span><span class="o">=</span>11.0.1.181

<span class="c"># ipa trust-add --type=ad [AD domain name] --admin Administrator --password</span>
ipa trust-add <span class="nt">--two-way</span><span class="o">=</span><span class="nb">true</span> <span class="nt">--type</span><span class="o">=</span>ad ad.zack.world <span class="nt">--admin</span> Administrator <span class="nt">--password</span>
Active Directory domain administrator<span class="s1">'s password:
-----------------------------------------------------
Added Active Directory trust for realm "ad.zack.world"
-----------------------------------------------------
 Realm name: ad.zack.world
 Domain NetBIOS name: AD01
 Domain Security Identifier: S-1-5-21-726412840-3773945212-2352305327
 Trust direction: Two-way trust
 Trust type: Active Directory domain
 Trust status: Established and verified

# set  home directory at initial login
authselect enable-feature with-mkhomedir
systemctl enable --now oddjobd</span></code></pre></figure>

<p><img src="/assets/idm4.png" alt="image tooltip here" /></p>

<p><b> Validation of both idm clients with idm and AD user</b></p>

<ul>
  <li>Validate ssh into ubuntu client with AD user “joez@ad.zack.world”</li>
</ul>

<p><img src="/assets/idm6.png" alt="image tooltip here" /></p>

<p>Validate ssh into Centos client with idm user “tina”</p>

<figure class="highlight"><pre><code class="language-shell" data-lang="shell">login as: tina
Keyboard-interactive authentication prompts from server:
| Password:
End of keyboard-interactive prompts from server
Last login: Sun Jul 14 20:48:42 2024 from 11.0.1.1
<span class="o">[</span>tina@idm-client3-centos7 ~]<span class="nv">$ </span><span class="nb">id
</span><span class="nv">uid</span><span class="o">=</span>1240000004<span class="o">(</span>tina<span class="o">)</span> <span class="nv">gid</span><span class="o">=</span>1240000004<span class="o">(</span>tina<span class="o">)</span> <span class="nb">groups</span><span class="o">=</span>1240000004<span class="o">(</span>tina<span class="o">)</span> 
<span class="nv">context</span><span class="o">=</span>unconfined_u:unconfined_r:unconfined_t:s0-s0:c0.c1023</code></pre></figure>

<p><b> Conclusion</b></p>

<p>Now we install Redhat IdM server and can enrol client hosts, set up AD trust, ssh and authenticate with both idm and AD users. IdM using Kerberos for authentication, together with user group, policy, HBAC and Sudo roles, provides a flexible and robust authentication framework that supports multiple authentication mechanisms, enabling organizations to authenticate users securely across their Linux and Unix environments.</p>

<p>More info can be found via <a href="https://freeipa.readthedocs.io/en/latest/workshop.html">Freeipa workshop</a>, <a href="https://www.server-world.info/en/note?os=CentOS_Stream_9&amp;p=freeipa&amp;f=8">FreeIPA:FreeIPA trust AD</a>, <a href="https://access.redhat.com/documentation/en-us/red_hat_enterprise_linux/9/html/managing_idm_users_groups_hosts_and_access_control_rules/index">Red Hat product documentation</a>, <a href="https://chamathb.wordpress.com/2019/06/21/setting-up-rhel-idm-with-integrated-dns-on-aws/">Redhat Idm on AWS with DNS forwarder</a>, <a href="https://www.reddit.com/r/redhat/comments/6ixtoe/idmfreeipa_dns_forwarding/">idmfreeipa DNS forwarder configurations on AWS</a>, and <a href="https://redhat.com/en/blog/automating-red-hat-identity-management-installation">Automating Red Hat Identity Management installation with Ansible</a>.</p>]]></content><author><name></name></author><category term="jekyll" /><category term="Cat2" /><summary type="html"><![CDATA[About Linux Identity Management]]></summary></entry><entry><title type="html">Serverless with AWS Fargate</title><link href="http://localhost:4000/jekyll/cat2/2024/07/10/aws-fargate.html" rel="alternate" type="text/html" title="Serverless with AWS Fargate" /><published>2024-07-10T10:15:29+10:00</published><updated>2024-07-10T10:15:29+10:00</updated><id>http://localhost:4000/jekyll/cat2/2024/07/10/aws-fargate</id><content type="html" xml:base="http://localhost:4000/jekyll/cat2/2024/07/10/aws-fargate.html"><![CDATA[<p><b>Why go serverless</b></p>

<p>Some of the company’s applications recently moved from Rancher to Fargate, which is understandable as the cloud resource and traffic will be very intensive only during a certain period (HSC exam), hence AWS serverless with Fargate can be a better option for such business mode so rest of the year without exam we can save cost significantly.</p>

<p><b>Hosting our blog on Fargate? Why not!</b></p>

<p>In the past, I used to try different methods to host this blog:</p>

<ul>
  <li><a href="https://zackz.site/jekyll/cat2/2023/11/02/about-this-project.html">EC2 with docker</a></li>
  <li><a href="https://zackz.site/jekyll/cat2/2023/11/07/ArgoCD.html">K8s with ArgoCD</a></li>
  <li><a href="https://zackz.site/jekyll/cat2/2024/04/30/serverless.html">S3 with static website</a></li>
  <li><a href="https://zackz.site/jekyll/cat2/2024/05/12/Helm.html">Customize Helm Chart for Zack’ Blog</a></li>
</ul>

<p>Here I will use AWS Fargate, together with AWS ECR, Docker, Terraform and Github Action workflow to move this blog to AWS serverless compute for containers.</p>

<ul>
  <li>Terraform Provisioning</li>
</ul>

<figure class="highlight"><pre><code class="language-shell" data-lang="shell"><span class="c"># Provider Configuration  "provider.tf"</span>
provider <span class="s2">"aws"</span> <span class="o">{</span>
 region <span class="o">=</span> <span class="s2">"ap-southeast-2"</span>
<span class="o">}</span>

<span class="c"># Create an ECR Repository "ecr.tf"</span>
resource <span class="s2">"aws_ecr_repository"</span> <span class="s2">"zackblog_repo"</span> <span class="o">{</span>
 name <span class="o">=</span> <span class="s2">"zackblog-repo"</span>
<span class="o">}</span>

<span class="c"># Fargate Task Definition  "task_definition.tf"</span>
resource <span class="s2">"aws_ecs_task_definition"</span> <span class="s2">"zackblog_task"</span> <span class="o">{</span>
 family                   <span class="o">=</span> <span class="s2">"zackblog-task"</span>
 network_mode             <span class="o">=</span> <span class="s2">"awsvpc"</span>
 requires_compatibilities <span class="o">=</span> <span class="o">[</span><span class="s2">"FARGATE"</span><span class="o">]</span>
 cpu                      <span class="o">=</span> <span class="s2">"256"</span>
 memory                   <span class="o">=</span> <span class="s2">"512"</span>

 container_definitions <span class="o">=</span> jsonencode<span class="o">([</span>
 <span class="o">{</span>
 name      <span class="o">=</span> <span class="s2">"zackblog-container"</span>,
 image     <span class="o">=</span> <span class="s2">"</span><span class="k">${</span><span class="nv">aws_ecr_repository</span><span class="p">.zackblog_repo.repository_url</span><span class="k">}</span><span class="s2">:latest"</span>,
 essential <span class="o">=</span> <span class="nb">true</span>,
 portMappings <span class="o">=</span> <span class="o">[</span>
 <span class="o">{</span>
 containerPort <span class="o">=</span> 80,
 hostPort      <span class="o">=</span> 80,
 protocol      <span class="o">=</span> <span class="s2">"tcp"</span>
 <span class="o">}</span>
 <span class="o">]</span>
 <span class="o">}</span>
 <span class="o">])</span>
<span class="o">}</span>

<span class="c"># Create an ECS Cluster "cluster.tf"</span>
resource <span class="s2">"aws_ecs_cluster"</span> <span class="s2">"zackblog_cluster"</span> <span class="o">{</span>
 name <span class="o">=</span> <span class="s2">"zackblog-cluster"</span>
<span class="o">}</span>

<span class="c"># Configure Networking to Use Default VPC - save cost haha</span>
<span class="c"># use the data block to fetch existing resources</span>
data <span class="s2">"aws_vpc"</span> <span class="s2">"default"</span> <span class="o">{</span>
 default <span class="o">=</span> <span class="nb">true</span>
<span class="o">}</span>

data <span class="s2">"aws_subnet"</span> <span class="s2">"default"</span> <span class="o">{</span>
 filter <span class="o">{</span>
 name   <span class="o">=</span> <span class="s2">"vpc-id"</span>
 values <span class="o">=</span> <span class="o">[</span>data.aws_vpc.default.id]
 <span class="o">}</span>
<span class="o">}</span>

resource <span class="s2">"aws_security_group"</span> <span class="s2">"zackblog_sg"</span> <span class="o">{</span>
 name_prefix <span class="o">=</span> <span class="s2">"zackblog-sg"</span>
 vpc_id      <span class="o">=</span> data.aws_vpc.default.id

 ingress <span class="o">{</span>
 from_port   <span class="o">=</span> 80
 to_port     <span class="o">=</span> 80
 protocol    <span class="o">=</span> <span class="s2">"tcp"</span>
 cidr_blocks <span class="o">=</span> <span class="o">[</span><span class="s2">"0.0.0.0/0"</span><span class="o">]</span>
 <span class="o">}</span>

 egress <span class="o">{</span>
 from_port   <span class="o">=</span> 0
 to_port     <span class="o">=</span> 0
 protocol    <span class="o">=</span> <span class="s2">"-1"</span>
 cidr_blocks <span class="o">=</span> <span class="o">[</span><span class="s2">"0.0.0.0/0"</span><span class="o">]</span>
 <span class="o">}</span>
<span class="o">}</span>

<span class="c"># Define the ECS Service "service.tf"</span>
resource <span class="s2">"aws_ecs_service"</span> <span class="s2">"zackblog_service"</span> <span class="o">{</span>
 name            <span class="o">=</span> <span class="s2">"zackblog-service"</span>
 cluster         <span class="o">=</span> aws_ecs_cluster.zackblog_cluster.id
 task_definition <span class="o">=</span> aws_ecs_task_definition.zackblog_task.arn
 desired_count   <span class="o">=</span> 1
 launch_type     <span class="o">=</span> <span class="s2">"FARGATE"</span>

 network_configuration <span class="o">{</span>
 subnets         <span class="o">=</span> <span class="o">[</span><span class="k">for </span>subnet <span class="k">in </span>data.aws_subnet.default : subnet.id]
 security_groups <span class="o">=</span> <span class="o">[</span>aws_security_group.zackblog_sg.id]
 assign_public_ip <span class="o">=</span> <span class="nb">true</span>
 <span class="o">}</span>
<span class="o">}</span>

<span class="c"># Configure Load Balancer and attach to Fargate service "load_balancer.tf"</span>
resource <span class="s2">"aws_lb"</span> <span class="s2">"zackblog_lb"</span> <span class="o">{</span>
 name               <span class="o">=</span> <span class="s2">"zackblog-lb"</span>
 internal           <span class="o">=</span> <span class="nb">false
 </span>load_balancer_type <span class="o">=</span> <span class="s2">"application"</span>
 security_groups    <span class="o">=</span> <span class="o">[</span>aws_security_group.zackblog_sg.id]
 subnets            <span class="o">=</span> <span class="o">[</span><span class="k">for </span>subnet <span class="k">in </span>data.aws_subnet.default : subnet.id]
<span class="o">}</span>

resource <span class="s2">"aws_lb_target_group"</span> <span class="s2">"zackblog_tg"</span> <span class="o">{</span>
 name     <span class="o">=</span> <span class="s2">"zackblog-tg"</span>
 port     <span class="o">=</span> 80
 protocol <span class="o">=</span> <span class="s2">"HTTP"</span>
 vpc_id   <span class="o">=</span> data.aws_vpc.default.id
<span class="o">}</span>

resource <span class="s2">"aws_lb_listener"</span> <span class="s2">"zackblog_listener"</span> <span class="o">{</span>
 load_balancer_arn <span class="o">=</span> aws_lb.zackblog_lb.arn
 port              <span class="o">=</span> 80
 protocol          <span class="o">=</span> <span class="s2">"HTTP"</span>

 default_action <span class="o">{</span>
 <span class="nb">type</span>             <span class="o">=</span> <span class="s2">"forward"</span>
 target_group_arn <span class="o">=</span> aws_lb_target_group.zackblog_tg.arn
 <span class="o">}</span>
<span class="o">}</span>

resource <span class="s2">"aws_lb_target_group_attachment"</span> <span class="s2">"zackblog_tg_attachment"</span> <span class="o">{</span>
 target_group_arn <span class="o">=</span> aws_lb_target_group.zackblog_tg.arn
 target_id        <span class="o">=</span> aws_ecs_service.zackblog_service.id
 port             <span class="o">=</span> 80
<span class="o">}</span></code></pre></figure>

<ul>
  <li>Github Action Workflow fo CICD</li>
</ul>

<p>1.First we need to create Github Secret to contain dockerhub and aws credentials and some other vars:</p>

<figure class="highlight"><pre><code class="language-shell" data-lang="shell">AWS_ACCESS_KEY_ID

AWS_SECRET_ACCESS_KEY

AWS_REGION

<span class="c"># xxx.dkr.ecr.ap-southeast-2.amazonaws.com</span>
ECR_REGISTRY  

<span class="c"># zackblog-repo</span>
ECR_REPOSITORY  

<span class="c"># zackblog-cluster</span>
ECS_CLUSTER 

<span class="c"># zackblog-service</span>
ECS_SERVICE </code></pre></figure>

<p>2.Then define the workflow to create /.github/workflows/zackblog-fargate.yaml, in this configure Github runner, it will :</p>

<p>Log in to Amazon ECR</p>

<p>Build and push Docker Image to the ECR repository</p>

<p>Deploy to ECS by updating the ECS service to use the new image by forcing a new deployment</p>

<figure class="highlight"><pre><code class="language-yaml" data-lang="yaml"><span class="na">name</span><span class="pi">:</span> <span class="s">Deploy to AWS Fargate</span>

<span class="na">on</span><span class="pi">:</span>
 <span class="na">push</span><span class="pi">:</span>
 <span class="na">branches</span><span class="pi">:</span>
 <span class="pi">-</span> <span class="s">editing  # not main branch</span>

<span class="na">jobs</span><span class="pi">:</span>
 <span class="na">deploy</span><span class="pi">:</span>
 <span class="na">runs-on</span><span class="pi">:</span> <span class="s">ubuntu-latest</span>

 <span class="na">steps</span><span class="pi">:</span>
 <span class="pi">-</span> <span class="na">name</span><span class="pi">:</span> <span class="s">Checkout code</span>
 <span class="na">uses</span><span class="pi">:</span> <span class="s">actions/checkout@v3</span>

 <span class="pi">-</span> <span class="na">name</span><span class="pi">:</span> <span class="s">Set up Docker Buildx</span>
 <span class="na">uses</span><span class="pi">:</span> <span class="s">docker/setup-buildx-action@v2</span>

 <span class="pi">-</span> <span class="na">name</span><span class="pi">:</span> <span class="s">Log in to Amazon ECR</span>
 <span class="na">env</span><span class="pi">:</span>
 <span class="na">AWS_REGION</span><span class="pi">:</span> <span class="s">${{ secrets.AWS_REGION }}</span>
 <span class="na">run</span><span class="pi">:</span> <span class="pi">|</span>
 <span class="s">aws ecr get-login-password --region $AWS_REGION | docker login --username AWS --password-stdin ${{ secrets.ECR_REGISTRY }}</span>

 <span class="s">- name: Build and push Docker image</span>
 <span class="s">env:</span>
 <span class="s">IMAGE_TAG: ${{ github.sha }}</span>
 <span class="s">ECR_REGISTRY: ${{ secrets.ECR_REGISTRY }}</span>
 <span class="s">ECR_REPOSITORY: ${{ secrets.ECR_REPOSITORY }}</span>
 <span class="s">run: |</span>
 <span class="s">docker build -t $ECR_REGISTRY/$ECR_REPOSITORY:$IMAGE_TAG .</span>
 <span class="s">docker push $ECR_REGISTRY/$ECR_REPOSITORY:$IMAGE_TAG</span>

 <span class="s">- name: Deploy to ECS</span>
 <span class="s">env:</span>
 <span class="s">AWS_REGION: ${{ secrets.AWS_REGION }}</span>
 <span class="s">ECS_CLUSTER: ${{ secrets.ECS_CLUSTER }}</span>
 <span class="s">ECS_SERVICE: ${{ secrets.ECS_SERVICE }}</span>
 <span class="s">ECR_REGISTRY: ${{ secrets.ECR_REGISTRY }}</span>
 <span class="s">ECR_REPOSITORY: ${{ secrets.ECR_REPOSITORY }}</span>
 <span class="s">IMAGE_TAG: ${{ github.sha }}</span>
 <span class="s">run: |</span>
 <span class="s">aws ecs update-service --cluster $ECS_CLUSTER --service $ECS_SERVICE --force-new-deployment --region $AWS_REGION</span></code></pre></figure>

<p><b> Conclusion</b></p>

<p>Now we have a seamless incurvature as a code together with CICD pipeline to ensure that the “Zack’s Blog” can be moved to AWS serverless container service Fargate, every time I update the blog by committing changes to “zack-gitops-project” editing branch, a new Docker image will be built, pushed to ECR, and the AWS Fargate service is automatically updated.  </p>]]></content><author><name></name></author><category term="jekyll" /><category term="Cat2" /><summary type="html"><![CDATA[Why go serverless]]></summary></entry><entry><title type="html">Automate Package Deployment via AWS System Manager</title><link href="http://localhost:4000/jekyll/cat2/2024/06/23/aws-ssm.html" rel="alternate" type="text/html" title="Automate Package Deployment via AWS System Manager" /><published>2024-06-23T10:15:29+10:00</published><updated>2024-06-23T10:15:29+10:00</updated><id>http://localhost:4000/jekyll/cat2/2024/06/23/aws-ssm</id><content type="html" xml:base="http://localhost:4000/jekyll/cat2/2024/06/23/aws-ssm.html"><![CDATA[<p><b>The task</b></p>

<p>Recently we got a task from the Company’s security team, to install 2 security agents which will be used to perform centralized security scans for all active AWS EC2 instances. here I will see how to use AWS Systems Manager for software distribution and installation for multiple AWS accounts and infrastructure at scale.</p>

<p>SSM features will be used :</p>

<ul>
  <li><b>Session Manager</b>: ensure the EC2 instance has the SSM Agent installed and running and The instances need an IAM role with at least the <code class="language-plaintext highlighter-rouge">AmazonSSMManagedInstanceCore</code> policy attached  </li>
  <li><b>Run Command</b>: send command and execute security agent software package installation scripts and command to varify post-installation status on remote instances for task automation</li>
</ul>

<p>Prerequisites:</p>
<ul>
  <li>
    <p><b>AWSCLI</b>: programatically manage all the operation bellow.</p>
  </li>
  <li>
    <p><b>SSM Agent</b>: Ensure the SSM Agent is installed and running on all EC2 instances. Most Amazon Machine Images (AMIs) have the SSM Agent pre-installed.</p>
  </li>
  <li>
    <p><b>IAM Role</b>: Attach an IAM role to each instance with the AmazonSSMManagedInstanceCore policy.</p>
  </li>
</ul>

<p>Create and attach IAM role to EC2 instance for SSM to be able to perform action:</p>

<figure class="highlight"><pre><code class="language-shell" data-lang="shell"><span class="o">[</span>cloudshell-user@ip-10-134-56-72 ~]<span class="nv">$ </span>vim trust-policy.json

<span class="o">{</span>
 <span class="s2">"Version"</span>: <span class="s2">"2012-10-17"</span>,
 <span class="s2">"Statement"</span>: <span class="o">[</span>
 <span class="o">{</span>
 <span class="s2">"Effect"</span>: <span class="s2">"Allow"</span>,
 <span class="s2">"Principal"</span>: <span class="o">{</span>
 <span class="s2">"Service"</span>: <span class="s2">"ec2.amazonaws.com"</span>
 <span class="o">}</span>,
 <span class="s2">"Action"</span>: <span class="s2">"sts:AssumeRole"</span>
 <span class="o">}</span>
 <span class="o">]</span>
<span class="o">}</span>

<span class="o">[</span>cloudshell-user@ip-10-134-56-72 ~]<span class="nv">$ </span>aws iam create-role <span class="nt">--role-name</span> SSMAccessRole <span class="nt">--assume-role-policy-document</span> file://trust-policy.json
<span class="o">{</span>
 <span class="s2">"Role"</span>: <span class="o">{</span>
 <span class="s2">"Path"</span>: <span class="s2">"/"</span>,
 <span class="s2">"RoleName"</span>: <span class="s2">"SSMAccessRole"</span>,
 <span class="s2">"RoleId"</span>: <span class="s2">"AROA4MTWLTSHKK3QL3NOU"</span>,
 <span class="s2">"Arn"</span>: <span class="s2">"arn:aws:iam::85xxxxxx1342:role/SSMAccessRole"</span>,
 <span class="s2">"CreateDate"</span>: <span class="s2">"2024-06-25T00:29:07+00:00"</span>,
 <span class="s2">"AssumeRolePolicyDocument"</span>: <span class="o">{</span>
 <span class="s2">"Version"</span>: <span class="s2">"2012-10-17"</span>,
 <span class="s2">"Statement"</span>: <span class="o">[</span>
 <span class="o">{</span>
 <span class="s2">"Effect"</span>: <span class="s2">"Allow"</span>,
 <span class="s2">"Principal"</span>: <span class="o">{</span>
 <span class="s2">"Service"</span>: <span class="s2">"ec2.amazonaws.com"</span>
 <span class="o">}</span>,
 <span class="s2">"Action"</span>: <span class="s2">"sts:AssumeRole"</span>
 <span class="o">}</span>
 <span class="o">]</span>
 <span class="o">}</span>
 <span class="o">}</span>
<span class="o">}</span>

<span class="o">[</span>cloudshell-user@ip-10-134-56-72 ~]<span class="nv">$ </span>aws iam attach-role-policy <span class="nt">--role-name</span> SSMAccessRole <span class="nt">--policy-arn</span> arn:aws:iam::aws:policy/AmazonSSMManagedInstanceCore

<span class="o">[</span>cloudshell-user@ip-10-134-56-72 ~]<span class="nv">$ </span>aws iam create-instance-profile <span class="nt">--instance-profile-name</span> SSMInstanceProfile
<span class="o">{</span>
 <span class="s2">"InstanceProfile"</span>: <span class="o">{</span>
 <span class="s2">"Path"</span>: <span class="s2">"/"</span>,
 <span class="s2">"InstanceProfileName"</span>: <span class="s2">"SSMInstanceProfile"</span>,
 <span class="s2">"InstanceProfileId"</span>: <span class="s2">"AIPA4MTWLTSHF7KJRFLYC"</span>,
 <span class="s2">"Arn"</span>: <span class="s2">"arn:aws:iam::851xxxxxxx42:instance-profile/SSMInstanceProfile"</span>,
 <span class="s2">"CreateDate"</span>: <span class="s2">"2024-06-25T00:31:25+00:00"</span>,
 <span class="s2">"Roles"</span>: <span class="o">[]</span>
 <span class="o">}</span>
<span class="o">}</span>

<span class="o">[</span>cloudshell-user@ip-10-134-56-72 ~]<span class="nv">$ INSTANCE_IDS</span><span class="o">=</span><span class="si">$(</span>aws ec2 describe-instances <span class="nt">--query</span> <span class="s2">"Reservations[*].Instances[*].InstanceId"</span> <span class="nt">--output</span> text<span class="si">)</span>
<span class="k">for </span>INSTANCE_ID <span class="k">in</span> <span class="nv">$INSTANCE_IDS</span><span class="p">;</span> <span class="k">do</span>
<span class="o">&gt;</span> aws ec2 associate-iam-instance-profile <span class="nt">--instance-id</span> <span class="nv">$INSTANCE_ID</span> <span class="nt">--iam-instance-profile</span> <span class="nv">Name</span><span class="o">=</span>SSMInstanceProfile
<span class="o">&gt;</span> <span class="k">done</span>

<span class="o">{</span>
 <span class="s2">"IamInstanceProfileAssociation"</span>: <span class="o">{</span>
 <span class="s2">"AssociationId"</span>: <span class="s2">"iip-assoc-04e81626bf6bcd9b5"</span>,
 <span class="s2">"InstanceId"</span>: <span class="s2">"i-0762xxxxxxxcf2"</span>,
 <span class="s2">"IamInstanceProfile"</span>: <span class="o">{</span>
 <span class="s2">"Arn"</span>: <span class="s2">"arn:aws:iam::8517xxxxxxx42:instance-profile/SSMInstanceProfile"</span>,
 <span class="s2">"Id"</span>: <span class="s2">"AIPA4MTWLTSHF7KJRFLYC"</span>
 <span class="o">}</span>,
 <span class="s2">"State"</span>: <span class="s2">"associating"</span>
 <span class="o">}</span>
<span class="o">}</span>
<span class="o">{</span>
 <span class="s2">"IamInstanceProfileAssociation"</span>: <span class="o">{</span>
 <span class="s2">"AssociationId"</span>: <span class="s2">"iip-assoc-09233165b3a53ca68"</span>,
 <span class="s2">"InstanceId"</span>: <span class="s2">"i-01a2xxxxxx048c"</span>,
 <span class="s2">"IamInstanceProfile"</span>: <span class="o">{</span>
 <span class="s2">"Arn"</span>: <span class="s2">"arn:aws:iam::851xxxx42:instance-profile/SSMInstanceProfile"</span>,
 <span class="s2">"Id"</span>: <span class="s2">"AIPA4MTWLTSHF7KJRFLYC"</span>
 <span class="o">}</span>,
 <span class="s2">"State"</span>: <span class="s2">"associating"</span>
 <span class="o">}</span>
<span class="o">}</span>
<span class="o">{</span>
 <span class="s2">"IamInstanceProfileAssociation"</span>: <span class="o">{</span>
 <span class="s2">"AssociationId"</span>: <span class="s2">"iip-assoc-09236a8ee456e39cd"</span>,
 <span class="s2">"InstanceId"</span>: <span class="s2">"i-07axxxxxxb823"</span>,
 <span class="s2">"IamInstanceProfile"</span>: <span class="o">{</span>
 <span class="s2">"Arn"</span>: <span class="s2">"arn:aws:iam::85xxxxxxx42:instance-profile/SSMInstanceProfile"</span>,
 <span class="s2">"Id"</span>: <span class="s2">"AIPA4MTWLTSHF7KJRFLYC"</span>
 <span class="o">}</span>,
 <span class="s2">"State"</span>: <span class="s2">"associating"</span>
 <span class="o">}</span>
<span class="o">}</span>

<span class="o">[</span>cloudshell-user@ip-10-134-56-72 ~]<span class="nv">$ </span>aws ssm describe-instance-information</code></pre></figure>

<p>Now verify from session manager to see if instances are there:</p>

<p><img src="/assets/ssm1.png" alt="image tooltip here" /></p>

<ul>
  <li>Tag Instances</li>
</ul>

<p>Tag EC2 instances to identify which instances need the security agent to be installed:</p>

<figure class="highlight"><pre><code class="language-shell" data-lang="shell"><span class="nv">Key</span><span class="o">=</span>InstallSecurityAgent, <span class="nv">Value</span><span class="o">=</span>True.</code></pre></figure>

<figure class="highlight"><pre><code class="language-shell" data-lang="shell"><span class="c"># List all instance IDs #: </span>
<span class="nv">INSTANCE_IDS</span><span class="o">=</span><span class="si">$(</span>aws ec2 describe-instances <span class="nt">--query</span> <span class="s2">"Reservations[*].Instances[*].InstanceId"</span> <span class="nt">--output</span> text<span class="si">)</span>

<span class="c"># Tag all instances with Key=InstallSecurityAgent and Value=True</span>
<span class="k">for </span>INSTANCE_ID <span class="k">in</span> <span class="nv">$INSTANCE_IDS</span><span class="p">;</span> <span class="k">do
 </span>aws ec2 create-tags <span class="nt">--resources</span> <span class="nv">$INSTANCE_ID</span> <span class="nt">--tags</span> <span class="nv">Key</span><span class="o">=</span>InstallSecurityAgent,Value<span class="o">=</span>True
<span class="k">done</span></code></pre></figure>

<ul>
  <li>SSM Run Command to Create a custom SSM document that contains the script to install the security agent</li>
</ul>

<figure class="highlight"><pre><code class="language-shell" data-lang="shell"><span class="o">[</span>cloudshell-user@ip-10-134-56-72 ~]<span class="nv">$ </span>vim install_security_agent.json
<span class="o">{</span>
 <span class="s2">"schemaVersion"</span>: <span class="s2">"2.2"</span>,
 <span class="s2">"description"</span>: <span class="s2">"Install Security Agent"</span>,
 <span class="s2">"mainSteps"</span>: <span class="o">[</span>
 <span class="o">{</span>
 <span class="s2">"action"</span>: <span class="s2">"aws:runShellScript"</span>,
 <span class="s2">"name"</span>: <span class="s2">"installSecurityAgent"</span>,
 <span class="s2">"inputs"</span>: <span class="o">{</span>
 <span class="s2">"runCommand"</span>: <span class="o">[</span>
 <span class="s2">"curl -o /tmp/security-agent-installer.sh https://github.com/ZackZhouHB/zack-gitops-project/blob/editing/Python_scripts/security-agent-installer.sh"</span>,
 <span class="s2">"chmod +x /tmp/security-agent-installer.sh"</span>,
 <span class="s2">"/tmp/security-agent-installer.sh"</span>
 <span class="o">]</span>
 <span class="o">}</span>
 <span class="o">}</span>
 <span class="o">]</span>
<span class="o">}</span></code></pre></figure>

<p>Create Document to execute the installation script on all tagged instances.</p>

<figure class="highlight"><pre><code class="language-shell" data-lang="shell"><span class="o">[</span>cloudshell-user@ip-10-134-56-72 ~]<span class="nv">$ </span>aws ssm create-document <span class="se">\</span>
 <span class="nt">--name</span> <span class="s2">"InstallSecurityAgent"</span> <span class="se">\</span>
 <span class="nt">--document-type</span> <span class="s2">"Command"</span> <span class="se">\</span>
 <span class="nt">--content</span> file://install_security_agent.json

<span class="o">{</span>
 <span class="s2">"DocumentDescription"</span>: <span class="o">{</span>
 <span class="s2">"Hash"</span>: <span class="s2">"9e17a699d2d987134eb05f6b49a7c837161320b0ed42635b07928acc557970b5"</span>,
 <span class="s2">"HashType"</span>: <span class="s2">"Sha256"</span>,
 <span class="s2">"Name"</span>: <span class="s2">"InstallSecurityAgent"</span>,
 <span class="s2">"Owner"</span>: <span class="s2">"851725491342"</span>,
 <span class="s2">"CreatedDate"</span>: <span class="s2">"2024-06-25T01:51:36.666000+00:00"</span>,
 <span class="s2">"Status"</span>: <span class="s2">"Creating"</span>,
 <span class="s2">"DocumentVersion"</span>: <span class="s2">"1"</span>,
 <span class="s2">"Description"</span>: <span class="s2">"Install Security Agent"</span>,
 <span class="s2">"PlatformTypes"</span>: <span class="o">[</span>
 <span class="s2">"Linux"</span>,
 <span class="s2">"MacOS"</span>
 <span class="o">]</span>,
 <span class="s2">"DocumentType"</span>: <span class="s2">"Command"</span>,
 <span class="s2">"SchemaVersion"</span>: <span class="s2">"2.2"</span>,
 <span class="s2">"LatestVersion"</span>: <span class="s2">"1"</span>,
 <span class="s2">"DefaultVersion"</span>: <span class="s2">"1"</span>,
 <span class="s2">"DocumentFormat"</span>: <span class="s2">"JSON"</span>,
 <span class="s2">"Tags"</span>: <span class="o">[]</span>
 <span class="o">}</span>
<span class="o">}</span>

<span class="o">[</span>cloudshell-user@ip-10-132-90-150 ~]<span class="nv">$ </span>aws ssm send-command <span class="se">\</span>
<span class="o">&gt;</span> <span class="nt">--document-name</span> <span class="s2">"InstallSecurityAgent"</span> <span class="se">\</span>
<span class="o">&gt;</span> <span class="nt">--targets</span> <span class="s2">"Key=tag:InstallSecurityAgent,Values=True"</span> <span class="se">\</span>
<span class="o">&gt;</span> <span class="nt">--comment</span> <span class="s2">"Installing security agent on all instances with the specified tag"</span> <span class="se">\</span>
<span class="o">&gt;</span> <span class="nt">--max-concurrency</span> <span class="s2">"50"</span> <span class="se">\</span>
<span class="o">&gt;</span> <span class="nt">--max-errors</span> <span class="s2">"0"</span> <span class="se">\</span>
<span class="o">&gt;</span> <span class="nt">--region</span> ap-southeast-2
<span class="o">{</span>
 <span class="s2">"Command"</span>: <span class="o">{</span>
 <span class="s2">"CommandId"</span>: <span class="s2">"edfc9e9b-5e74-4660-8335-a98eb48251f7"</span>,
 <span class="s2">"DocumentName"</span>: <span class="s2">"InstallSecurityAgent"</span>,
 <span class="s2">"DocumentVersion"</span>: <span class="s2">"</span><span class="nv">$DEFAULT</span><span class="s2">"</span>,
 <span class="s2">"Comment"</span>: <span class="s2">"Installing security agent on all instances with the specified tag"</span>,
 <span class="s2">"ExpiresAfter"</span>: <span class="s2">"2024-06-25T04:03:44.665000+00:00"</span>,
 <span class="s2">"Parameters"</span>: <span class="o">{}</span>,
 <span class="s2">"InstanceIds"</span>: <span class="o">[]</span>,
 <span class="s2">"Targets"</span>: <span class="o">[</span>
 <span class="o">{</span>
 <span class="s2">"Key"</span>: <span class="s2">"tag:InstallSecurityAgent"</span>,
 <span class="s2">"Values"</span>: <span class="o">[</span>
 <span class="s2">"True"</span>
 <span class="o">]</span>
 <span class="o">}</span>
 <span class="o">]</span>,
 <span class="s2">"RequestedDateTime"</span>: <span class="s2">"2024-06-25T02:03:44.665000+00:00"</span>,
 <span class="s2">"Status"</span>: <span class="s2">"Pending"</span>,
 <span class="s2">"StatusDetails"</span>: <span class="s2">"Pending"</span>,
 <span class="s2">"OutputS3Region"</span>: <span class="s2">"ap-southeast-2"</span>,
 <span class="s2">"OutputS3BucketName"</span>: <span class="s2">""</span>,
 <span class="s2">"OutputS3KeyPrefix"</span>: <span class="s2">""</span>,
 <span class="s2">"MaxConcurrency"</span>: <span class="s2">"50"</span>,
 <span class="s2">"MaxErrors"</span>: <span class="s2">"0"</span>,
 <span class="s2">"TargetCount"</span>: 0,
 <span class="s2">"CompletedCount"</span>: 0,
 <span class="s2">"ErrorCount"</span>: 0,
 <span class="s2">"DeliveryTimedOutCount"</span>: 0,
 <span class="s2">"ServiceRole"</span>: <span class="s2">""</span>,
 <span class="s2">"NotificationConfig"</span>: <span class="o">{</span>
 <span class="s2">"NotificationArn"</span>: <span class="s2">""</span>,
 <span class="s2">"NotificationEvents"</span>: <span class="o">[]</span>,
 <span class="s2">"NotificationType"</span>: <span class="s2">""</span>
 <span class="o">}</span>,
 <span class="s2">"CloudWatchOutputConfig"</span>: <span class="o">{</span>
 <span class="s2">"CloudWatchLogGroupName"</span>: <span class="s2">""</span>,
 <span class="s2">"CloudWatchOutputEnabled"</span>: <span class="nb">false</span>
 <span class="o">}</span>,
 <span class="s2">"TimeoutSeconds"</span>: 3600,
 <span class="s2">"AlarmConfiguration"</span>: <span class="o">{</span>
 <span class="s2">"IgnorePollAlarmFailure"</span>: <span class="nb">false</span>,
 <span class="s2">"Alarms"</span>: <span class="o">[]</span>
 <span class="o">}</span>,
 <span class="s2">"TriggeredAlarms"</span>: <span class="o">[]</span>
 <span class="o">}</span>
<span class="o">}</span>
<span class="o">(</span>END<span class="o">)</span></code></pre></figure>

<p>Validate from Run Command console for the installation:
<img src="/assets/ssm2.png" alt="image tooltip here" /></p>

<p>Create an SSM Document to Check the package installation status:</p>

<figure class="highlight"><pre><code class="language-shell" data-lang="shell"><span class="o">[</span>cloudshell-user@ip-10-134-56-72 ~]<span class="nv">$ </span>vim verify.json

<span class="o">{</span>
 <span class="s2">"schemaVersion"</span>: <span class="s2">"2.2"</span>,
 <span class="s2">"description"</span>: <span class="s2">"Install Security Agent"</span>,
 <span class="s2">"mainSteps"</span>: <span class="o">[</span>
 <span class="o">{</span>
 <span class="s2">"action"</span>: <span class="s2">"aws:runShellScript"</span>,
 <span class="s2">"name"</span>: <span class="s2">"installSecurityAgent"</span>,
 <span class="s2">"inputs"</span>: <span class="o">{</span>
 <span class="s2">"runCommand"</span>: <span class="o">[</span>
 <span class="s2">"apt list --installed | grep nfs-common"</span>,
 <span class="s2">"apt list --installed | grep lrzsz"</span>
 <span class="o">]</span>
 <span class="o">}</span>
 <span class="o">}</span>
 <span class="o">]</span>
<span class="o">}</span></code></pre></figure>

<p>Create this document using the AWS CLI:</p>

<figure class="highlight"><pre><code class="language-shell" data-lang="shell"><span class="o">[</span>cloudshell-user@ip-10-134-56-72 ~]<span class="nv">$ </span>aws ssm create-document <span class="se">\</span>
 <span class="nt">--name</span> <span class="s2">"VerifyPackageInstallation"</span> <span class="se">\</span>
 <span class="nt">--document-type</span> <span class="s2">"Command"</span> <span class="se">\</span>
 <span class="nt">--content</span> file://verify.json

<span class="o">[</span>cloudshell-user@ip-10-134-56-72 ~]<span class="nv">$ </span>aws ssm send-command <span class="se">\</span>
 <span class="nt">--document-name</span> <span class="s2">"VerifyPackageInstallation"</span> <span class="se">\</span>
 <span class="nt">--targets</span> <span class="s2">"Key=tag:InstallSecurityAgent,Values=True"</span> <span class="se">\</span>
 <span class="nt">--comment</span> <span class="s2">"Check if Packages installed on all instances"</span> <span class="se">\</span>
 <span class="nt">--max-concurrency</span> <span class="s2">"50"</span> <span class="se">\</span>
 <span class="nt">--max-errors</span> <span class="s2">"0"</span> <span class="se">\</span>
 <span class="nt">--region</span> ap-southeast-2</code></pre></figure>

<p>Verify both “nfs-common” and “lrzsz”, we have 3 machines with “nfs-common” installed, and 2 instances with Ubuntu24.04 which did not get “lrzsz” installed.</p>

<p><img src="/assets/ssm3.png" alt="image tooltip here" /></p>

<p><img src="/assets/ssm4.png" alt="image tooltip here" /></p>

<p><b> Conclusion</b></p>

<p>So now we can use AWS CLI and AWS System Manager to automate software deployment and verify the installation status.</p>]]></content><author><name></name></author><category term="jekyll" /><category term="Cat2" /><summary type="html"><![CDATA[The task]]></summary></entry><entry><title type="html">Handling a RDS MySQL cluster CPU 100%</title><link href="http://localhost:4000/jekyll/cat2/2024/06/17/mysql-cup100.html" rel="alternate" type="text/html" title="Handling a RDS MySQL cluster CPU 100%" /><published>2024-06-17T10:15:29+10:00</published><updated>2024-06-17T10:15:29+10:00</updated><id>http://localhost:4000/jekyll/cat2/2024/06/17/mysql-cup100</id><content type="html" xml:base="http://localhost:4000/jekyll/cat2/2024/06/17/mysql-cup100.html"><![CDATA[<p><b>The Incident</b></p>

<p>Today I got a performance issue from our analytic team, saying they experienced a Production MySQL cluster running on RDS very slow since yesterday morning.  </p>

<p>I started to look into bellow areas for investigation:</p>

<ul>
  <li>AWS CloudWatch Metrics for RDS</li>
</ul>

<p>AWS CloudWatch provides a wide range of metrics that can help diagnose resource usage for databases. So I started with</p>

<p><em>CloudWatch - Metrics - All metrics - Add query - RDS - Top 10 RDS instances by highest CPU utilization</em></p>

<p>This only queries the recent 3 hours metrics, but it is enough for me to identify the issue: CPU 100%</p>

<p><img src="/assets/mysqlcpu1.png" alt="image tooltip here" /></p>

<p>To further understand the high CUP, I go:</p>

<p><em>CloudWatch - Metrics - All metrics - Browse - RDS - DBClusterIdentifier - CPUUtilization</em></p>

<p>which gives me a long period of monitoring, so I can see it started to 100% CPU since yesterday morning.</p>

<p><img src="/assets/mysqlcpu2.png" alt="image tooltip here" /></p>

<ul>
  <li>AWS console RDS Logs &amp; events</li>
</ul>

<p>Now let’s find out from the RDS logs to see if any errors can indicate who could be the person. So I go</p>

<p><em>RDS - “the DB cluster” - “the DB instance” - “Logs &amp; events” - “error/mysql-error-running.log.2024-06-18.02”</em></p>

<p>I got :</p>

<figure class="highlight"><pre><code class="language-shell" data-lang="shell">2024-06-18T00:04:58.750212Z 2831474 <span class="o">[</span>Note] Aborted connection 2831474 to db: <span class="s1">'xxxxxx'</span> user: <span class="s1">'xxxx'</span> host: <span class="s1">'10.xx.xx.xx'</span> <span class="o">(</span>Unknown error<span class="o">)</span>
2024-06-18T00:12:00.798173Z 2831498 <span class="o">[</span>Note] Aborted connection 2831498 to db: <span class="s1">'xxxx'</span> user: <span class="s1">'xxxx'</span> host: <span class="s1">'10.xx.xx.xx'</span> <span class="o">(</span>Got an error writing communication packets<span class="o">)</span>
<span class="nt">-----------------------</span> END OF LOG <span class="nt">----------------------</span></code></pre></figure>

<p>Up to here I generally have an idea of what is going on and can locate the person “xxxx” who was running something at the time CPU 100%.</p>

<ul>
  <li>MySQL Client Tool to list, identiry and terminate long-running queries</li>
</ul>

<p>It is time to log in to the RDS endpoint to see what is happening and which queries might cause the CPU usage. Here we need login via MySQL “root” to be able to see all other users’ running processes. Then pay attention to the high “Time” and “State” values indicating all the stuck processes, then we kill them and restart the RDS instance</p>

<figure class="highlight"><pre><code class="language-shell" data-lang="shell">mysql <span class="nt">-u</span> root <span class="nt">-p</span> <span class="nt">-h</span> rds_endpoint
SHOW PROCESSLIST<span class="p">;</span>
KILL &lt;process_id&gt;<span class="p">;</span></code></pre></figure>

<p><img src="/assets/mysqlcpu4.png" alt="image tooltip here" /></p>

<p>Then I go <em>AWS RDS console - Actions - Reboot</em> the RDS instance.</p>

<ul>
  <li>Now the CPU usage started to drop and back to normal after terminating the stuck processes and DB instance reboot.</li>
</ul>

<p><img src="/assets/mysqlcpu3.png" alt="image tooltip here" /></p>

<p>Done.</p>

<p><b> Conclusion</b></p>

<p>Even the issue had been fixed, I was still thinking how to better monitor RDS resource usage. I think we need:</p>

<ul>
  <li>
    <p>A “CloudWatch Alarm” to set “CPUUtilization” metric threshold to 80%, then specify the period (e.g., 5 minutes) and the number of periods (e.g., 2 out of 3) that the metric must breach the threshold to trigger the alarm.</p>
  </li>
  <li>
    <p>Create “SNS topic” with team Email for the alarm to send a notification</p>
  </li>
  <li>
    <p>Enable “RDS Performance Insights”, this can monitor the load on the database, identify the source of bottlenecks, and understand how the DB is performing, especially during troubleshooting.</p>
  </li>
  <li>
    <p>Enable “Enhanced Monitoring” and select the monitoring interval (e.g., 1 minute), which provides real-time metrics for the operating system that the DB instance runs on, this helps for immediate investigation on OS level</p>
  </li>
  <li>
    <p>Enable “Slow Query Log” for regularly analysing slow query logs and performance insights to optimize RDS database queries, identify queries that take a long time to execute, use tools like EXPLAIN to understand query performance, add appropriate indexes, and then ultimately rewrite queries for better performance.</p>
  </li>
</ul>]]></content><author><name></name></author><category term="jekyll" /><category term="Cat2" /><summary type="html"><![CDATA[The Incident]]></summary></entry></feed>