<?xml version="1.0" encoding="utf-8"?><feed xmlns="http://www.w3.org/2005/Atom" ><generator uri="https://jekyllrb.com/" version="4.3.2">Jekyll</generator><link href="http://localhost:4000/feed.xml" rel="self" type="application/atom+xml" /><link href="http://localhost:4000/" rel="alternate" type="text/html" /><updated>2024-07-19T01:06:18+10:00</updated><id>http://localhost:4000/feed.xml</id><title type="html">Zack’s Blog</title><subtitle>## AWS   ## Jenkins  ## Microservices ## Automation ## K8S   ## CICD     ## Gitops </subtitle><entry><title type="html">RedHat Identity Management (IdM) with AD Intergration</title><link href="http://localhost:4000/jekyll/cat2/2024/07/13/Redhatidm.html" rel="alternate" type="text/html" title="RedHat Identity Management (IdM) with AD Intergration" /><published>2024-07-13T10:15:29+10:00</published><updated>2024-07-13T10:15:29+10:00</updated><id>http://localhost:4000/jekyll/cat2/2024/07/13/Redhatidm</id><content type="html" xml:base="http://localhost:4000/jekyll/cat2/2024/07/13/Redhatidm.html"><![CDATA[<p><b> About Linux Identity Management </b></p>

<p>When a company faces challenge to manage its Linux environments across local and public cloud, RedHat Identity management can be the solution to achieve:</p>

<ul>
  <li>
    <p>With Local AD and Azure AD (AAD) Integration</p>
  </li>
  <li>
    <p>With AWS SSO Integration as externel identity provider</p>
  </li>
  <li>
    <p>LDAP, Kerberos and NTP</p>
  </li>
  <li>
    <p>A web-based management front-end running on Apache</p>
  </li>
</ul>

<p><b> A Typical AD User Authentication Flow End-to-End: </b></p>

<p>User Creation and Management:</p>

<ul>
  <li>
    <p>Azure AD / Local AD: Users are created in the Azure Active Directory or local Active Directory.</p>
  </li>
  <li>
    <p>Synchronization to RedHat IdM: The users are synchronized from AD to RedHat IdM using the two-way trust established between AD and IdM.</p>
  </li>
</ul>

<p>Accessing EC2 Instances via SSH:</p>

<ul>
  <li>User Sync to RedHat IdM: Users synchronized to RedHat IdM are assigned roles and permissions, including SSH access to specific EC2 instances.</li>
</ul>

<p>Host-Based Access Control (HBAC):</p>

<ul>
  <li>
    <p>HBAC Rules: RedHat IdM enforces HBAC rules to control which users can access specific EC2 instances.</p>
  </li>
  <li>
    <p>SSH Access Control: When a user attempts to SSH into an EC2 instance, RedHat IdM verifies the user’s identity and permissions, allowing or denying access based on the defined HBAC rules.</p>
  </li>
</ul>

<p><b> The design:</b></p>

<p>For Idm on AWS, configure the security groups to allow ports required by IdM. IdM desires below to be open:</p>

<p>HTTP/HTTPS — 80, 443 — TCP</p>

<p>LDAP/LDAPS — 389, 636 — TCP</p>

<p>Kerberos — 88, 464 — Both TCP and UDP</p>

<p>DNS — 53 — Both TCP and UDP</p>

<p>NTP — 123 — UDP</p>

<p>Here I am going to:</p>

<ul>
  <li>
    <p>install and configure a local freeIPA server</p>
  </li>
  <li>
    <p>enroll 2 Linux client machines (both CentOS and Ubuntu)</p>
  </li>
  <li>
    <p>Setup a local AD,</p>
  </li>
  <li>
    <p>build a 2 way trust between idm and AD</p>
  </li>
  <li>
    <p>Validate IDM and AD user to ssh into idm client machines.</p>
  </li>
</ul>

<p><b> Prerequisites: </b></p>

<ul>
  <li>
    <p>Windows AD Domain <b> ad.zack.world</b> and Idm Domain <b> ipa.zack.world</b></p>
  </li>
  <li>
    <p>Windows AD: 11.0.1.181 dc01.ad.zack.world (win server 2019)</p>
  </li>
  <li>
    <p>Windows client1: 11.0.1.182 win-client.ad.zack.world (win server 2019)</p>
  </li>
  <li>
    <p>idm Server: 11.0.1.180 server1.ipa.zack.world (CentOS 9)</p>
  </li>
  <li>
    <p>idm Client2: 11.0.1.184 ubt-client02.ipa.zack.world (Ubuntu 24.04)</p>
  </li>
  <li>
    <p>idm Client3: 11.0.1.185 idm-client3-centos7.ipa.zack.world (CentOS 9)</p>
  </li>
</ul>

<p><b> FreeIPA Installation </b></p>

<p>On freeIPA Server server1.ipa.zack.world 11.0.1.180 (CentOS 9):</p>

<figure class="highlight"><pre><code class="language-shell" data-lang="shell"><span class="c"># set hostname, IP and DNS</span>
hostnamectl set-hostname server1.ipa.zack.world

<span class="c"># add 3 hosts to /etc/hosts</span>
<span class="nb">echo </span>11.0.1.180 server1.ipa.zack.world  ipa <span class="o">&gt;&gt;</span> /etc/hosts
<span class="nb">echo </span>11.0.1.184 ubt-client02.ipa.zack.world ipa <span class="o">&gt;&gt;</span> /etc/hosts
<span class="nb">echo </span>11.0.1.185  idm-client3-centos7.ipa.zack.world  ipa <span class="o">&gt;&gt;</span> /etc/hosts
<span class="nb">echo </span>11.0.1.181  dc01.ad.zack.world ipa <span class="o">&gt;&gt;</span> /etc/hosts

<span class="c"># install ipa-server</span>
dnf <span class="nt">-y</span> <span class="nb">install </span>freeipa-server freeipa-server-dns freeipa-client

<span class="c"># Configure ipa-server and DNS, here set ipa console and domain admin password</span>
ipa-server-install <span class="nt">--setup-dns</span>

<span class="c"># confirm or change NetBIOS domain name</span>
NetBIOS domain name <span class="o">[</span>IPA]: IPA01

The ipa-server-install <span class="nb">command </span>was successful.

<span class="c"># Configure firewall rules and services</span>
firewall-cmd <span class="nt">--add-service</span><span class="o">={</span>freeipa-ldap,freeipa-ldaps,dns,ntp<span class="o">}</span>
firewall-cmd <span class="nt">--runtime-to-permanent</span>
firewall-cmd <span class="nt">--reload</span> 

<span class="c"># check ipastatus</span>
<span class="o">[</span>root@freeipa ~]# ipactl status
Directory Service: RUNNING
krb5kdc Service: RUNNING
kadmin Service: RUNNING
httpd Service: RUNNING
ipa-custodia Service: RUNNING
ntpd Service: RUNNING
pki-tomcatd Service: RUNNING
ipa-otpd Service: RUNNING
ipa: INFO: The ipactl <span class="nb">command </span>was successful

<span class="c"># Obtain a Kerberos ticket for the Kerberos admin user and Verify the ticket</span>
kinit admin
klist

Ticket cache: KEYRING:persistent:0:0
Default principal: admin@ZACKZ.OONLINE

Valid starting     Expires            Service principal
07/13/24 22:17:29  07/14/24 22:02:43  HTTP/server1.ipa.zack.world@IPA.ZACK.WORLD

<span class="c"># check content of /etc/resolv.conf</span>
<span class="nb">cat</span> /etc/resolv.conf
search ipa.zack.world
nameserver 127.0.0.1

<span class="c"># Configure default login shell to Bash and Create User tina</span>
ipa config-mod <span class="nt">--defaultshell</span><span class="o">=</span>/bin/bash
ipa user-add tina <span class="nt">--first</span><span class="o">=</span>tina <span class="nt">--last</span><span class="o">=</span>qi <span class="nt">--password</span></code></pre></figure>

<p><img src="/assets/idm3.png" alt="image tooltip here" /></p>

<p><b> Idm client Enrollment </b></p>

<p>Now the idm web portal should be accessible, by adding “11.0.1.180 server1.ipa.zack.world” into local “c:/wondows/system32/drivers/etc/hosts.</p>

<p>Then enrol both centos and Ubuntu IDM client machines</p>

<ul>
  <li>On FreeIPA Server, add DNS entry for FreeIPA Client machines</li>
</ul>

<figure class="highlight"><pre><code class="language-shell" data-lang="shell"><span class="c"># ipa dnsrecord-add [domain name] [record name] [record type] [record]</span>
ipa dnsrecord-add ipa.zack.world idm-client3-centos7 <span class="nt">--a-rec</span> 11.0.1.185
ipa dnsrecord-add ipa.zack.world ubt-client02 <span class="nt">--a-rec</span> 11.0.1.184

- <span class="nb">set </span>IP, <span class="nb">hostname</span>, DNS on idm client
<span class="c"># set idm server ID as client DNS</span>
nmcli connection modify ens33 ipv4.dns 11.0.1.180
nmcli connection up ens33

<span class="c"># Install FreeIPA Client packages.</span>
dnf <span class="nt">-y</span> <span class="nb">install </span>freeipa-client

<span class="c"># enrol client to idm server with domain name</span>
ipa-client-install <span class="nt">--server</span><span class="o">=</span>server1.ipa.zack.world <span class="nt">--domain</span> ipa.zack.world

Enrolled <span class="k">in </span>IPA realm IPA.ZACK.WORLD
Configuring ipa.zack.world as NIS domain.
Client configuration complete.
The ipa-client-install <span class="nb">command </span>was successful

<span class="c"># set create home directory at initial login</span>
authselect enable-feature with-mkhomedir
systemctl <span class="nb">enable</span> <span class="nt">--now</span> oddjobd

<span class="c"># same as Ubuntu client</span>
<span class="nb">echo </span>11.0.1.180 server1.ipa.zack.world server1 <span class="o">&gt;&gt;</span> /etc/hosts
<span class="nb">echo </span>11.0.1.184 ubt-client02.ipa.zack.world ubt-client02 <span class="o">&gt;&gt;</span> /etc/hosts
<span class="nb">echo </span>11.0.1.185 idm-client3-centos7.ipa.zack.world idm-client3-centos7 <span class="o">&gt;&gt;</span> /etc/hosts

<span class="c"># Edit host file and install client, then enrol into idm server domain</span>
apt update <span class="o">&amp;&amp;</span> apt <span class="nb">install </span>freeipa-client oddjob-mkhomedir <span class="nt">-y</span>
ipa-client-install <span class="nt">--server</span><span class="o">=</span>server1.ipa.zack.world <span class="nt">--domain</span> ipa.zack.world

Client configuration complete.
The ipa-client-install <span class="nb">command </span>was successful</code></pre></figure>

<p><img src="/assets/idm2.png" alt="image tooltip here" /></p>

<p><b> Setup idm and AD trust</b></p>

<p>On Windows DC, setup AD</p>

<ul>
  <li>
    <p>install ADDC role and feature</p>
  </li>
  <li>
    <p>create forest “ad.zack.world”</p>
  </li>
  <li>
    <p>promote to primary DC</p>
  </li>
  <li>
    <p>test AD to join Windows client machine to domain</p>
  </li>
  <li>
    <p>create AD user joez@ad.zack.world</p>
  </li>
  <li>
    <p>add idm domain to Windows AD zones</p>
  </li>
</ul>

<figure class="highlight"><pre><code class="language-shell" data-lang="shell"><span class="c"># dnscmd 127.0.0.1 /ZoneAdd [FreeIPA domain name] /Secondary [FreeIPA IP address]</span>
C:<span class="se">\U</span>sers<span class="se">\A</span>dministrator&gt;dnscmd 127.0.0.1 /ZoneAdd ipa.zack.world /Secondary 11.0.1.180
DNS Server 127.0.0.1 created zone ipa.zack.world:

Command completed successfully.

<span class="c"># Verify both AD and Idm DNS resolution, then setup trust</span>
dig SRV _ldap._tcp.ipa.zack.world
dig SRV _ldap._tcp.ad.zack.world</code></pre></figure>

<p><img src="/assets/idm1.png" alt="image tooltip here" /></p>

<ul>
  <li>Install required packages then setup trust on FreeIPA Server</li>
</ul>

<figure class="highlight"><pre><code class="language-shell" data-lang="shell"><span class="c"># Install packages</span>
dnf <span class="nt">-y</span> <span class="nb">install </span>ipa-server-trust-ad
<span class="c"># setup ad trust</span>
ipa-adtrust-install

<span class="c"># FreeIPA admin password</span>
admin password:
<span class="o">=============================================================================</span>
Setup <span class="nb">complete</span>

<span class="c"># add firewall service and ports for ad trust</span>
firewall-cmd <span class="nt">--add-service</span><span class="o">=</span>freeipa-trust

firewall-cmd <span class="nt">--permanent</span> <span class="nt">--add-port</span><span class="o">=</span>135/tcp
firewall-cmd <span class="nt">--permanent</span> <span class="nt">--add-port</span><span class="o">=</span>138/tcp
firewall-cmd <span class="nt">--permanent</span> <span class="nt">--add-port</span><span class="o">=</span>139/tcp
firewall-cmd <span class="nt">--permanent</span> <span class="nt">--add-port</span><span class="o">=</span>445/tcp
firewall-cmd <span class="nt">--permanent</span> <span class="nt">--add-port</span><span class="o">=</span>1024-1300/tcp
firewall-cmd <span class="nt">--permanent</span> <span class="nt">--add-port</span><span class="o">=</span>3268/tcp
<span class="c"># Open UDP ports</span>
firewall-cmd <span class="nt">--permanent</span> <span class="nt">--add-port</span><span class="o">=</span>138/udp
firewall-cmd <span class="nt">--permanent</span> <span class="nt">--add-port</span><span class="o">=</span>139/udp
firewall-cmd <span class="nt">--permanent</span> <span class="nt">--add-port</span><span class="o">=</span>389/udp
firewall-cmd <span class="nt">--permanent</span> <span class="nt">--add-port</span><span class="o">=</span>445/udp
<span class="c"># Open TCP ports</span>
firewall-cmd <span class="nt">--permanent</span> <span class="nt">--add-port</span><span class="o">=</span>80/tcp
firewall-cmd <span class="nt">--permanent</span> <span class="nt">--add-port</span><span class="o">=</span>443/tcp
firewall-cmd <span class="nt">--permanent</span> <span class="nt">--add-port</span><span class="o">=</span>389/tcp
firewall-cmd <span class="nt">--permanent</span> <span class="nt">--add-port</span><span class="o">=</span>636/tcp
firewall-cmd <span class="nt">--permanent</span> <span class="nt">--add-port</span><span class="o">=</span>88/tcp
<span class="nb">sudo </span>firewall-cmd <span class="nt">--permanent</span> <span class="nt">--add-port</span><span class="o">=</span>464/tcp
<span class="nb">sudo </span>firewall-cmd <span class="nt">--permanent</span> <span class="nt">--add-port</span><span class="o">=</span>53/tcp
<span class="c"># Open UDP ports</span>
firewall-cmd <span class="nt">--permanent</span> <span class="nt">--add-port</span><span class="o">=</span>88/udp
firewall-cmd <span class="nt">--permanent</span> <span class="nt">--add-port</span><span class="o">=</span>464/udp
firewall-cmd <span class="nt">--permanent</span> <span class="nt">--add-port</span><span class="o">=</span>53/udp
firewall-cmd <span class="nt">--permanent</span> <span class="nt">--add-port</span><span class="o">=</span>123/udp

firewall-cmd <span class="nt">--reload</span>

<span class="c"># Configure DNS Setting on FreeIPA Server</span>
<span class="c"># ipa dnsforwardzone-add [AD domain name] --forwarder=[AD IP address] --forward-policy=only</span>
ipa dnsforwardzone-add ad.zack.world <span class="nt">--forwarder</span><span class="o">=</span>11.0.1.181 <span class="nt">--forward-policy</span><span class="o">=</span>only
<span class="c"># ipa dnszone-mod [IPA domain name] --allow-transfer=[AD IP address]</span>
ipa dnszone-mod ipa.zack.world <span class="nt">--allow-transfer</span><span class="o">=</span>11.0.1.181

<span class="c"># ipa trust-add --type=ad [AD domain name] --admin Administrator --password</span>
ipa trust-add <span class="nt">--two-way</span><span class="o">=</span><span class="nb">true</span> <span class="nt">--type</span><span class="o">=</span>ad ad.zack.world <span class="nt">--admin</span> Administrator <span class="nt">--password</span>
Active Directory domain administrator<span class="s1">'s password:
-----------------------------------------------------
Added Active Directory trust for realm "ad.zack.world"
-----------------------------------------------------
 Realm name: ad.zack.world
 Domain NetBIOS name: AD01
 Domain Security Identifier: S-1-5-21-726412840-3773945212-2352305327
 Trust direction: Two-way trust
 Trust type: Active Directory domain
 Trust status: Established and verified

# set  home directory at initial login
authselect enable-feature with-mkhomedir
systemctl enable --now oddjobd</span></code></pre></figure>

<p><img src="/assets/idm4.png" alt="image tooltip here" /></p>

<p><b> Validation of both idm clients with idm and AD user</b></p>

<ul>
  <li>Validate ssh into ubuntu client with AD user “joez@ad.zack.world”</li>
</ul>

<p><img src="/assets/idm6.png" alt="image tooltip here" /></p>

<p>Validate ssh into Centos client with idm user “tina”</p>

<figure class="highlight"><pre><code class="language-shell" data-lang="shell">login as: tina
Keyboard-interactive authentication prompts from server:
| Password:
End of keyboard-interactive prompts from server
Last login: Sun Jul 14 20:48:42 2024 from 11.0.1.1
<span class="o">[</span>tina@idm-client3-centos7 ~]<span class="nv">$ </span><span class="nb">id
</span><span class="nv">uid</span><span class="o">=</span>1240000004<span class="o">(</span>tina<span class="o">)</span> <span class="nv">gid</span><span class="o">=</span>1240000004<span class="o">(</span>tina<span class="o">)</span> <span class="nb">groups</span><span class="o">=</span>1240000004<span class="o">(</span>tina<span class="o">)</span> 
<span class="nv">context</span><span class="o">=</span>unconfined_u:unconfined_r:unconfined_t:s0-s0:c0.c1023</code></pre></figure>

<p><b> Conclusion</b></p>

<p>Now we install Redhat IdM server and can enrol client hosts, set up AD trust, ssh and authenticate with both idm and AD users. IdM using Kerberos for authentication, together with user group, policy, HBAC and Sudo roles, provides a flexible and robust authentication framework that supports multiple authentication mechanisms, enabling organizations to authenticate users securely across their Linux and Unix environments.</p>

<p>More info can be found via <a href="https://freeipa.readthedocs.io/en/latest/workshop.html">Freeipa workshop</a>, <a href="https://www.server-world.info/en/note?os=CentOS_Stream_9&amp;p=freeipa&amp;f=8">FreeIPA:FreeIPA trust AD</a>, <a href="https://access.redhat.com/documentation/en-us/red_hat_enterprise_linux/9/html/managing_idm_users_groups_hosts_and_access_control_rules/index">Red Hat product documentation</a>, <a href="https://chamathb.wordpress.com/2019/06/21/setting-up-rhel-idm-with-integrated-dns-on-aws/">Redhat Idm on AWS with DNS forwarder</a>, <a href="https://www.reddit.com/r/redhat/comments/6ixtoe/idmfreeipa_dns_forwarding/">idmfreeipa DNS forwarder configurations on AWS</a>, and <a href="https://redhat.com/en/blog/automating-red-hat-identity-management-installation">Automating Red Hat Identity Management installation with Ansible</a>.</p>]]></content><author><name></name></author><category term="jekyll" /><category term="Cat2" /><summary type="html"><![CDATA[About Linux Identity Management]]></summary></entry><entry><title type="html">Serverless with AWS Fargate</title><link href="http://localhost:4000/jekyll/cat2/2024/07/10/aws-fargate.html" rel="alternate" type="text/html" title="Serverless with AWS Fargate" /><published>2024-07-10T10:15:29+10:00</published><updated>2024-07-10T10:15:29+10:00</updated><id>http://localhost:4000/jekyll/cat2/2024/07/10/aws-fargate</id><content type="html" xml:base="http://localhost:4000/jekyll/cat2/2024/07/10/aws-fargate.html"><![CDATA[<p><b>Why go serverless</b></p>

<p>Some of the company’s applications recently moved from Rancher to Fargate, which is understandable as the cloud resource and traffic will be very intensive only during a certain period (HSC exam), hence AWS serverless with Fargate can be a better option for such business mode so rest of the year without exam we can save cost significantly.</p>

<p><b>Hosting our blog on Fargate? Why not!</b></p>

<p>In the past, I used to try different methods to host this blog:</p>

<ul>
  <li><a href="https://zackz.site/jekyll/cat2/2023/11/02/about-this-project.html">EC2 with docker</a></li>
  <li><a href="https://zackz.site/jekyll/cat2/2023/11/07/ArgoCD.html">K8s with ArgoCD</a></li>
  <li><a href="https://zackz.site/jekyll/cat2/2024/04/30/serverless.html">S3 with static website</a></li>
  <li><a href="https://zackz.site/jekyll/cat2/2024/05/12/Helm.html">Customize Helm Chart for Zack’ Blog</a></li>
</ul>

<p>Here I will use AWS Fargate, together with AWS ECR, Docker, Terraform and Github Action workflow to move this blog to AWS serverless compute for containers.</p>

<ul>
  <li>Terraform Provisioning</li>
</ul>

<figure class="highlight"><pre><code class="language-shell" data-lang="shell"><span class="c"># Provider Configuration  "provider.tf"</span>
provider <span class="s2">"aws"</span> <span class="o">{</span>
 region <span class="o">=</span> <span class="s2">"ap-southeast-2"</span>
<span class="o">}</span>

<span class="c"># Create an ECR Repository "ecr.tf"</span>
resource <span class="s2">"aws_ecr_repository"</span> <span class="s2">"zackblog_repo"</span> <span class="o">{</span>
 name <span class="o">=</span> <span class="s2">"zackblog-repo"</span>
<span class="o">}</span>

<span class="c"># Fargate Task Definition  "task_definition.tf"</span>
resource <span class="s2">"aws_ecs_task_definition"</span> <span class="s2">"zackblog_task"</span> <span class="o">{</span>
 family                   <span class="o">=</span> <span class="s2">"zackblog-task"</span>
 network_mode             <span class="o">=</span> <span class="s2">"awsvpc"</span>
 requires_compatibilities <span class="o">=</span> <span class="o">[</span><span class="s2">"FARGATE"</span><span class="o">]</span>
 cpu                      <span class="o">=</span> <span class="s2">"256"</span>
 memory                   <span class="o">=</span> <span class="s2">"512"</span>

 container_definitions <span class="o">=</span> jsonencode<span class="o">([</span>
 <span class="o">{</span>
 name      <span class="o">=</span> <span class="s2">"zackblog-container"</span>,
 image     <span class="o">=</span> <span class="s2">"</span><span class="k">${</span><span class="nv">aws_ecr_repository</span><span class="p">.zackblog_repo.repository_url</span><span class="k">}</span><span class="s2">:latest"</span>,
 essential <span class="o">=</span> <span class="nb">true</span>,
 portMappings <span class="o">=</span> <span class="o">[</span>
 <span class="o">{</span>
 containerPort <span class="o">=</span> 80,
 hostPort      <span class="o">=</span> 80,
 protocol      <span class="o">=</span> <span class="s2">"tcp"</span>
 <span class="o">}</span>
 <span class="o">]</span>
 <span class="o">}</span>
 <span class="o">])</span>
<span class="o">}</span>

<span class="c"># Create an ECS Cluster "cluster.tf"</span>
resource <span class="s2">"aws_ecs_cluster"</span> <span class="s2">"zackblog_cluster"</span> <span class="o">{</span>
 name <span class="o">=</span> <span class="s2">"zackblog-cluster"</span>
<span class="o">}</span>

<span class="c"># Configure Networking to Use Default VPC - save cost haha</span>
<span class="c"># use the data block to fetch existing resources</span>
data <span class="s2">"aws_vpc"</span> <span class="s2">"default"</span> <span class="o">{</span>
 default <span class="o">=</span> <span class="nb">true</span>
<span class="o">}</span>

data <span class="s2">"aws_subnet"</span> <span class="s2">"default"</span> <span class="o">{</span>
 filter <span class="o">{</span>
 name   <span class="o">=</span> <span class="s2">"vpc-id"</span>
 values <span class="o">=</span> <span class="o">[</span>data.aws_vpc.default.id]
 <span class="o">}</span>
<span class="o">}</span>

resource <span class="s2">"aws_security_group"</span> <span class="s2">"zackblog_sg"</span> <span class="o">{</span>
 name_prefix <span class="o">=</span> <span class="s2">"zackblog-sg"</span>
 vpc_id      <span class="o">=</span> data.aws_vpc.default.id

 ingress <span class="o">{</span>
 from_port   <span class="o">=</span> 80
 to_port     <span class="o">=</span> 80
 protocol    <span class="o">=</span> <span class="s2">"tcp"</span>
 cidr_blocks <span class="o">=</span> <span class="o">[</span><span class="s2">"0.0.0.0/0"</span><span class="o">]</span>
 <span class="o">}</span>

 egress <span class="o">{</span>
 from_port   <span class="o">=</span> 0
 to_port     <span class="o">=</span> 0
 protocol    <span class="o">=</span> <span class="s2">"-1"</span>
 cidr_blocks <span class="o">=</span> <span class="o">[</span><span class="s2">"0.0.0.0/0"</span><span class="o">]</span>
 <span class="o">}</span>
<span class="o">}</span>

<span class="c"># Define the ECS Service "service.tf"</span>
resource <span class="s2">"aws_ecs_service"</span> <span class="s2">"zackblog_service"</span> <span class="o">{</span>
 name            <span class="o">=</span> <span class="s2">"zackblog-service"</span>
 cluster         <span class="o">=</span> aws_ecs_cluster.zackblog_cluster.id
 task_definition <span class="o">=</span> aws_ecs_task_definition.zackblog_task.arn
 desired_count   <span class="o">=</span> 1
 launch_type     <span class="o">=</span> <span class="s2">"FARGATE"</span>

 network_configuration <span class="o">{</span>
 subnets         <span class="o">=</span> <span class="o">[</span><span class="k">for </span>subnet <span class="k">in </span>data.aws_subnet.default : subnet.id]
 security_groups <span class="o">=</span> <span class="o">[</span>aws_security_group.zackblog_sg.id]
 assign_public_ip <span class="o">=</span> <span class="nb">true</span>
 <span class="o">}</span>
<span class="o">}</span>

<span class="c"># Configure Load Balancer and attach to Fargate service "load_balancer.tf"</span>
resource <span class="s2">"aws_lb"</span> <span class="s2">"zackblog_lb"</span> <span class="o">{</span>
 name               <span class="o">=</span> <span class="s2">"zackblog-lb"</span>
 internal           <span class="o">=</span> <span class="nb">false
 </span>load_balancer_type <span class="o">=</span> <span class="s2">"application"</span>
 security_groups    <span class="o">=</span> <span class="o">[</span>aws_security_group.zackblog_sg.id]
 subnets            <span class="o">=</span> <span class="o">[</span><span class="k">for </span>subnet <span class="k">in </span>data.aws_subnet.default : subnet.id]
<span class="o">}</span>

resource <span class="s2">"aws_lb_target_group"</span> <span class="s2">"zackblog_tg"</span> <span class="o">{</span>
 name     <span class="o">=</span> <span class="s2">"zackblog-tg"</span>
 port     <span class="o">=</span> 80
 protocol <span class="o">=</span> <span class="s2">"HTTP"</span>
 vpc_id   <span class="o">=</span> data.aws_vpc.default.id
<span class="o">}</span>

resource <span class="s2">"aws_lb_listener"</span> <span class="s2">"zackblog_listener"</span> <span class="o">{</span>
 load_balancer_arn <span class="o">=</span> aws_lb.zackblog_lb.arn
 port              <span class="o">=</span> 80
 protocol          <span class="o">=</span> <span class="s2">"HTTP"</span>

 default_action <span class="o">{</span>
 <span class="nb">type</span>             <span class="o">=</span> <span class="s2">"forward"</span>
 target_group_arn <span class="o">=</span> aws_lb_target_group.zackblog_tg.arn
 <span class="o">}</span>
<span class="o">}</span>

resource <span class="s2">"aws_lb_target_group_attachment"</span> <span class="s2">"zackblog_tg_attachment"</span> <span class="o">{</span>
 target_group_arn <span class="o">=</span> aws_lb_target_group.zackblog_tg.arn
 target_id        <span class="o">=</span> aws_ecs_service.zackblog_service.id
 port             <span class="o">=</span> 80
<span class="o">}</span></code></pre></figure>

<ul>
  <li>Github Action Workflow fo CICD</li>
</ul>

<p>1.First we need to create Github Secret to contain dockerhub and aws credentials and some other vars:</p>

<figure class="highlight"><pre><code class="language-shell" data-lang="shell">AWS_ACCESS_KEY_ID

AWS_SECRET_ACCESS_KEY

AWS_REGION

<span class="c"># xxx.dkr.ecr.ap-southeast-2.amazonaws.com</span>
ECR_REGISTRY  

<span class="c"># zackblog-repo</span>
ECR_REPOSITORY  

<span class="c"># zackblog-cluster</span>
ECS_CLUSTER 

<span class="c"># zackblog-service</span>
ECS_SERVICE </code></pre></figure>

<p>2.Then define the workflow to create /.github/workflows/zackblog-fargate.yaml, in this configure Github runner, it will :</p>

<p>Log in to Amazon ECR</p>

<p>Build and push Docker Image to the ECR repository</p>

<p>Deploy to ECS by updating the ECS service to use the new image by forcing a new deployment</p>

<figure class="highlight"><pre><code class="language-yaml" data-lang="yaml"><span class="na">name</span><span class="pi">:</span> <span class="s">Deploy to AWS Fargate</span>

<span class="na">on</span><span class="pi">:</span>
 <span class="na">push</span><span class="pi">:</span>
 <span class="na">branches</span><span class="pi">:</span>
 <span class="pi">-</span> <span class="s">editing  # not main branch</span>

<span class="na">jobs</span><span class="pi">:</span>
 <span class="na">deploy</span><span class="pi">:</span>
 <span class="na">runs-on</span><span class="pi">:</span> <span class="s">ubuntu-latest</span>

 <span class="na">steps</span><span class="pi">:</span>
 <span class="pi">-</span> <span class="na">name</span><span class="pi">:</span> <span class="s">Checkout code</span>
 <span class="na">uses</span><span class="pi">:</span> <span class="s">actions/checkout@v3</span>

 <span class="pi">-</span> <span class="na">name</span><span class="pi">:</span> <span class="s">Set up Docker Buildx</span>
 <span class="na">uses</span><span class="pi">:</span> <span class="s">docker/setup-buildx-action@v2</span>

 <span class="pi">-</span> <span class="na">name</span><span class="pi">:</span> <span class="s">Log in to Amazon ECR</span>
 <span class="na">env</span><span class="pi">:</span>
 <span class="na">AWS_REGION</span><span class="pi">:</span> <span class="s">${{ secrets.AWS_REGION }}</span>
 <span class="na">run</span><span class="pi">:</span> <span class="pi">|</span>
 <span class="s">aws ecr get-login-password --region $AWS_REGION | docker login --username AWS --password-stdin ${{ secrets.ECR_REGISTRY }}</span>

 <span class="s">- name: Build and push Docker image</span>
 <span class="s">env:</span>
 <span class="s">IMAGE_TAG: ${{ github.sha }}</span>
 <span class="s">ECR_REGISTRY: ${{ secrets.ECR_REGISTRY }}</span>
 <span class="s">ECR_REPOSITORY: ${{ secrets.ECR_REPOSITORY }}</span>
 <span class="s">run: |</span>
 <span class="s">docker build -t $ECR_REGISTRY/$ECR_REPOSITORY:$IMAGE_TAG .</span>
 <span class="s">docker push $ECR_REGISTRY/$ECR_REPOSITORY:$IMAGE_TAG</span>

 <span class="s">- name: Deploy to ECS</span>
 <span class="s">env:</span>
 <span class="s">AWS_REGION: ${{ secrets.AWS_REGION }}</span>
 <span class="s">ECS_CLUSTER: ${{ secrets.ECS_CLUSTER }}</span>
 <span class="s">ECS_SERVICE: ${{ secrets.ECS_SERVICE }}</span>
 <span class="s">ECR_REGISTRY: ${{ secrets.ECR_REGISTRY }}</span>
 <span class="s">ECR_REPOSITORY: ${{ secrets.ECR_REPOSITORY }}</span>
 <span class="s">IMAGE_TAG: ${{ github.sha }}</span>
 <span class="s">run: |</span>
 <span class="s">aws ecs update-service --cluster $ECS_CLUSTER --service $ECS_SERVICE --force-new-deployment --region $AWS_REGION</span></code></pre></figure>

<p><b> Conclusion</b></p>

<p>Now we have a seamless incurvature as a code together with CICD pipeline to ensure that the “Zack’s Blog” can be moved to AWS serverless container service Fargate, every time I update the blog by committing changes to “zack-gitops-project” editing branch, a new Docker image will be built, pushed to ECR, and the AWS Fargate service is automatically updated.  </p>]]></content><author><name></name></author><category term="jekyll" /><category term="Cat2" /><summary type="html"><![CDATA[Why go serverless]]></summary></entry><entry><title type="html">Automate Package Deployment via AWS System Manager</title><link href="http://localhost:4000/jekyll/cat2/2024/06/23/aws-ssm.html" rel="alternate" type="text/html" title="Automate Package Deployment via AWS System Manager" /><published>2024-06-23T10:15:29+10:00</published><updated>2024-06-23T10:15:29+10:00</updated><id>http://localhost:4000/jekyll/cat2/2024/06/23/aws-ssm</id><content type="html" xml:base="http://localhost:4000/jekyll/cat2/2024/06/23/aws-ssm.html"><![CDATA[<p><b>The task</b></p>

<p>Recently we got a task from the Company’s security team, to install 2 security agents which will be used to perform centralized security scans for all active AWS EC2 instances. here I will see how to use AWS Systems Manager for software distribution and installation for multiple AWS accounts and infrastructure at scale.</p>

<p>SSM features will be used :</p>

<ul>
  <li><b>Session Manager</b>: ensure the EC2 instance has the SSM Agent installed and running and The instances need an IAM role with at least the <code class="language-plaintext highlighter-rouge">AmazonSSMManagedInstanceCore</code> policy attached  </li>
  <li><b>Run Command</b>: send command and execute security agent software package installation scripts and command to varify post-installation status on remote instances for task automation</li>
</ul>

<p>Prerequisites:</p>
<ul>
  <li>
    <p><b>AWSCLI</b>: programatically manage all the operation bellow.</p>
  </li>
  <li>
    <p><b>SSM Agent</b>: Ensure the SSM Agent is installed and running on all EC2 instances. Most Amazon Machine Images (AMIs) have the SSM Agent pre-installed.</p>
  </li>
  <li>
    <p><b>IAM Role</b>: Attach an IAM role to each instance with the AmazonSSMManagedInstanceCore policy.</p>
  </li>
</ul>

<p>Create and attach IAM role to EC2 instance for SSM to be able to perform action:</p>

<figure class="highlight"><pre><code class="language-shell" data-lang="shell"><span class="o">[</span>cloudshell-user@ip-10-134-56-72 ~]<span class="nv">$ </span>vim trust-policy.json

<span class="o">{</span>
 <span class="s2">"Version"</span>: <span class="s2">"2012-10-17"</span>,
 <span class="s2">"Statement"</span>: <span class="o">[</span>
 <span class="o">{</span>
 <span class="s2">"Effect"</span>: <span class="s2">"Allow"</span>,
 <span class="s2">"Principal"</span>: <span class="o">{</span>
 <span class="s2">"Service"</span>: <span class="s2">"ec2.amazonaws.com"</span>
 <span class="o">}</span>,
 <span class="s2">"Action"</span>: <span class="s2">"sts:AssumeRole"</span>
 <span class="o">}</span>
 <span class="o">]</span>
<span class="o">}</span>

<span class="o">[</span>cloudshell-user@ip-10-134-56-72 ~]<span class="nv">$ </span>aws iam create-role <span class="nt">--role-name</span> SSMAccessRole <span class="nt">--assume-role-policy-document</span> file://trust-policy.json
<span class="o">{</span>
 <span class="s2">"Role"</span>: <span class="o">{</span>
 <span class="s2">"Path"</span>: <span class="s2">"/"</span>,
 <span class="s2">"RoleName"</span>: <span class="s2">"SSMAccessRole"</span>,
 <span class="s2">"RoleId"</span>: <span class="s2">"AROA4MTWLTSHKK3QL3NOU"</span>,
 <span class="s2">"Arn"</span>: <span class="s2">"arn:aws:iam::85xxxxxx1342:role/SSMAccessRole"</span>,
 <span class="s2">"CreateDate"</span>: <span class="s2">"2024-06-25T00:29:07+00:00"</span>,
 <span class="s2">"AssumeRolePolicyDocument"</span>: <span class="o">{</span>
 <span class="s2">"Version"</span>: <span class="s2">"2012-10-17"</span>,
 <span class="s2">"Statement"</span>: <span class="o">[</span>
 <span class="o">{</span>
 <span class="s2">"Effect"</span>: <span class="s2">"Allow"</span>,
 <span class="s2">"Principal"</span>: <span class="o">{</span>
 <span class="s2">"Service"</span>: <span class="s2">"ec2.amazonaws.com"</span>
 <span class="o">}</span>,
 <span class="s2">"Action"</span>: <span class="s2">"sts:AssumeRole"</span>
 <span class="o">}</span>
 <span class="o">]</span>
 <span class="o">}</span>
 <span class="o">}</span>
<span class="o">}</span>

<span class="o">[</span>cloudshell-user@ip-10-134-56-72 ~]<span class="nv">$ </span>aws iam attach-role-policy <span class="nt">--role-name</span> SSMAccessRole <span class="nt">--policy-arn</span> arn:aws:iam::aws:policy/AmazonSSMManagedInstanceCore

<span class="o">[</span>cloudshell-user@ip-10-134-56-72 ~]<span class="nv">$ </span>aws iam create-instance-profile <span class="nt">--instance-profile-name</span> SSMInstanceProfile
<span class="o">{</span>
 <span class="s2">"InstanceProfile"</span>: <span class="o">{</span>
 <span class="s2">"Path"</span>: <span class="s2">"/"</span>,
 <span class="s2">"InstanceProfileName"</span>: <span class="s2">"SSMInstanceProfile"</span>,
 <span class="s2">"InstanceProfileId"</span>: <span class="s2">"AIPA4MTWLTSHF7KJRFLYC"</span>,
 <span class="s2">"Arn"</span>: <span class="s2">"arn:aws:iam::851xxxxxxx42:instance-profile/SSMInstanceProfile"</span>,
 <span class="s2">"CreateDate"</span>: <span class="s2">"2024-06-25T00:31:25+00:00"</span>,
 <span class="s2">"Roles"</span>: <span class="o">[]</span>
 <span class="o">}</span>
<span class="o">}</span>

<span class="o">[</span>cloudshell-user@ip-10-134-56-72 ~]<span class="nv">$ INSTANCE_IDS</span><span class="o">=</span><span class="si">$(</span>aws ec2 describe-instances <span class="nt">--query</span> <span class="s2">"Reservations[*].Instances[*].InstanceId"</span> <span class="nt">--output</span> text<span class="si">)</span>
<span class="k">for </span>INSTANCE_ID <span class="k">in</span> <span class="nv">$INSTANCE_IDS</span><span class="p">;</span> <span class="k">do</span>
<span class="o">&gt;</span> aws ec2 associate-iam-instance-profile <span class="nt">--instance-id</span> <span class="nv">$INSTANCE_ID</span> <span class="nt">--iam-instance-profile</span> <span class="nv">Name</span><span class="o">=</span>SSMInstanceProfile
<span class="o">&gt;</span> <span class="k">done</span>

<span class="o">{</span>
 <span class="s2">"IamInstanceProfileAssociation"</span>: <span class="o">{</span>
 <span class="s2">"AssociationId"</span>: <span class="s2">"iip-assoc-04e81626bf6bcd9b5"</span>,
 <span class="s2">"InstanceId"</span>: <span class="s2">"i-0762xxxxxxxcf2"</span>,
 <span class="s2">"IamInstanceProfile"</span>: <span class="o">{</span>
 <span class="s2">"Arn"</span>: <span class="s2">"arn:aws:iam::8517xxxxxxx42:instance-profile/SSMInstanceProfile"</span>,
 <span class="s2">"Id"</span>: <span class="s2">"AIPA4MTWLTSHF7KJRFLYC"</span>
 <span class="o">}</span>,
 <span class="s2">"State"</span>: <span class="s2">"associating"</span>
 <span class="o">}</span>
<span class="o">}</span>
<span class="o">{</span>
 <span class="s2">"IamInstanceProfileAssociation"</span>: <span class="o">{</span>
 <span class="s2">"AssociationId"</span>: <span class="s2">"iip-assoc-09233165b3a53ca68"</span>,
 <span class="s2">"InstanceId"</span>: <span class="s2">"i-01a2xxxxxx048c"</span>,
 <span class="s2">"IamInstanceProfile"</span>: <span class="o">{</span>
 <span class="s2">"Arn"</span>: <span class="s2">"arn:aws:iam::851xxxx42:instance-profile/SSMInstanceProfile"</span>,
 <span class="s2">"Id"</span>: <span class="s2">"AIPA4MTWLTSHF7KJRFLYC"</span>
 <span class="o">}</span>,
 <span class="s2">"State"</span>: <span class="s2">"associating"</span>
 <span class="o">}</span>
<span class="o">}</span>
<span class="o">{</span>
 <span class="s2">"IamInstanceProfileAssociation"</span>: <span class="o">{</span>
 <span class="s2">"AssociationId"</span>: <span class="s2">"iip-assoc-09236a8ee456e39cd"</span>,
 <span class="s2">"InstanceId"</span>: <span class="s2">"i-07axxxxxxb823"</span>,
 <span class="s2">"IamInstanceProfile"</span>: <span class="o">{</span>
 <span class="s2">"Arn"</span>: <span class="s2">"arn:aws:iam::85xxxxxxx42:instance-profile/SSMInstanceProfile"</span>,
 <span class="s2">"Id"</span>: <span class="s2">"AIPA4MTWLTSHF7KJRFLYC"</span>
 <span class="o">}</span>,
 <span class="s2">"State"</span>: <span class="s2">"associating"</span>
 <span class="o">}</span>
<span class="o">}</span>

<span class="o">[</span>cloudshell-user@ip-10-134-56-72 ~]<span class="nv">$ </span>aws ssm describe-instance-information</code></pre></figure>

<p>Now verify from session manager to see if instances are there:</p>

<p><img src="/assets/ssm1.png" alt="image tooltip here" /></p>

<ul>
  <li>Tag Instances</li>
</ul>

<p>Tag EC2 instances to identify which instances need the security agent to be installed:</p>

<figure class="highlight"><pre><code class="language-shell" data-lang="shell"><span class="nv">Key</span><span class="o">=</span>InstallSecurityAgent, <span class="nv">Value</span><span class="o">=</span>True.</code></pre></figure>

<figure class="highlight"><pre><code class="language-shell" data-lang="shell"><span class="c"># List all instance IDs #: </span>
<span class="nv">INSTANCE_IDS</span><span class="o">=</span><span class="si">$(</span>aws ec2 describe-instances <span class="nt">--query</span> <span class="s2">"Reservations[*].Instances[*].InstanceId"</span> <span class="nt">--output</span> text<span class="si">)</span>

<span class="c"># Tag all instances with Key=InstallSecurityAgent and Value=True</span>
<span class="k">for </span>INSTANCE_ID <span class="k">in</span> <span class="nv">$INSTANCE_IDS</span><span class="p">;</span> <span class="k">do
 </span>aws ec2 create-tags <span class="nt">--resources</span> <span class="nv">$INSTANCE_ID</span> <span class="nt">--tags</span> <span class="nv">Key</span><span class="o">=</span>InstallSecurityAgent,Value<span class="o">=</span>True
<span class="k">done</span></code></pre></figure>

<ul>
  <li>SSM Run Command to Create a custom SSM document that contains the script to install the security agent</li>
</ul>

<figure class="highlight"><pre><code class="language-shell" data-lang="shell"><span class="o">[</span>cloudshell-user@ip-10-134-56-72 ~]<span class="nv">$ </span>vim install_security_agent.json
<span class="o">{</span>
 <span class="s2">"schemaVersion"</span>: <span class="s2">"2.2"</span>,
 <span class="s2">"description"</span>: <span class="s2">"Install Security Agent"</span>,
 <span class="s2">"mainSteps"</span>: <span class="o">[</span>
 <span class="o">{</span>
 <span class="s2">"action"</span>: <span class="s2">"aws:runShellScript"</span>,
 <span class="s2">"name"</span>: <span class="s2">"installSecurityAgent"</span>,
 <span class="s2">"inputs"</span>: <span class="o">{</span>
 <span class="s2">"runCommand"</span>: <span class="o">[</span>
 <span class="s2">"curl -o /tmp/security-agent-installer.sh https://github.com/ZackZhouHB/zack-gitops-project/blob/editing/Python_scripts/security-agent-installer.sh"</span>,
 <span class="s2">"chmod +x /tmp/security-agent-installer.sh"</span>,
 <span class="s2">"/tmp/security-agent-installer.sh"</span>
 <span class="o">]</span>
 <span class="o">}</span>
 <span class="o">}</span>
 <span class="o">]</span>
<span class="o">}</span></code></pre></figure>

<p>Create Document to execute the installation script on all tagged instances.</p>

<figure class="highlight"><pre><code class="language-shell" data-lang="shell"><span class="o">[</span>cloudshell-user@ip-10-134-56-72 ~]<span class="nv">$ </span>aws ssm create-document <span class="se">\</span>
 <span class="nt">--name</span> <span class="s2">"InstallSecurityAgent"</span> <span class="se">\</span>
 <span class="nt">--document-type</span> <span class="s2">"Command"</span> <span class="se">\</span>
 <span class="nt">--content</span> file://install_security_agent.json

<span class="o">{</span>
 <span class="s2">"DocumentDescription"</span>: <span class="o">{</span>
 <span class="s2">"Hash"</span>: <span class="s2">"9e17a699d2d987134eb05f6b49a7c837161320b0ed42635b07928acc557970b5"</span>,
 <span class="s2">"HashType"</span>: <span class="s2">"Sha256"</span>,
 <span class="s2">"Name"</span>: <span class="s2">"InstallSecurityAgent"</span>,
 <span class="s2">"Owner"</span>: <span class="s2">"851725491342"</span>,
 <span class="s2">"CreatedDate"</span>: <span class="s2">"2024-06-25T01:51:36.666000+00:00"</span>,
 <span class="s2">"Status"</span>: <span class="s2">"Creating"</span>,
 <span class="s2">"DocumentVersion"</span>: <span class="s2">"1"</span>,
 <span class="s2">"Description"</span>: <span class="s2">"Install Security Agent"</span>,
 <span class="s2">"PlatformTypes"</span>: <span class="o">[</span>
 <span class="s2">"Linux"</span>,
 <span class="s2">"MacOS"</span>
 <span class="o">]</span>,
 <span class="s2">"DocumentType"</span>: <span class="s2">"Command"</span>,
 <span class="s2">"SchemaVersion"</span>: <span class="s2">"2.2"</span>,
 <span class="s2">"LatestVersion"</span>: <span class="s2">"1"</span>,
 <span class="s2">"DefaultVersion"</span>: <span class="s2">"1"</span>,
 <span class="s2">"DocumentFormat"</span>: <span class="s2">"JSON"</span>,
 <span class="s2">"Tags"</span>: <span class="o">[]</span>
 <span class="o">}</span>
<span class="o">}</span>

<span class="o">[</span>cloudshell-user@ip-10-132-90-150 ~]<span class="nv">$ </span>aws ssm send-command <span class="se">\</span>
<span class="o">&gt;</span> <span class="nt">--document-name</span> <span class="s2">"InstallSecurityAgent"</span> <span class="se">\</span>
<span class="o">&gt;</span> <span class="nt">--targets</span> <span class="s2">"Key=tag:InstallSecurityAgent,Values=True"</span> <span class="se">\</span>
<span class="o">&gt;</span> <span class="nt">--comment</span> <span class="s2">"Installing security agent on all instances with the specified tag"</span> <span class="se">\</span>
<span class="o">&gt;</span> <span class="nt">--max-concurrency</span> <span class="s2">"50"</span> <span class="se">\</span>
<span class="o">&gt;</span> <span class="nt">--max-errors</span> <span class="s2">"0"</span> <span class="se">\</span>
<span class="o">&gt;</span> <span class="nt">--region</span> ap-southeast-2
<span class="o">{</span>
 <span class="s2">"Command"</span>: <span class="o">{</span>
 <span class="s2">"CommandId"</span>: <span class="s2">"edfc9e9b-5e74-4660-8335-a98eb48251f7"</span>,
 <span class="s2">"DocumentName"</span>: <span class="s2">"InstallSecurityAgent"</span>,
 <span class="s2">"DocumentVersion"</span>: <span class="s2">"</span><span class="nv">$DEFAULT</span><span class="s2">"</span>,
 <span class="s2">"Comment"</span>: <span class="s2">"Installing security agent on all instances with the specified tag"</span>,
 <span class="s2">"ExpiresAfter"</span>: <span class="s2">"2024-06-25T04:03:44.665000+00:00"</span>,
 <span class="s2">"Parameters"</span>: <span class="o">{}</span>,
 <span class="s2">"InstanceIds"</span>: <span class="o">[]</span>,
 <span class="s2">"Targets"</span>: <span class="o">[</span>
 <span class="o">{</span>
 <span class="s2">"Key"</span>: <span class="s2">"tag:InstallSecurityAgent"</span>,
 <span class="s2">"Values"</span>: <span class="o">[</span>
 <span class="s2">"True"</span>
 <span class="o">]</span>
 <span class="o">}</span>
 <span class="o">]</span>,
 <span class="s2">"RequestedDateTime"</span>: <span class="s2">"2024-06-25T02:03:44.665000+00:00"</span>,
 <span class="s2">"Status"</span>: <span class="s2">"Pending"</span>,
 <span class="s2">"StatusDetails"</span>: <span class="s2">"Pending"</span>,
 <span class="s2">"OutputS3Region"</span>: <span class="s2">"ap-southeast-2"</span>,
 <span class="s2">"OutputS3BucketName"</span>: <span class="s2">""</span>,
 <span class="s2">"OutputS3KeyPrefix"</span>: <span class="s2">""</span>,
 <span class="s2">"MaxConcurrency"</span>: <span class="s2">"50"</span>,
 <span class="s2">"MaxErrors"</span>: <span class="s2">"0"</span>,
 <span class="s2">"TargetCount"</span>: 0,
 <span class="s2">"CompletedCount"</span>: 0,
 <span class="s2">"ErrorCount"</span>: 0,
 <span class="s2">"DeliveryTimedOutCount"</span>: 0,
 <span class="s2">"ServiceRole"</span>: <span class="s2">""</span>,
 <span class="s2">"NotificationConfig"</span>: <span class="o">{</span>
 <span class="s2">"NotificationArn"</span>: <span class="s2">""</span>,
 <span class="s2">"NotificationEvents"</span>: <span class="o">[]</span>,
 <span class="s2">"NotificationType"</span>: <span class="s2">""</span>
 <span class="o">}</span>,
 <span class="s2">"CloudWatchOutputConfig"</span>: <span class="o">{</span>
 <span class="s2">"CloudWatchLogGroupName"</span>: <span class="s2">""</span>,
 <span class="s2">"CloudWatchOutputEnabled"</span>: <span class="nb">false</span>
 <span class="o">}</span>,
 <span class="s2">"TimeoutSeconds"</span>: 3600,
 <span class="s2">"AlarmConfiguration"</span>: <span class="o">{</span>
 <span class="s2">"IgnorePollAlarmFailure"</span>: <span class="nb">false</span>,
 <span class="s2">"Alarms"</span>: <span class="o">[]</span>
 <span class="o">}</span>,
 <span class="s2">"TriggeredAlarms"</span>: <span class="o">[]</span>
 <span class="o">}</span>
<span class="o">}</span>
<span class="o">(</span>END<span class="o">)</span></code></pre></figure>

<p>Validate from Run Command console for the installation:
<img src="/assets/ssm2.png" alt="image tooltip here" /></p>

<p>Create an SSM Document to Check the package installation status:</p>

<figure class="highlight"><pre><code class="language-shell" data-lang="shell"><span class="o">[</span>cloudshell-user@ip-10-134-56-72 ~]<span class="nv">$ </span>vim verify.json

<span class="o">{</span>
 <span class="s2">"schemaVersion"</span>: <span class="s2">"2.2"</span>,
 <span class="s2">"description"</span>: <span class="s2">"Install Security Agent"</span>,
 <span class="s2">"mainSteps"</span>: <span class="o">[</span>
 <span class="o">{</span>
 <span class="s2">"action"</span>: <span class="s2">"aws:runShellScript"</span>,
 <span class="s2">"name"</span>: <span class="s2">"installSecurityAgent"</span>,
 <span class="s2">"inputs"</span>: <span class="o">{</span>
 <span class="s2">"runCommand"</span>: <span class="o">[</span>
 <span class="s2">"apt list --installed | grep nfs-common"</span>,
 <span class="s2">"apt list --installed | grep lrzsz"</span>
 <span class="o">]</span>
 <span class="o">}</span>
 <span class="o">}</span>
 <span class="o">]</span>
<span class="o">}</span></code></pre></figure>

<p>Create this document using the AWS CLI:</p>

<figure class="highlight"><pre><code class="language-shell" data-lang="shell"><span class="o">[</span>cloudshell-user@ip-10-134-56-72 ~]<span class="nv">$ </span>aws ssm create-document <span class="se">\</span>
 <span class="nt">--name</span> <span class="s2">"VerifyPackageInstallation"</span> <span class="se">\</span>
 <span class="nt">--document-type</span> <span class="s2">"Command"</span> <span class="se">\</span>
 <span class="nt">--content</span> file://verify.json

<span class="o">[</span>cloudshell-user@ip-10-134-56-72 ~]<span class="nv">$ </span>aws ssm send-command <span class="se">\</span>
 <span class="nt">--document-name</span> <span class="s2">"VerifyPackageInstallation"</span> <span class="se">\</span>
 <span class="nt">--targets</span> <span class="s2">"Key=tag:InstallSecurityAgent,Values=True"</span> <span class="se">\</span>
 <span class="nt">--comment</span> <span class="s2">"Check if Packages installed on all instances"</span> <span class="se">\</span>
 <span class="nt">--max-concurrency</span> <span class="s2">"50"</span> <span class="se">\</span>
 <span class="nt">--max-errors</span> <span class="s2">"0"</span> <span class="se">\</span>
 <span class="nt">--region</span> ap-southeast-2</code></pre></figure>

<p>Verify both “nfs-common” and “lrzsz”, we have 3 machines with “nfs-common” installed, and 2 instances with Ubuntu24.04 which did not get “lrzsz” installed.</p>

<p><img src="/assets/ssm3.png" alt="image tooltip here" /></p>

<p><img src="/assets/ssm4.png" alt="image tooltip here" /></p>

<p><b> Conclusion</b></p>

<p>So now we can use AWS CLI and AWS System Manager to automate software deployment and verify the installation status.</p>]]></content><author><name></name></author><category term="jekyll" /><category term="Cat2" /><summary type="html"><![CDATA[The task]]></summary></entry><entry><title type="html">Handling a RDS MySQL cluster CPU 100%</title><link href="http://localhost:4000/jekyll/cat2/2024/06/17/mysql-cup100.html" rel="alternate" type="text/html" title="Handling a RDS MySQL cluster CPU 100%" /><published>2024-06-17T10:15:29+10:00</published><updated>2024-06-17T10:15:29+10:00</updated><id>http://localhost:4000/jekyll/cat2/2024/06/17/mysql-cup100</id><content type="html" xml:base="http://localhost:4000/jekyll/cat2/2024/06/17/mysql-cup100.html"><![CDATA[<p><b>The Incident</b></p>

<p>Today I got a performance issue from our analytic team, saying they experienced a Production MySQL cluster running on RDS very slow since yesterday morning.  </p>

<p>I started to look into bellow areas for investigation:</p>

<ul>
  <li>AWS CloudWatch Metrics for RDS</li>
</ul>

<p>AWS CloudWatch provides a wide range of metrics that can help diagnose resource usage for databases. So I started with</p>

<p><em>CloudWatch - Metrics - All metrics - Add query - RDS - Top 10 RDS instances by highest CPU utilization</em></p>

<p>This only queries the recent 3 hours metrics, but it is enough for me to identify the issue: CPU 100%</p>

<p><img src="/assets/mysqlcpu1.png" alt="image tooltip here" /></p>

<p>To further understand the high CUP, I go:</p>

<p><em>CloudWatch - Metrics - All metrics - Browse - RDS - DBClusterIdentifier - CPUUtilization</em></p>

<p>which gives me a long period of monitoring, so I can see it started to 100% CPU since yesterday morning.</p>

<p><img src="/assets/mysqlcpu2.png" alt="image tooltip here" /></p>

<ul>
  <li>AWS console RDS Logs &amp; events</li>
</ul>

<p>Now let’s find out from the RDS logs to see if any errors can indicate who could be the person. So I go</p>

<p><em>RDS - “the DB cluster” - “the DB instance” - “Logs &amp; events” - “error/mysql-error-running.log.2024-06-18.02”</em></p>

<p>I got :</p>

<figure class="highlight"><pre><code class="language-shell" data-lang="shell">2024-06-18T00:04:58.750212Z 2831474 <span class="o">[</span>Note] Aborted connection 2831474 to db: <span class="s1">'xxxxxx'</span> user: <span class="s1">'xxxx'</span> host: <span class="s1">'10.xx.xx.xx'</span> <span class="o">(</span>Unknown error<span class="o">)</span>
2024-06-18T00:12:00.798173Z 2831498 <span class="o">[</span>Note] Aborted connection 2831498 to db: <span class="s1">'xxxx'</span> user: <span class="s1">'xxxx'</span> host: <span class="s1">'10.xx.xx.xx'</span> <span class="o">(</span>Got an error writing communication packets<span class="o">)</span>
<span class="nt">-----------------------</span> END OF LOG <span class="nt">----------------------</span></code></pre></figure>

<p>Up to here I generally have an idea of what is going on and can locate the person “xxxx” who was running something at the time CPU 100%.</p>

<ul>
  <li>MySQL Client Tool to list, identiry and terminate long-running queries</li>
</ul>

<p>It is time to log in to the RDS endpoint to see what is happening and which queries might cause the CPU usage. Here we need login via MySQL “root” to be able to see all other users’ running processes. Then pay attention to the high “Time” and “State” values indicating all the stuck processes, then we kill them and restart the RDS instance</p>

<figure class="highlight"><pre><code class="language-shell" data-lang="shell">mysql <span class="nt">-u</span> root <span class="nt">-p</span> <span class="nt">-h</span> rds_endpoint
SHOW PROCESSLIST<span class="p">;</span>
KILL &lt;process_id&gt;<span class="p">;</span></code></pre></figure>

<p><img src="/assets/mysqlcpu4.png" alt="image tooltip here" /></p>

<p>Then I go <em>AWS RDS console - Actions - Reboot</em> the RDS instance.</p>

<ul>
  <li>Now the CPU usage started to drop and back to normal after terminating the stuck processes and DB instance reboot.</li>
</ul>

<p><img src="/assets/mysqlcpu3.png" alt="image tooltip here" /></p>

<p>Done.</p>

<p><b> Conclusion</b></p>

<p>Even the issue had been fixed, I was still thinking how to better monitor RDS resource usage. I think we need:</p>

<ul>
  <li>
    <p>A “CloudWatch Alarm” to set “CPUUtilization” metric threshold to 80%, then specify the period (e.g., 5 minutes) and the number of periods (e.g., 2 out of 3) that the metric must breach the threshold to trigger the alarm.</p>
  </li>
  <li>
    <p>Create “SNS topic” with team Email for the alarm to send a notification</p>
  </li>
  <li>
    <p>Enable “RDS Performance Insights”, this can monitor the load on the database, identify the source of bottlenecks, and understand how the DB is performing, especially during troubleshooting.</p>
  </li>
  <li>
    <p>Enable “Enhanced Monitoring” and select the monitoring interval (e.g., 1 minute), which provides real-time metrics for the operating system that the DB instance runs on, this helps for immediate investigation on OS level</p>
  </li>
  <li>
    <p>Enable “Slow Query Log” for regularly analysing slow query logs and performance insights to optimize RDS database queries, identify queries that take a long time to execute, use tools like EXPLAIN to understand query performance, add appropriate indexes, and then ultimately rewrite queries for better performance.</p>
  </li>
</ul>]]></content><author><name></name></author><category term="jekyll" /><category term="Cat2" /><summary type="html"><![CDATA[The Incident]]></summary></entry><entry><title type="html">Istio: Distributed Tracing with Jaeger</title><link href="http://localhost:4000/jekyll/cat2/2024/05/24/istio2.html" rel="alternate" type="text/html" title="Istio: Distributed Tracing with Jaeger" /><published>2024-05-24T10:15:29+10:00</published><updated>2024-05-24T10:15:29+10:00</updated><id>http://localhost:4000/jekyll/cat2/2024/05/24/istio2</id><content type="html" xml:base="http://localhost:4000/jekyll/cat2/2024/05/24/istio2.html"><![CDATA[<p><b>About Jaeger</b></p>

<p>Last post we are able to depoly <a href="https://zackz.online/jekyll/cat2/2024/05/22/istio.html">Istio</a> and manage traffic for a book review microservice application. This session we will dive deeper into Istia for it add-on Jaeger for Microservice tracing.</p>

<p>Jaeger is an open-source end-to-end distributed tracing tool to monitor and troubleshoot the performance of microservices-based distributed systems by providing insights into the latency and other performance metrics.</p>

<ul>
  <li>Trace</li>
</ul>

<p>A trace represents the entire journey of a request or transaction as it propagates through various services and components of a distributed system. It captures the path the request takes, including all the microservices it interacts with, from start to finish. A trace is composed of multiple spans.</p>

<ul>
  <li>Span</li>
</ul>

<p>A span is a single unit of work within a trace. It represents an individual operation within a microservice, such as a function call, database query, or external API request. Each span contains metadata such as:</p>

<p><b>Prepration for Hands on</b></p>

<p>Here we will use <a href="https://github.com/DickChesterwood/k8s-fleetman">Fleetman GPS sumilater microservice application</a> as example to explore Jaeger and it capabilities.</p>

<ul>
  <li>Enable Istio sidecar injection for existing deployment</li>
</ul>

<figure class="highlight"><pre><code class="language-shell" data-lang="shell"><span class="c"># lable the namaspace to allow istio sidecar container injection</span>
<span class="o">[</span>root@freeipa-server ~]# kubectl label namespace default istio-injection<span class="o">=</span>enabled <span class="nt">--overwrite</span>

<span class="c"># Redeploy fleetman application</span>
<span class="o">[</span>root@freeipa-server ~]# kubectl rollout restart deployment <span class="nt">-n</span> default</code></pre></figure>

<ul>
  <li>validate pod for istio sidecar injection, also check service status in Kiali</li>
</ul>

<figure class="highlight"><pre><code class="language-shell" data-lang="shell"><span class="o">[</span>root@freeipa-server ~]# kubectl get po
NAME                                                        READY   STATUS    RESTARTS       AGE
api-gateway-58f978dfc6-phdgp                                2/2     Running   4 <span class="o">(</span>30m ago<span class="o">)</span>    17h
position-simulator-6f5df9b447-57d75                         2/2     Running   4 <span class="o">(</span>30m ago<span class="o">)</span>    17h
position-tracker-6698577777-fz52v                           2/2     Running   4 <span class="o">(</span>30m ago<span class="o">)</span>    17h
staff-service-59987757dc-mfm2t                              2/2     Running   4 <span class="o">(</span>30m ago<span class="o">)</span>    17h
vehicle-telemetry-56c7f8d859-jvtpj                          2/2     Running   4 <span class="o">(</span>30m ago<span class="o">)</span>    17h
webapp-59bc7757fb-trnnv                                     2/2     Running   6 <span class="o">(</span>30m ago<span class="o">)</span>    17h</code></pre></figure>

<p><img src="/assets/istio2-2.png" alt="image tooltip here" /></p>

<p><b>How Jaeger Works</b></p>

<p>When a request enters a microservice (e.g., a user making a request to a frontend service), the tracing library creates a span and assigns it a trace ID. As the request propagates through other services, additional spans are created and linked to the same trace ID. Each span is recorded with its respective start and end timestamps, operation name, and other metadata.</p>

<p>The Jaeger UI provides a way to visualize traces. Users can search for traces based on various criteria (e.g., service name, operation name, duration) and view the detailed structure of individual traces, like durations of time spent between microservices.</p>

<p>As the request flows through different services, each service creates additional or child spans. (e.g., The frontend service might call an authentication service. then authentication service call a user service, thus Jaeger will create 2 child spans)</p>

<p><img src="/assets/istio2-1.png" alt="image tooltip here" /></p>

<p><b>Latency and Performance Analysis</b></p>

<p>By examining the durations of each span, If a particular span has a long duration, that service might be a bottleneck.
If spans have significant gaps between them, network latency or queuing delays might be an issue. so we can identify which part of the request is taking the most time and investigate further to optimize performance.</p>

<p><img src="/assets/istio2-4.png" alt="image tooltip here" /></p>

<p><b>Manage routing in each service from Kiali </b></p>

<p>Managing routing in Istio can be done either through the Kiali console or by defining VirtualServices and DestinationRules using Kubernetes YAML manifests. here from Kiali console, we have the visualization of each service traffic flow, metrics, and dependencies between services in real-time.</p>

<p>By create weighted routing or suspend traffic, Kiali will create it own VirtualServices and DestinationRules to manage the traffic</p>

<p><img src="/assets/istio2-3.png" alt="image tooltip here" /></p>

<p><b>Add timeout in istio virtual service YAML</b></p>

<p>To add a timeout into istio virtual service YAML and ensure it works with Jaeger for better visibility and efficiency in the microservice architecture.</p>

<p>By adding this timeout to 3s for bellow “api-gateway” virtual service, Jaeger trace will aviod long response time when a request call api-gateway, any response longer than 3s will reture http timeout, which add visibility to Jaeger UI to determine if the request successful or not.</p>

<figure class="highlight"><pre><code class="language-shell" data-lang="shell">apiVersion: networking.istio.io/v1alpha3
kind: VirtualService
metadata:
  name: api-gateway
spec:
  hosts:
  - api-gateway
  http:
  - route:
    - destination:
        host: api-gateway
        port:
          number: 80
    <span class="nb">timeout</span>: 3s <span class="c"># 3 seconds timeout add</span></code></pre></figure>

<p><b> Conclusion</b></p>

<p>In this session we deep dive into Istio add-on Jaeger for distributed tracing, which Jaeger facilitates, involves tracking requests as they flow through various services and components of an application. This helps identify bottlenecks, understand service dependencies, and improve overall performance.</p>

<p>In the next post I will see how to use Istio and Kiali to run some Canary Releases, Blue-Green deployment Rolling Updates and A/B Testing.</p>]]></content><author><name></name></author><category term="jekyll" /><category term="Cat2" /><summary type="html"><![CDATA[About Jaeger]]></summary></entry><entry><title type="html">Istio: Traffic Routing</title><link href="http://localhost:4000/jekyll/cat2/2024/05/22/istio.html" rel="alternate" type="text/html" title="Istio: Traffic Routing" /><published>2024-05-22T10:15:29+10:00</published><updated>2024-05-22T10:15:29+10:00</updated><id>http://localhost:4000/jekyll/cat2/2024/05/22/istio</id><content type="html" xml:base="http://localhost:4000/jekyll/cat2/2024/05/22/istio.html"><![CDATA[<p><b>Helm install istio </b></p>

<p>Here we use helm to install istio (istio-base, istiod, istia gateway), then deploy a sample online book store microservice “bookinfo”, practise istio tasks include Traffic Management, Observability, Security.</p>

<p>Bookinfo Topology:</p>

<p><img src="/assets/bookinfo.png" alt="image tooltip here" /></p>

<ul>
  <li>Helm install istio (istiod, istio-ingress)</li>
</ul>

<figure class="highlight"><pre><code class="language-shell" data-lang="shell">kubectl create namespace istio-system
helm pull istio/base
helm <span class="nb">install </span>istio-base <span class="nb">.</span> <span class="nt">-n</span> istio-system <span class="nt">--set</span> <span class="nv">defaultRevision</span><span class="o">=</span>default

helm pull istio/istiod
helm <span class="nb">install </span>istiod <span class="nb">.</span> <span class="nt">-n</span> istio-system 

kubectl create namespace istio-ingress
helm pull istio/gateway
helm <span class="nb">install </span>istio-ingress <span class="nb">.</span> <span class="nt">-n</span> istio-ingress

helm <span class="nb">ls</span> <span class="nt">-n</span> istio-system
NAME      	NAMESPACE   	REVISION	UPDATED                                	STATUS  	CHART        	APP VERSION
istio-base	istio-system	1       	2023-12-17 08:14:06.943276388 +0800 CST	deployed	base-1.20.1  	1.20.1     
istiod    	istio-system	1       	2023-12-17 08:15:40.370551503 +0800 CST	deployed	istiod-1.20.1	1.20.1 

helm <span class="nb">ls</span> <span class="nt">-n</span> istio-ingress
NAME         	NAMESPACE    	REVISION	UPDATED                                	STATUS  	CHART         	APP VERSION
istio-ingress	istio-ingress	1       	2023-12-17 08:25:07.111999373 +0800 CST	deployed	gateway-1.20.1	1.20.1</code></pre></figure>

<ul>
  <li>Deploy bookinfo microservice and istio ingressgateway and virtualservice</li>
</ul>

<figure class="highlight"><pre><code class="language-shell" data-lang="shell">kubectl label namespace istio-system istio-injection<span class="o">=</span>enabled

kubectl apply <span class="nt">-f</span> https://github.com/istio/istio/blob/master/samples/bookinfo/platform/kube/bookinfo.yaml <span class="nt">-oyaml</span> <span class="o">&gt;</span> bookinfo.yaml
kubectl apply <span class="nt">-f</span> bookinfo.yaml

kubectl get po
NAME                                                     READY   STATUS    RESTARTS       AGE
details-v1-698d88b-wmfcb                                 2/2     Running   0              21m
ratings-v1-6484c4d9bb-cb6gx                              2/2     Running   0              21m
reviews-v1-5b5d6494f4-jrsvc                              2/2     Running   0              21m
reviews-v2-5b667bcbf8-jgfzj                              2/2     Running   0              21m
reviews-v3-5b9bd44f4-tmmfz                               2/2     Running   0              21m

kubectl apply <span class="nt">-f</span> https://github.com/istio/istio/blob/master/samples/bookinfo/networking/bookinfo-gateway.yaml <span class="nt">-oyaml</span> <span class="o">&gt;</span> bookinfo-gateway.yaml
kubectl apply <span class="nt">-f</span> bookinfo-gateway.yaml</code></pre></figure>

<ul>
  <li>Deploy Kiali, jaeger, grafana, prometheus</li>
</ul>

<figure class="highlight"><pre><code class="language-shell" data-lang="shell">wget https://raw.githubusercontent.com/istio/istio/release-1.20/samples/addons/prometheus.yaml
wget https://raw.githubusercontent.com/istio/istio/release-1.20/samples/addons/jaeger.yaml
wget https://raw.githubusercontent.com/istio/istio/release-1.20/samples/addons/grafana.yaml
kubectl create <span class="nt">-f</span> prometheus.yaml <span class="nt">-f</span> jaeger.yaml <span class="nt">-f</span> grafana.yaml</code></pre></figure>

<ul>
  <li>
    <p>visit http://book.istio:31000/productpage, with review (v1, v2, v3)
<img src="/assets/kiali.png" alt="image tooltip here" /></p>
  </li>
  <li>
    <p>define destination rules and virtual service for reviews</p>
  </li>
</ul>

<figure class="highlight"><pre><code class="language-shell" data-lang="shell">wget https://raw.githubusercontent.com/istio/istio/master/samples/bookinfo/networking/destination-rule-all.yaml
wget https://raw.githubusercontent.com/istio/istio/master/samples/bookinfo/networking/virtual-service-reviews-90-10.yaml

kubectl create <span class="nt">-f</span> destination-rule-all.yaml <span class="nt">-f</span> virtual-service-reviews-90-10.yaml   <span class="c"># route v1 10% and v3 90%</span>
kubectl scale deployment reviews-v2 <span class="nt">-n</span> istio-system <span class="nt">--replicas</span><span class="o">=</span>0 <span class="c"># scale down v2 to 0</span>

kubectl get dr <span class="nt">-A</span>
NAMESPACE      NAME          HOST          AGE
istio-system   details       details       6m56s
istio-system   productpage   productpage   6m56s
istio-system   ratings       ratings       6m56s
istio-system   reviews       reviews       6m56s
kubectl get vs <span class="nt">-A</span>
NAMESPACE      NAME       GATEWAYS               HOSTS            AGE
istio-system   bookinfo   <span class="o">[</span><span class="s2">"bookinfo-gateway"</span><span class="o">]</span>   <span class="o">[</span><span class="s2">"book.istio"</span><span class="o">]</span>   19h
istio-system   reviews                           <span class="o">[</span><span class="s2">"reviews"</span><span class="o">]</span>      5m26s

Spec:
  Hosts:
    reviews
  Http:
    Route:
      Destination:
        Host:    reviews
        Subset:  v1
      Weight:    10
      Destination:
        Host:    reviews
        Subset:  v3
      Weight:    90</code></pre></figure>

<p>refresh bookinfo webpage, test Traffic route weight as bellow</p>

<p>90% traffic for reviews v3  vs  10% traffic for review v1</p>

<p><img src="/assets/1090.png" alt="image tooltip here" /></p>]]></content><author><name></name></author><category term="jekyll" /><category term="Cat2" /><summary type="html"><![CDATA[Helm install istio]]></summary></entry><entry><title type="html">Terraform Module for AWS SSO User Assignment</title><link href="http://localhost:4000/jekyll/cat2/2024/05/20/terraform1.html" rel="alternate" type="text/html" title="Terraform Module for AWS SSO User Assignment" /><published>2024-05-20T10:15:29+10:00</published><updated>2024-05-20T10:15:29+10:00</updated><id>http://localhost:4000/jekyll/cat2/2024/05/20/terraform1</id><content type="html" xml:base="http://localhost:4000/jekyll/cat2/2024/05/20/terraform1.html"><![CDATA[<p><b> Challange About AWS SSO User Assignment</b></p>

<p>In the company, we use AWS SSO for user authentication; when a new user is created from Azure AD, it will automatically synced by AWS IAM Identity Center and Azure AD integration, and then our team will need to handle the SSO user assignment to put them in the required AWS accounts with requested permission sets, it became a pain when such requests coming more frequently and every time an individual user or a whole team with different accounts and permission requirements need to be fulfilled, so how to handle this efficiently become my recent topic.</p>

<p>So far, I have tried shell script and Python script to read the user name, AWS account ID, and permission sets ARN from a CSV file, then complete the task with AWScli. However it is not smart enough when the request or scenario changes. I have to adjust the script everytime.</p>

<p><b> Managing individual request via Terraform </b></p>

<p>Let’s start with handling user assignment individually with terraform first. here I have 2 requests:</p>

<ol>
  <li>
    <p>A user “user1@company.com”, under a group called “AD-RDS-READ-ONLY” in AWS IAM Identity Center, I need to create a permission set in aws account “123456789”, and assign to this user.</p>
  </li>
  <li>
    <p>The second request is from security team, we have 3 security team members (security1@company.com, security2@company.com, security3@company.com), under a group called “AD-ACM-FULL-ACCESS” in AWS IAM Identity Center, they all need full access for AWS certificate manager access, for all of our 3 AWS accounts (12345678901, 12345678902, and 12345678903).</p>
  </li>
</ol>

<figure class="highlight"><pre><code class="language-shell" data-lang="shell">vim main.tf

<span class="c"># For Request 1 for RDS read only access for 1 user in 1 AWS account </span>

<span class="c"># for AWS in ap-southeast-2</span>
provider <span class="s2">"aws"</span> <span class="o">{</span>
 region <span class="o">=</span> <span class="s2">"ap-southeast-2"</span>
<span class="o">}</span>

<span class="c"># Define the AWS SSO Instance ARN</span>
data <span class="s2">"aws_ssoadmin_instances"</span> <span class="s2">"main"</span> <span class="o">{}</span>

resource <span class="s2">"aws_ssoadmin_permission_set"</span> <span class="s2">"request1"</span> <span class="o">{</span>
 instance_arn <span class="o">=</span> data.aws_ssoadmin_instances.main.arns[0]
 name         <span class="o">=</span> <span class="s2">"RDS-ReadOnly"</span>
 description  <span class="o">=</span> <span class="s2">"Read-only access to RDS resources"</span>
 session_duration <span class="o">=</span> <span class="s2">"PT1H"</span>

 <span class="c"># Add the policies you need for this permission set</span>
 managed_policies <span class="o">=</span> <span class="o">[</span>
 <span class="s2">"arn:aws:iam::aws:policy/AmazonRDSReadOnlyAccess"</span>,
 <span class="o">]</span>
<span class="o">}</span>

resource <span class="s2">"aws_ssoadmin_account_assignment"</span> <span class="s2">"request1"</span> <span class="o">{</span>
 instance_arn       <span class="o">=</span> data.aws_ssoadmin_instances.main.arns[0]
 permission_set_arn <span class="o">=</span> aws_ssoadmin_permission_set.request1.arn
 principal_id       <span class="o">=</span> <span class="s2">"user1@company.com"</span>
 principal_type     <span class="o">=</span> <span class="s2">"USER"</span>
 target_id          <span class="o">=</span> <span class="s2">"123456789"</span>  # Replace with your AWS Account ID
 target_type        <span class="o">=</span> <span class="s2">"AWS_ACCOUNT"</span>
<span class="o">}</span>

<span class="c"># Ensure the user is part of the required group</span>
data <span class="s2">"aws_identitystore_group"</span> <span class="s2">"request1"</span> <span class="o">{</span>
 identity_store_id <span class="o">=</span> data.aws_ssoadmin_instances.main.identity_store_id
 display_name      <span class="o">=</span> <span class="s2">"AD-RDS-READ-ONLY"</span>
<span class="o">}</span>

resource <span class="s2">"aws_ssoadmin_group_membership"</span> <span class="s2">"request1"</span> <span class="o">{</span>
 identity_store_id <span class="o">=</span> data.aws_ssoadmin_instances.main.identity_store_id
 group_id          <span class="o">=</span> data.aws_identitystore_group.request1.group_id
 user_ids          <span class="o">=</span> <span class="o">[</span><span class="s2">"user1@company.com"</span><span class="o">]</span>
<span class="o">}</span>

<span class="c"># handle request 2 for ACM full access for whole security team in all 3 AWS accounts </span>

vim main.tf

<span class="c"># use existing main.tf file  </span>
<span class="c"># provider "aws" {</span>
<span class="c">#  region = "ap-southeast-2"</span>
<span class="c"># }</span>
<span class="c"># data "aws_ssoadmin_instances" "main" {}</span>

<span class="c"># Create the Permission Set for ACM Full Access</span>
resource <span class="s2">"aws_ssoadmin_permission_set"</span> <span class="s2">"acm_full_access"</span> <span class="o">{</span>
 instance_arn <span class="o">=</span> data.aws_ssoadmin_instances.main.arns[0]
 name         <span class="o">=</span> <span class="s2">"ACM-FullAccess"</span>
 description  <span class="o">=</span> <span class="s2">"Full access to AWS Certificate Manager"</span>
 session_duration <span class="o">=</span> <span class="s2">"PT1H"</span>

 managed_policies <span class="o">=</span> <span class="o">[</span>
 <span class="s2">"arn:aws:iam::aws:policy/AWSCertificateManagerFullAccess"</span>,
 <span class="o">]</span>
<span class="o">}</span>

<span class="c"># List of AWS account IDs</span>
<span class="c"># here we use terrafom "locals", "dynamic" and "for_each" to loop SSO user assignment for security team within all AWS accounts </span>
locals <span class="o">{</span>
 aws_account_ids <span class="o">=</span> <span class="o">[</span><span class="s2">"12345678901"</span>, <span class="s2">"12345678902"</span>, <span class="s2">"12345678903"</span><span class="o">]</span>
<span class="o">}</span>

<span class="c"># Security team members</span>
locals <span class="o">{</span>
 security_team_members <span class="o">=</span> <span class="o">[</span><span class="s2">"security1@company.com"</span>, <span class="s2">"security2@company.com"</span>, <span class="s2">"security3@company.com"</span><span class="o">]</span>
<span class="o">}</span>

<span class="c"># Ensure the users are part of the required group</span>
data <span class="s2">"aws_identitystore_group"</span> <span class="s2">"acm_full_access_group"</span> <span class="o">{</span>
 identity_store_id <span class="o">=</span> data.aws_ssoadmin_instances.main.identity_store_id
 display_name      <span class="o">=</span> <span class="s2">"AD-ACM-FULL-ACCESS"</span>
<span class="o">}</span>

resource <span class="s2">"aws_ssoadmin_group_membership"</span> <span class="s2">"acm_full_access_membership"</span> <span class="o">{</span>
 identity_store_id <span class="o">=</span> data.aws_ssoadmin_instances.main.identity_store_id
 group_id          <span class="o">=</span> data.aws_identitystore_group.acm_full_access_group.group_id
 user_ids          <span class="o">=</span> local.security_team_members
<span class="o">}</span>

<span class="c"># Assign the Permission Set to Each User for Each Account</span>
resource <span class="s2">"aws_ssoadmin_account_assignment"</span> <span class="s2">"acm_full_access_assignments"</span> <span class="o">{</span>
 for_each <span class="o">=</span> <span class="o">{</span> <span class="k">for </span>acc_id <span class="k">in </span>local.aws_account_ids : acc_id <span class="o">=&gt;</span> acc_id <span class="o">}</span>

 instance_arn       <span class="o">=</span> data.aws_ssoadmin_instances.main.arns[0]
 permission_set_arn <span class="o">=</span> aws_ssoadmin_permission_set.acm_full_access.arn
 principal_type     <span class="o">=</span> <span class="s2">"USER"</span>
 target_type        <span class="o">=</span> <span class="s2">"AWS_ACCOUNT"</span>

 dynamic <span class="s2">"assignment"</span> <span class="o">{</span>
 for_each <span class="o">=</span> local.security_team_members
 content <span class="o">{</span>
 principal_id <span class="o">=</span> assignment.value
 target_id    <span class="o">=</span> each.key
 <span class="o">}</span>
 <span class="o">}</span>
<span class="o">}</span></code></pre></figure>

<p><b> Terraform Modularity </b></p>

<p>How about the Terraform module, as I will get different user assignment requests with different permission sets and AWS accounts? I guess a Terraform module for SSO user assignment is the best way to make the Terraform code more clean and reuseable. There are many benefits to infrastructure as code with modularity. It can reduce code duplication, is easy to update, and has a clear code structure, which fits my AWS SSO user assignment task and challenge perfectly.</p>

<p>To achieve this, I will need to create a folder called “sso_user_assignment_module”, inside the folder it will contain:</p>

<ul>
  <li>A “main.tf” file to define the resources for creating permission sets and assigning them to users.</li>
</ul>

<figure class="highlight"><pre><code class="language-shell" data-lang="shell"><span class="c"># modules/sso_account_assignment/main.tf</span>

provider <span class="s2">"aws"</span> <span class="o">{</span>
 region <span class="o">=</span> var.aws_region
<span class="o">}</span>

data <span class="s2">"aws_ssoadmin_instances"</span> <span class="s2">"main"</span> <span class="o">{}</span>

resource <span class="s2">"aws_ssoadmin_permission_set"</span> <span class="s2">"this"</span> <span class="o">{</span>
 for_each <span class="o">=</span> var.permission_sets

 instance_arn <span class="o">=</span> data.aws_ssoadmin_instances.main.arns[0]
 name         <span class="o">=</span> each.key
 description  <span class="o">=</span> each.value.description
 session_duration <span class="o">=</span> each.value.session_duration

 managed_policies <span class="o">=</span> each.value.managed_policies
<span class="o">}</span>

resource <span class="s2">"aws_ssoadmin_account_assignment"</span> <span class="s2">"this"</span> <span class="o">{</span>
 for_each <span class="o">=</span> <span class="o">{</span> <span class="k">for </span>ps_key, ps_value <span class="k">in </span>var.permission_sets : ps_key <span class="o">=&gt;</span> ps_value.accounts <span class="o">}</span>

 instance_arn       <span class="o">=</span> data.aws_ssoadmin_instances.main.arns[0]
 permission_set_arn <span class="o">=</span> aws_ssoadmin_permission_set.this[each.key].arn
 principal_type     <span class="o">=</span> <span class="s2">"USER"</span>
 target_type        <span class="o">=</span> <span class="s2">"AWS_ACCOUNT"</span>

 dynamic <span class="s2">"assignment"</span> <span class="o">{</span>
 for_each <span class="o">=</span> each.value.users
 content <span class="o">{</span>
 principal_id <span class="o">=</span> assignment.value
 target_id    <span class="o">=</span> each.value.account_id
 <span class="o">}</span>
 <span class="o">}</span>
<span class="o">}</span>

data <span class="s2">"aws_identitystore_group"</span> <span class="s2">"this"</span> <span class="o">{</span>
 for_each <span class="o">=</span> var.groups

 identity_store_id <span class="o">=</span> data.aws_ssoadmin_instances.main.identity_store_id
 display_name      <span class="o">=</span> each.key
<span class="o">}</span>

resource <span class="s2">"aws_ssoadmin_group_membership"</span> <span class="s2">"this"</span> <span class="o">{</span>
 for_each <span class="o">=</span> var.groups

 identity_store_id <span class="o">=</span> data.aws_ssoadmin_instances.main.identity_store_id
 group_id          <span class="o">=</span> data.aws_identitystore_group.this[each.key].group_id
 user_ids          <span class="o">=</span> each.value
<span class="o">}</span></code></pre></figure>

<ul>
  <li>A “variables.tf” to define the input variables for the module</li>
</ul>

<figure class="highlight"><pre><code class="language-shell" data-lang="shell"><span class="c"># variables.tf</span>
vim variables.tf

provider <span class="s2">"aws"</span> <span class="o">{</span>
 region <span class="o">=</span> var.region
<span class="o">}</span>

variable <span class="s2">"sso_instance_arn"</span> <span class="o">{</span>
 description <span class="o">=</span> <span class="s2">"The ARN of the AWS SSO instance"</span>
 <span class="nb">type</span>    <span class="o">=</span> string
<span class="o">}</span>

variable <span class="s2">"assignments"</span> <span class="o">{</span>
 description <span class="o">=</span> <span class="s2">"Map of account IDs to users and their permission sets"</span>
 <span class="nb">type</span>    <span class="o">=</span> map<span class="o">(</span>list<span class="o">(</span>object<span class="o">({</span>
 principal_id   <span class="o">=</span> string
 permission_set_arn <span class="o">=</span> string
 <span class="o">})))</span>
<span class="o">}</span>

variable <span class="s2">"region"</span> <span class="o">{</span>
 description <span class="o">=</span> <span class="s2">"AWS region"</span>
 <span class="nb">type</span>    <span class="o">=</span> string
 default  <span class="o">=</span> <span class="s2">"ap-southeast-2"</span>
<span class="o">}</span>

module <span class="s2">"sso_account_assignments"</span> <span class="o">{</span>
 <span class="nb">source</span> <span class="o">=</span> <span class="s2">"./modules/sso_account_assignment"</span>

 for_each    <span class="o">=</span> var.assignments
 sso_instance_arn <span class="o">=</span> var.sso_instance_arn
 account_id   <span class="o">=</span> each.key
 <span class="nb">users</span>     <span class="o">=</span> each.value
<span class="o">}</span></code></pre></figure>

<ul>
  <li>A “outputs.tf” file to define the outputs of the module.</li>
</ul>

<figure class="highlight"><pre><code class="language-shell" data-lang="shell">vim outputs.tf
<span class="c"># define outputs of permission_set_arns and group_ids</span>
output <span class="s2">"permission_set_arns"</span> <span class="o">{</span>
 value <span class="o">=</span> <span class="o">{</span> <span class="k">for </span>k, v <span class="k">in </span>aws_ssoadmin_permission_set.this : k <span class="o">=&gt;</span> v.arn <span class="o">}</span>
<span class="o">}</span>

output <span class="s2">"group_ids"</span> <span class="o">{</span>
 value <span class="o">=</span> <span class="o">{</span> <span class="k">for </span>k, v <span class="k">in </span>data.aws_identitystore_group.this : k <span class="o">=&gt;</span> v.group_id <span class="o">}</span>
<span class="o">}</span></code></pre></figure>

<ul>
  <li>now we need to Create a Terraform configuration that uses this module and set the environment variables accordingly. go back to the root folder, create a root “main.tf” file to call the module and pass the necessary variables.</li>
</ul>

<figure class="highlight"><pre><code class="language-shell" data-lang="shell"><span class="nb">cd</span> ..
vim main.tf
<span class="c"># the root main.tf file</span>
module <span class="s2">"sso_permission_sets"</span> <span class="o">{</span>
 <span class="nb">source</span> <span class="o">=</span> <span class="s2">"./modules/aws_sso_permission_sets"</span>

 aws_region       <span class="o">=</span> var.aws_region
 permission_sets  <span class="o">=</span> var.permission_sets
 <span class="nb">groups</span>           <span class="o">=</span> var.groups
<span class="o">}</span>

<span class="c"># Optionally output the values</span>
output <span class="s2">"permission_set_arns"</span> <span class="o">{</span>
 value <span class="o">=</span> module.sso_permission_sets.permission_set_arns
<span class="o">}</span>

output <span class="s2">"group_ids"</span> <span class="o">{</span>
 value <span class="o">=</span> module.sso_permission_sets.group_ids
<span class="o">}</span></code></pre></figure>

<ul>
  <li>root “variables.tf” file to define the input variables for the root configuration.</li>
</ul>

<figure class="highlight"><pre><code class="language-shell" data-lang="shell"><span class="c"># the root variables.tf</span>
vim variables.tf

variable <span class="s2">"aws_region"</span> <span class="o">{</span>
 description <span class="o">=</span> <span class="s2">"The AWS region to use."</span>
 <span class="nb">type</span>        <span class="o">=</span> string
 default     <span class="o">=</span> <span class="s2">"ap-southeast-2"</span>
<span class="o">}</span>

variable <span class="s2">"permission_sets"</span> <span class="o">{</span>
 description <span class="o">=</span> <span class="s2">"A map of permission sets with their configurations."</span>
 <span class="nb">type</span> <span class="o">=</span> map<span class="o">(</span>object<span class="o">({</span>
 description     <span class="o">=</span> string
 session_duration <span class="o">=</span> string
 managed_policies <span class="o">=</span> list<span class="o">(</span>string<span class="o">)</span>
 accounts        <span class="o">=</span> map<span class="o">(</span>object<span class="o">({</span>
 account_id <span class="o">=</span> string
 <span class="nb">users</span>      <span class="o">=</span> list<span class="o">(</span>string<span class="o">)</span>
 <span class="o">}))</span>
 <span class="o">}))</span>
<span class="o">}</span>

variable <span class="s2">"groups"</span> <span class="o">{</span>
 description <span class="o">=</span> <span class="s2">"A map of groups with their associated user emails."</span>
 <span class="nb">type</span>        <span class="o">=</span> map<span class="o">(</span>list<span class="o">(</span>string<span class="o">))</span>
<span class="o">}</span></code></pre></figure>

<ul>
  <li>now is the place we can reuse the module to create the root “terraform.tfvars” which provides the actual values for the variables to define each assignment request. in future we only set each request here as environment variables, and then apply the terraform module.</li>
</ul>

<figure class="highlight"><pre><code class="language-shell" data-lang="shell">aws_region <span class="o">=</span> <span class="s2">"ap-southeast-2"</span>

permission_sets <span class="o">=</span> <span class="o">{</span>
 <span class="c"># The 1st request RDS read-only permission sets and user assignment redefine in the module using variables</span>
 <span class="s2">"RDS-ReadOnly"</span> <span class="o">=</span> <span class="o">{</span>
 description     <span class="o">=</span> <span class="s2">"Read-only access to RDS resources"</span>
 session_duration <span class="o">=</span> <span class="s2">"PT1H"</span>
 managed_policies <span class="o">=</span> <span class="o">[</span>
 <span class="s2">"arn:aws:iam::aws:policy/AmazonRDSReadOnlyAccess"</span>,
 <span class="o">]</span>
 accounts <span class="o">=</span> <span class="o">{</span>
 <span class="s2">"123456789"</span> <span class="o">=</span> <span class="o">{</span>
 account_id <span class="o">=</span> <span class="s2">"123456789"</span>
 <span class="nb">users</span>      <span class="o">=</span> <span class="o">[</span><span class="s2">"user1@company.com"</span><span class="o">]</span>
 <span class="o">}</span>
 <span class="o">}</span>
 <span class="o">}</span>
 <span class="c"># the 2nd request security full access for ACM redefine in the module using variables</span>
 <span class="s2">"ACM-FullAccess"</span> <span class="o">=</span> <span class="o">{</span>
 description     <span class="o">=</span> <span class="s2">"Full access to AWS Certificate Manager"</span>
 session_duration <span class="o">=</span> <span class="s2">"PT1H"</span>
 managed_policies <span class="o">=</span> <span class="o">[</span>
 <span class="s2">"arn:aws:iam::aws:policy/AWSCertificateManagerFullAccess"</span>,
 <span class="o">]</span>
 accounts <span class="o">=</span> <span class="o">{</span>
 <span class="s2">"12345678901"</span> <span class="o">=</span> <span class="o">{</span>
 account_id <span class="o">=</span> <span class="s2">"12345678901"</span>
 <span class="nb">users</span>      <span class="o">=</span> <span class="o">[</span><span class="s2">"security1@company.com"</span>, <span class="s2">"security2@company.com"</span>, <span class="s2">"security3@company.com"</span><span class="o">]</span>
 <span class="o">}</span>,
 <span class="s2">"12345678902"</span> <span class="o">=</span> <span class="o">{</span>
 account_id <span class="o">=</span> <span class="s2">"12345678902"</span>
 <span class="nb">users</span>      <span class="o">=</span> <span class="o">[</span><span class="s2">"security1@company.com"</span>, <span class="s2">"security2@company.com"</span>, <span class="s2">"security3@company.com"</span><span class="o">]</span>
 <span class="o">}</span>,
 <span class="s2">"12345678903"</span> <span class="o">=</span> <span class="o">{</span>
 account_id <span class="o">=</span> <span class="s2">"12345678903"</span>
 <span class="nb">users</span>      <span class="o">=</span> <span class="o">[</span><span class="s2">"security1@company.com"</span>, <span class="s2">"security2@company.com"</span>, <span class="s2">"security3@company.com"</span><span class="o">]</span>
 <span class="o">}</span>
 <span class="o">}</span>
 <span class="o">}</span>

 <span class="c"># Add 3rd request a developer needs S3 full access for 2 AWS accounts redefine in the module using variables</span>
 <span class="s2">"S3-ModifyAccess"</span> <span class="o">=</span> <span class="o">{</span>
 description     <span class="o">=</span> <span class="s2">"Modify access to S3 buckets"</span>
 session_duration <span class="o">=</span> <span class="s2">"PT1H"</span>
 managed_policies <span class="o">=</span> <span class="o">[</span>
 <span class="s2">"arn:aws:iam::aws:policy/AmazonS3FullAccess"</span>,
 <span class="o">]</span>
 accounts <span class="o">=</span> <span class="o">{</span>
 <span class="s2">"12345678902"</span> <span class="o">=</span> <span class="o">{</span>
 account_id <span class="o">=</span> <span class="s2">"12345678902"</span>
 <span class="nb">users</span>      <span class="o">=</span> <span class="o">[</span><span class="s2">"developer1@company.com"</span><span class="o">]</span>
 <span class="o">}</span>,
 <span class="s2">"12345678903"</span> <span class="o">=</span> <span class="o">{</span>
 account_id <span class="o">=</span> <span class="s2">"12345678903"</span>
 <span class="nb">users</span>      <span class="o">=</span> <span class="o">[</span><span class="s2">"developer1@company.com"</span><span class="o">]</span>
 <span class="o">}</span>
 <span class="o">}</span>
 <span class="o">}</span>
<span class="o">}</span>

<span class="nb">groups</span> <span class="o">=</span> <span class="o">{</span>
 <span class="s2">"AD-RDS-EAD-ONLY"</span> <span class="o">=</span> <span class="o">[</span><span class="s2">"user1@company.com"</span><span class="o">]</span>
 <span class="s2">"AD-ACM-FULL-ACCESS"</span> <span class="o">=</span> <span class="o">[</span><span class="s2">"security1@company.com"</span>, <span class="s2">"security2@company.com"</span>, <span class="s2">"security3@company.com"</span><span class="o">]</span>
 <span class="c"># Optionally add a group for the developer, if needed:</span>
 <span class="c"># "AD-S3-Modify-Access" = ["developer1@company.com"]</span>
<span class="o">}</span></code></pre></figure>

<p><b> Conclusion</b></p>

<p>Now, we can achieve the task individually via terraform code and a Terraform module to handle the creation of AWS SSO users, This setup combines all three requests into a single Terraform configuration, leveraging the reusable module for creating permission sets and managing user assignments, it is more efficient, dynamically, and reusable. In future, we only define permission sets and maintain new users and assignments in the environment variables .tf file, then run Terraform apply to get the job done. The change also can be tracked when leveraging Git as version control.</p>

<p><a href="https://girishcodealchemy.medium.com/streamlining-aws-sso-in-complex-multi-account-environments-e82025792d11">Streamlining AWS SSO in Complex Multi-Account Environments</a></p>]]></content><author><name></name></author><category term="jekyll" /><category term="Cat2" /><summary type="html"><![CDATA[Challange About AWS SSO User Assignment]]></summary></entry><entry><title type="html">Python Flask: API Gateway &amp;amp; Consul</title><link href="http://localhost:4000/jekyll/cat2/2024/05/19/py-flask2.html" rel="alternate" type="text/html" title="Python Flask: API Gateway &amp;amp; Consul" /><published>2024-05-19T10:15:29+10:00</published><updated>2024-05-19T10:15:29+10:00</updated><id>http://localhost:4000/jekyll/cat2/2024/05/19/py-flask2</id><content type="html" xml:base="http://localhost:4000/jekyll/cat2/2024/05/19/py-flask2.html"><![CDATA[<p><b> About API Gateway</b></p>

<p>API Gateway acts as a single entry point for all clients and handles the request routing, composition, and protocol translation in a microservices architecture, here I will create a API Gateway using Python Flask and requests library, to route both “user” and “order” services.</p>

<p>Create an API Gateway to handle the 2 services.</p>

<figure class="highlight"><pre><code class="language-shell" data-lang="shell"><span class="c"># Folder Structure</span>
03-with-api-gatway/
├── user_service/
│   ├── Dockerfile
│   └── user_service.py
├── order_service/
│   ├── Dockerfile
│   └── order_service.py
├── api_gateway/
│   ├── Dockerfile
│   └── api_gateway.py
├── docker-compose.yml

<span class="c"># api_gateway.py</span>
from flask import Flask, jsonify
import requests

app <span class="o">=</span> Flask<span class="o">(</span>__name__<span class="o">)</span>

@app.route<span class="o">(</span><span class="s1">'/users'</span><span class="o">)</span>
def get_users<span class="o">()</span>:
 response <span class="o">=</span> requests.get<span class="o">(</span><span class="s1">'http://user-service:5001/users'</span><span class="o">)</span>
 <span class="k">return </span>jsonify<span class="o">(</span>response.json<span class="o">())</span>

@app.route<span class="o">(</span><span class="s1">'/orders'</span><span class="o">)</span>
def get_orders<span class="o">()</span>:
 response <span class="o">=</span> requests.get<span class="o">(</span><span class="s1">'http://order-service:5002/orders'</span><span class="o">)</span>
 <span class="k">return </span>jsonify<span class="o">(</span>response.json<span class="o">())</span>

<span class="k">if </span>__name__ <span class="o">==</span> <span class="s1">'__main__'</span>:
 app.run<span class="o">(</span><span class="nv">host</span><span class="o">=</span><span class="s1">'0.0.0.0'</span>, <span class="nv">port</span><span class="o">=</span>5000<span class="o">)</span>

<span class="c"># Dockerfile_apigateway</span>

<span class="c"># Use an official Python runtime as a parent image</span>
FROM python:3.9-slim

<span class="c"># Set the working directory in the container</span>
WORKDIR /app

<span class="c"># Copy the current directory contents into the container at /app</span>
COPY <span class="nb">.</span> /app

<span class="c"># Install flask requests</span>
RUN pip <span class="nb">install</span> <span class="nt">--no-cache-dir</span> flask requests

<span class="c"># Make port 5000 available to the world outside this container</span>
EXPOSE 5000

<span class="c"># Define environment variable</span>
ENV <span class="nv">FLASK_APP</span><span class="o">=</span>api_gateway.py

<span class="c"># Run api_gateway.py when the container launches</span>
CMD <span class="o">[</span><span class="s2">"flask"</span>, <span class="s2">"run"</span>, <span class="s2">"--host=0.0.0.0"</span>, <span class="s2">"--port=5000"</span><span class="o">]</span>

<span class="c"># update docker-compose.yaml</span>

.....

 api-gateway:
 build:
 context: <span class="nb">.</span>
 dockerfile: Dockerfile_apigateway
 ports:
 - <span class="s2">"5000:5000"</span>

<span class="c"># run docker-compose up --build</span>

docker-compose up <span class="nt">--build</span></code></pre></figure>

<p>Verify the 2 services can be accessed via API Gateway address and port plus /users and /orders by defining request functions.</p>

<p><img src="/assets/flask4.png" alt="image tooltip here" />
<img src="/assets/flask5.png" alt="image tooltip here" /></p>

<p><b> About Consul</b></p>

<p>Consul is a popular open-source tool for service discovery and service registration, here I will update the py files to register both services with Consul</p>

<p>In both user_service.py and order_service.py add service registration logic.</p>

<figure class="highlight"><pre><code class="language-shell" data-lang="shell"><span class="c"># vim order_service.py</span>
import requests
from flask import Flask, jsonify
import <span class="nb">time

</span>app <span class="o">=</span> Flask<span class="o">(</span>__name__<span class="o">)</span>

@app.route<span class="o">(</span><span class="s1">'/orders'</span><span class="o">)</span>
def get_orders<span class="o">()</span>:
 orders <span class="o">=</span> <span class="o">[</span>
 <span class="o">{</span><span class="s1">'id'</span>: 1, <span class="s1">'item'</span>: <span class="s1">'Laptop'</span>, <span class="s1">'price'</span>: 1200<span class="o">}</span>,
 <span class="o">{</span><span class="s1">'id'</span>: 2, <span class="s1">'item'</span>: <span class="s1">'Phone'</span>, <span class="s1">'price'</span>: 800<span class="o">}</span>
 <span class="o">]</span>
 <span class="k">return </span>jsonify<span class="o">(</span>orders<span class="o">)</span>

def register_service<span class="o">()</span>:
 payload <span class="o">=</span> <span class="o">{</span>
 <span class="s2">"ID"</span>: <span class="s2">"order-service"</span>,
 <span class="s2">"Name"</span>: <span class="s2">"order-service"</span>,
 <span class="s2">"Address"</span>: <span class="s2">"order-service"</span>,
 <span class="s2">"Port"</span>: 5002
 <span class="o">}</span>
 <span class="k">while </span>True:
 try:
 response <span class="o">=</span> requests.put<span class="o">(</span><span class="s1">'http://consul:8500/v1/agent/service/register'</span>, <span class="nv">json</span><span class="o">=</span>payload<span class="o">)</span>
 <span class="k">if </span>response.status_code <span class="o">==</span> 200:
 print<span class="o">(</span><span class="s2">"Successfully registered order-service with Consul"</span><span class="o">)</span>
 <span class="nb">break
 </span><span class="k">else</span>:
 print<span class="o">(</span>f<span class="s2">"Failed to register order-service with Consul, status code: {response.status_code}"</span><span class="o">)</span>
 except requests.exceptions.RequestException as e:
 print<span class="o">(</span>f<span class="s2">"Error registering order-service with Consul: {e}"</span><span class="o">)</span>
 time.sleep<span class="o">(</span>5<span class="o">)</span>

<span class="k">if </span>__name__ <span class="o">==</span> <span class="s1">'__main__'</span>:
 print<span class="o">(</span><span class="s2">"Registering order-service with Consul"</span><span class="o">)</span>
 register_service<span class="o">()</span>
 app.run<span class="o">(</span><span class="nv">host</span><span class="o">=</span><span class="s1">'0.0.0.0'</span>, <span class="nv">port</span><span class="o">=</span>5002<span class="o">)</span>


<span class="c"># vim user_service.py</span>
import requests
from flask import Flask, jsonify
import <span class="nb">time

</span>app <span class="o">=</span> Flask<span class="o">(</span>__name__<span class="o">)</span>

@app.route<span class="o">(</span><span class="s1">'/users'</span><span class="o">)</span>
def get_users<span class="o">()</span>:
 <span class="nb">users</span> <span class="o">=</span> <span class="o">[</span>
 <span class="o">{</span><span class="s1">'id'</span>: 1, <span class="s1">'name'</span>: <span class="s1">'Alice'</span><span class="o">}</span>,
 <span class="o">{</span><span class="s1">'id'</span>: 2, <span class="s1">'name'</span>: <span class="s1">'Bob'</span><span class="o">}</span>
 <span class="o">]</span>
 <span class="k">return </span>jsonify<span class="o">(</span><span class="nb">users</span><span class="o">)</span>

def register_service<span class="o">()</span>:
 payload <span class="o">=</span> <span class="o">{</span>
 <span class="s2">"ID"</span>: <span class="s2">"user-service"</span>,
 <span class="s2">"Name"</span>: <span class="s2">"user-service"</span>,
 <span class="s2">"Address"</span>: <span class="s2">"user-service"</span>,
 <span class="s2">"Port"</span>: 5001
 <span class="o">}</span>
 <span class="k">while </span>True:
 try:
 response <span class="o">=</span> requests.put<span class="o">(</span><span class="s1">'http://consul:8500/v1/agent/service/register'</span>, <span class="nv">json</span><span class="o">=</span>payload<span class="o">)</span>
 <span class="k">if </span>response.status_code <span class="o">==</span> 200:
 print<span class="o">(</span><span class="s2">"Successfully registered user-service with Consul"</span><span class="o">)</span>
 <span class="nb">break
 </span><span class="k">else</span>:
 print<span class="o">(</span>f<span class="s2">"Failed to register user-service with Consul, status code: {response.status_code}"</span><span class="o">)</span>
 except requests.exceptions.RequestException as e:
 print<span class="o">(</span>f<span class="s2">"Error registering user-service with Consul: {e}"</span><span class="o">)</span>
 time.sleep<span class="o">(</span>5<span class="o">)</span>

<span class="k">if </span>__name__ <span class="o">==</span> <span class="s1">'__main__'</span>:
 print<span class="o">(</span><span class="s2">"Registering user-service with Consul"</span><span class="o">)</span>
 register_service<span class="o">()</span>
 app.run<span class="o">(</span><span class="nv">host</span><span class="o">=</span><span class="s1">'0.0.0.0'</span>, <span class="nv">port</span><span class="o">=</span>5001<span class="o">)</span>

<span class="c"># update docker-compose.yaml</span>

version: <span class="s1">'3'</span>
services:
 consul:
 image: consul:1.15.4
 ports:
 - <span class="s2">"8500:8500"</span>

 user-service:
 build:
 context: ./user_service
 depends_on:
 - consul
 environment:
 - <span class="nv">CONSUL_HTTP_ADDR</span><span class="o">=</span>consul:8500
 ports:
 - <span class="s2">"5001:5001"</span>

 order-service:
 build:
 context: ./order_service
 depends_on:
 - consul
 environment:
 - <span class="nv">CONSUL_HTTP_ADDR</span><span class="o">=</span>consul:8500
 ports:
 - <span class="s2">"5002:5002"</span>

 api-gateway:
 build:
 context: ./api_gateway
 depends_on:
 - consul
 - user-service
 - order-service
 environment:
 - <span class="nv">CONSUL_HTTP_ADDR</span><span class="o">=</span>consul:8500
 ports:
 - <span class="s2">"5000:5000"</span></code></pre></figure>

<p>Now run the docker-compose and verify in Consul via localhost:</p>

<figure class="highlight"><pre><code class="language-shell" data-lang="shell">docker-compose up <span class="nt">--build</span>

Creating 04-with-consul_consul_1 ... <span class="k">done
</span>Creating 04-with-consul_user-service_1  ... <span class="k">done
</span>Creating 04-with-consul_order-service_1 ... <span class="k">done
</span>Creating 04-with-consul_api-gateway_1   ... <span class="k">done

</span>consul_1         | 2024-05-18T14:28:45.465Z <span class="o">[</span>DEBUG] agent: Node info <span class="k">in </span><span class="nb">sync
</span>consul_1         | 2024-05-18T14:28:45.465Z <span class="o">[</span>DEBUG] agent: Service <span class="k">in </span><span class="nb">sync</span>: <span class="nv">service</span><span class="o">=</span>order-service
consul_1         | 2024-05-18T14:28:45.465Z <span class="o">[</span>DEBUG] agent: Service <span class="k">in </span><span class="nb">sync</span>: <span class="nv">service</span><span class="o">=</span>user-service</code></pre></figure>

<p><img src="/assets/flask6.png" alt="image tooltip here" /></p>

<p><b> Conclusion</b></p>

<p>Now we can use API gateway and Consul to manage route and service discovery.</p>

<p>In the next post, I will see how to enable logging with ELK stack and monitoring with Prometheus and Grafana stack.</p>]]></content><author><name></name></author><category term="jekyll" /><category term="Cat2" /><summary type="html"><![CDATA[About API Gateway]]></summary></entry><entry><title type="html">Python Flask: Monitoring with Prometheus and Grafana</title><link href="http://localhost:4000/jekyll/cat2/2024/05/19/py-flask4.html" rel="alternate" type="text/html" title="Python Flask: Monitoring with Prometheus and Grafana" /><published>2024-05-19T00:17:29+10:00</published><updated>2024-05-19T00:17:29+10:00</updated><id>http://localhost:4000/jekyll/cat2/2024/05/19/py-flask4</id><content type="html" xml:base="http://localhost:4000/jekyll/cat2/2024/05/19/py-flask4.html"><![CDATA[<p><b> About logging with ELK (Elasticsearch, Logstash, Kibana) Stack</b></p>

<p>ELK (Elasticsearch, Logstash, Kibana) is a popular log management solution. We will use the ELK Stack to collect and analyze logs. here I need to extend the current configuration by adding services for Elasticsearch, Logstash, and Kibana, and configure the microservices to send logs to Logstash.</p>

<p>Also, I will need to configure the logging in the Python applications to send logs to Logstash. Using the logging library in Python, I can send logs to Logstash using the GELF (Graylog Extended Log Format) format.</p>

<figure class="highlight"><pre><code class="language-shell" data-lang="shell"><span class="c"># folder structure </span>
05-with-ELK/
├── api_gateway/
│   └── Dockerfile
├── order_service/
│   └── Dockerfile
├── user_service/
│   └── Dockerfile
├── logstash.conf
└── docker-compose.yml

<span class="c"># create Logstash Configuration</span>
<span class="c"># vim logstash.conf</span>
input <span class="o">{</span>
 gelf <span class="o">{</span>
 port <span class="o">=&gt;</span> 12201
 <span class="o">}</span>
<span class="o">}</span>
output <span class="o">{</span>
 elasticsearch <span class="o">{</span>
 hosts <span class="o">=&gt;</span> <span class="o">[</span><span class="s2">"elasticsearch:9200"</span><span class="o">]</span>
 index <span class="o">=&gt;</span> <span class="s2">"%{[@metadata][beat]}-%{+YYYY.MM.dd}"</span>
 <span class="o">}</span>
<span class="o">}</span>
<span class="c"># vim user_service.py</span>

import logging
import requests
from flask import Flask, jsonify
from pygelf import GelfUdpHandler

app <span class="o">=</span> Flask<span class="o">(</span>__name__<span class="o">)</span>

@app.route<span class="o">(</span><span class="s1">'/users'</span><span class="o">)</span>
def get_users<span class="o">()</span>:
 <span class="nb">users</span> <span class="o">=</span> <span class="o">[</span>
 <span class="o">{</span><span class="s1">'id'</span>: 1, <span class="s1">'name'</span>: <span class="s1">'Alice'</span><span class="o">}</span>,
 <span class="o">{</span><span class="s1">'id'</span>: 2, <span class="s1">'name'</span>: <span class="s1">'Bob'</span><span class="o">}</span>
 <span class="o">]</span>
 app.logger.info<span class="o">(</span><span class="s2">"Fetched user data"</span><span class="o">)</span>
 <span class="k">return </span>jsonify<span class="o">(</span><span class="nb">users</span><span class="o">)</span>

def register_service<span class="o">()</span>:
 payload <span class="o">=</span> <span class="o">{</span>
 <span class="s2">"ID"</span>: <span class="s2">"user-service"</span>,
 <span class="s2">"Name"</span>: <span class="s2">"user-service"</span>,
 <span class="s2">"Address"</span>: <span class="s2">"user-service"</span>,
 <span class="s2">"Port"</span>: 5001
 <span class="o">}</span>
 response <span class="o">=</span> requests.put<span class="o">(</span><span class="s1">'http://consul:8500/v1/agent/service/register'</span>, <span class="nv">json</span><span class="o">=</span>payload<span class="o">)</span>
 <span class="k">if </span>response.status_code <span class="o">==</span> 200:
 app.logger.info<span class="o">(</span><span class="s2">"User service registered successfully"</span><span class="o">)</span>
 <span class="k">else</span>:
 app.logger.error<span class="o">(</span><span class="s2">"Failed to register user service"</span><span class="o">)</span>

<span class="k">if </span>__name__ <span class="o">==</span> <span class="s1">'__main__'</span>:
 <span class="c"># Configure logging</span>
 handler <span class="o">=</span> GelfUdpHandler<span class="o">(</span><span class="nv">host</span><span class="o">=</span><span class="s1">'logstash'</span>, <span class="nv">port</span><span class="o">=</span>12201<span class="o">)</span>
 app.logger.addHandler<span class="o">(</span>handler<span class="o">)</span>
 app.logger.setLevel<span class="o">(</span>logging.INFO<span class="o">)</span>
    
 register_service<span class="o">()</span>
 app.run<span class="o">(</span><span class="nv">host</span><span class="o">=</span><span class="s1">'0.0.0.0'</span>, <span class="nv">port</span><span class="o">=</span>5001<span class="o">)</span>

<span class="c"># vim order_service.py</span>

import logging
import requests
from flask import Flask, jsonify
from pygelf import GelfUdpHandler

app <span class="o">=</span> Flask<span class="o">(</span>__name__<span class="o">)</span>

@app.route<span class="o">(</span><span class="s1">'/orders'</span><span class="o">)</span>
def get_orders<span class="o">()</span>:
 orders <span class="o">=</span> <span class="o">[</span>
 <span class="o">{</span><span class="s1">'id'</span>: 1, <span class="s1">'item'</span>: <span class="s1">'Laptop'</span>, <span class="s1">'price'</span>: 1200<span class="o">}</span>,
 <span class="o">{</span><span class="s1">'id'</span>: 2, <span class="s1">'item'</span>: <span class="s1">'Phone'</span>, <span class="s1">'price'</span>: 800<span class="o">}</span>
 <span class="o">]</span>
 app.logger.info<span class="o">(</span><span class="s2">"Fetched order data"</span><span class="o">)</span>
 <span class="k">return </span>jsonify<span class="o">(</span>orders<span class="o">)</span>

def register_service<span class="o">()</span>:
 payload <span class="o">=</span> <span class="o">{</span>
 <span class="s2">"ID"</span>: <span class="s2">"order-service"</span>,
 <span class="s2">"Name"</span>: <span class="s2">"order-service"</span>,
 <span class="s2">"Address"</span>: <span class="s2">"order-service"</span>,
 <span class="s2">"Port"</span>: 5002
 <span class="o">}</span>
 response <span class="o">=</span> requests.put<span class="o">(</span><span class="s1">'http://consul:8500/v1/agent/service/register'</span>, <span class="nv">json</span><span class="o">=</span>payload<span class="o">)</span>
 <span class="k">if </span>response.status_code <span class="o">==</span> 200:
 app.logger.info<span class="o">(</span><span class="s2">"Order service registered successfully"</span><span class="o">)</span>
 <span class="k">else</span>:
 app.logger.error<span class="o">(</span><span class="s2">"Failed to register order service"</span><span class="o">)</span>

<span class="k">if </span>__name__ <span class="o">==</span> <span class="s1">'__main__'</span>:
 <span class="c"># Configure logging</span>
 handler <span class="o">=</span> GelfUdpHandler<span class="o">(</span><span class="nv">host</span><span class="o">=</span><span class="s1">'logstash'</span>, <span class="nv">port</span><span class="o">=</span>12201<span class="o">)</span>
 app.logger.addHandler<span class="o">(</span>handler<span class="o">)</span>
 app.logger.setLevel<span class="o">(</span>logging.INFO<span class="o">)</span>
    
 register_service<span class="o">()</span>
 app.run<span class="o">(</span><span class="nv">host</span><span class="o">=</span><span class="s1">'0.0.0.0'</span>, <span class="nv">port</span><span class="o">=</span>5002<span class="o">)</span>


<span class="c"># create user_service/requirements.txt for each service (user, order)</span>
flask
requests
pygelf

<span class="c"># modify each Dockerfile: Dockerfile-user</span>

<span class="c"># Use an official Python runtime as a parent image</span>
FROM python:3.9-slim

<span class="c"># Set the working directory in the container</span>
WORKDIR /app

<span class="c"># Copy the current directory contents into the container at /app</span>
COPY <span class="nb">.</span> /app

<span class="c"># Install any needed packages specified in requirements.txt</span>
RUN pip <span class="nb">install</span> <span class="nt">--no-cache-dir</span> <span class="nt">-r</span> requirements.txt

<span class="c"># Make port 5001 available to the world outside this container</span>
EXPOSE 5001

<span class="c"># Define environment variable</span>
ENV <span class="nv">FLASK_APP</span><span class="o">=</span>user_service.py

<span class="c"># Run user_service.py when the container launches</span>
CMD <span class="o">[</span><span class="s2">"flask"</span>, <span class="s2">"run"</span>, <span class="s2">"--host=0.0.0.0"</span>, <span class="s2">"--port=5001"</span><span class="o">]</span>


<span class="c"># vim Dockerfile-order</span>

<span class="c"># Use an official Python runtime as a parent image</span>
FROM python:3.9-slim

<span class="c"># Set the working directory in the container</span>
WORKDIR /app

<span class="c"># Copy the current directory contents into the container at /app</span>
COPY <span class="nb">.</span> /app

<span class="c"># Install any needed packages specified in requirements.txt</span>
RUN pip <span class="nb">install</span> <span class="nt">--no-cache-dir</span> <span class="nt">-r</span> requirements.txt

<span class="c"># Make port 5002 available to the world outside this container</span>
EXPOSE 5002

<span class="c"># Define environment variable</span>
ENV <span class="nv">FLASK_APP</span><span class="o">=</span>order_service.py

<span class="c"># Run order_service.py when the container launches</span>
CMD <span class="o">[</span><span class="s2">"flask"</span>, <span class="s2">"run"</span>, <span class="s2">"--host=0.0.0.0"</span>, <span class="s2">"--port=5002"</span><span class="o">]</span>

<span class="c"># modify docker-compose.yaml</span>

version: <span class="s1">'3'</span>
services:
 consul:
 image: consul:1.15.4
 ports:
 - <span class="s2">"8500:8500"</span>

 elasticsearch:
 image: docker.elastic.co/elasticsearch/elasticsearch:7.13.2
 environment:
 - discovery.type<span class="o">=</span>single-node
 ports:
 - <span class="s2">"9200:9200"</span>
 - <span class="s2">"9300:9300"</span>
 volumes:
 - esdata:/usr/share/elasticsearch/data

 logstash:
 image: docker.elastic.co/logstash/logstash:7.13.2
 volumes:
 - ./logstash.conf:/usr/share/logstash/pipeline/logstash.conf
 ports:
 - <span class="s2">"12201:12201/udp"</span>
 - <span class="s2">"5044:5044"</span>

 kibana:
 image: docker.elastic.co/kibana/kibana:7.13.2
 ports:
 - <span class="s2">"5601:5601"</span>
 depends_on:
 - elasticsearch

 user-service:
 build:
 context: ./user_service
 depends_on:
 - consul
 - logstash
 environment:
 - <span class="nv">CONSUL_HTTP_ADDR</span><span class="o">=</span>consul:8500
 ports:
 - <span class="s2">"5001:5001"</span>
 logging:
 driver: gelf
 options:
 gelf-address: udp://logstash:12201

 order-service:
 build:
 context: ./order_service
 depends_on:
 - consul
 - logstash
 environment:
 - <span class="nv">CONSUL_HTTP_ADDR</span><span class="o">=</span>consul:8500
 ports:
 - <span class="s2">"5002:5002"</span>
 logging:
 driver: gelf
 options:
 gelf-address: udp://logstash:12201

 api-gateway:
 build:
 context: ./api_gateway
 depends_on:
 - consul
 - user-service
 - order-service
 - logstash
 environment:
 - <span class="nv">CONSUL_HTTP_ADDR</span><span class="o">=</span>consul:8500
 ports:
 - <span class="s2">"5000:5000"</span>
 logging:
 driver: gelf
 options:
 gelf-address: udp://logstash:12201

volumes:
 esdata:</code></pre></figure>

<p>Now Run docker-compose to bring all containers up and running. Should see all services with ES, Logstash and Kibana populating logs on the screen.</p>

<figure class="highlight"><pre><code class="language-shell" data-lang="shell">docker-compose up <span class="nt">--build</span>

Creating 05-with-elk_logstash_1      ... <span class="k">done
</span>Creating 05-with-elk_consul_1        ... <span class="k">done
</span>Creating 05-with-elk_elasticsearch_1 ... <span class="k">done
</span>Creating 05-with-elk_kibana_1        ... <span class="k">done
</span>Creating 05-with-elk_user-service_1  ... <span class="k">done
</span>Creating 05-with-elk_order-service_1 ... <span class="k">done
</span>Creating 05-with-elk_api-gateway_1   ... <span class="k">done


</span>logstash_1       | <span class="o">[</span>2024-05-18T14:55:13,140][INFO <span class="o">][</span>logstash.inputs.udp      ][main][a30d8db137f99f1de18acbd53c081374cd720430a4dd0e752ff4a99c3005f9d0] Starting UDP listener <span class="o">{</span>:address<span class="o">=&gt;</span><span class="s2">"0.0.0.0:12201"</span><span class="o">}</span>
logstash_1       | <span class="o">[</span>2024-05-18T14:55:13,187][INFO <span class="o">][</span>logstash.inputs.udp      ][main][a30d8db137f99f1de18acbd53c081374cd720430a4dd0e752ff4a99c3005f9d0] UDP listener started <span class="o">{</span>:address<span class="o">=&gt;</span><span class="s2">"0.0.0.0:12201"</span>, :receive_buffer_bytes<span class="o">=&gt;</span><span class="s2">"106496"</span>, :queue_size<span class="o">=&gt;</span><span class="s2">"2000"</span><span class="o">}</span>
consul_1         | 2024-05-18T14:55:46.686Z <span class="o">[</span>DEBUG] agent: Skipping remote check since it is managed automatically: <span class="nv">check</span><span class="o">=</span>serfHealth
consul_1         | 2024-05-18T14:55:46.688Z <span class="o">[</span>DEBUG] agent: Node info <span class="k">in </span><span class="nb">sync
</span>logstash_1       | https://www.elastic.co/guide/en/logstash/current/monitoring-with-metricbeat.html
elasticsearch_1  | <span class="o">{</span><span class="s2">"type"</span>: <span class="s2">"deprecation.elasticsearch"</span>, <span class="s2">"timestamp"</span>: <span class="s2">"2024-05-18T14:55:09,016Z"</span>, <span class="s2">"level"</span>: <span class="s2">"DEPRECATION"</span>, <span class="s2">"component"</span>: <span class="s2">"o.e.d.r.RestController"</span>, <span class="s2">"cluster.name"</span>: <span class="s2">"docker-cluster"</span>, <span class="s2">"node.name"</span>: <span class="s2">"430bff78a529"</span>, <span class="s2">"message"</span>: <span class="s2">"Legacy index templates are deprecated in favor of composable templates."</span>, <span class="s2">"cluster.uuid"</span>: <span class="s2">"B9QKhgEGTA6Ot5auY9skQQ"</span>, <span class="s2">"node.id"</span>: <span class="s2">"QzKPL7DYSB2_CeWJpUaxXg"</span>  <span class="o">}</span>
kibana_1         | <span class="o">{</span><span class="s2">"type"</span>:<span class="s2">"log"</span>,<span class="s2">"@timestamp"</span>:<span class="s2">"2024-05-18T14:55:09+00:00"</span>,<span class="s2">"tags"</span>:[<span class="s2">"info"</span>,<span class="s2">"plugins"</span>,<span class="s2">"monitoring"</span>,<span class="s2">"monitoring"</span>,<span class="s2">"kibana-monitoring"</span><span class="o">]</span>,<span class="s2">"pid"</span>:952,<span class="s2">"message"</span>:<span class="s2">"Starting monitoring stats collection"</span><span class="o">}</span></code></pre></figure>

<p><img src="/assets/flask6.png" alt="image tooltip here" /></p>

<p><b> Verify ElasticSearch and Kibana</b></p>

<ul>
  <li>Validate ElasticSearch status via localhost:9200</li>
</ul>

<p><img src="/assets/flask7.png" alt="image tooltip here" /></p>

<ul>
  <li>Visit localhost:5601 to access Kibana dashboard, add Index Pattern “logs-*” to see data populated in the Discover tab</li>
</ul>

<p><img src="/assets/flask8.png" alt="image tooltip here" />
<b> Conclusion</b></p>

<p>Now we can enable logging with ELK stack, and use Logstash, ElasticSearch and Kibana.</p>

<p>In the next post, I will see how to enable monitoring with Prometheus and Grafana stack.</p>]]></content><author><name></name></author><category term="jekyll" /><category term="Cat2" /><summary type="html"><![CDATA[About logging with ELK (Elasticsearch, Logstash, Kibana) Stack]]></summary></entry><entry><title type="html">Python Flask: Logging with ELK</title><link href="http://localhost:4000/jekyll/cat2/2024/05/19/py-flask3.html" rel="alternate" type="text/html" title="Python Flask: Logging with ELK" /><published>2024-05-19T00:16:29+10:00</published><updated>2024-05-19T00:16:29+10:00</updated><id>http://localhost:4000/jekyll/cat2/2024/05/19/py-flask3</id><content type="html" xml:base="http://localhost:4000/jekyll/cat2/2024/05/19/py-flask3.html"><![CDATA[<p><b> About logging with ELK (Elasticsearch, Logstash, Kibana) Stack</b></p>

<p>ELK (Elasticsearch, Logstash, Kibana) is a popular log management solution. We will use the ELK Stack to collect and analyze logs. here I need to extend the current configuration by adding services for Elasticsearch, Logstash, and Kibana, and configure the microservices to send logs to Logstash.</p>

<p>Also, I will need to configure the logging in the Python applications to send logs to Logstash. Using the logging library in Python, I can send logs to Logstash using the GELF (Graylog Extended Log Format) format.</p>

<figure class="highlight"><pre><code class="language-shell" data-lang="shell"><span class="c"># folder structure </span>
05-with-ELK/
├── api_gateway/
│   └── Dockerfile
├── order_service/
│   └── Dockerfile
├── user_service/
│   └── Dockerfile
├── logstash.conf
└── docker-compose.yml

<span class="c"># create Logstash Configuration</span>
<span class="c"># vim logstash.conf</span>
input <span class="o">{</span>
 gelf <span class="o">{</span>
 port <span class="o">=&gt;</span> 12201
 <span class="o">}</span>
<span class="o">}</span>
output <span class="o">{</span>
 elasticsearch <span class="o">{</span>
 hosts <span class="o">=&gt;</span> <span class="o">[</span><span class="s2">"elasticsearch:9200"</span><span class="o">]</span>
 index <span class="o">=&gt;</span> <span class="s2">"%{[@metadata][beat]}-%{+YYYY.MM.dd}"</span>
 <span class="o">}</span>
<span class="o">}</span>
<span class="c"># vim user_service.py</span>

import logging
import requests
from flask import Flask, jsonify
from pygelf import GelfUdpHandler

app <span class="o">=</span> Flask<span class="o">(</span>__name__<span class="o">)</span>

@app.route<span class="o">(</span><span class="s1">'/users'</span><span class="o">)</span>
def get_users<span class="o">()</span>:
 <span class="nb">users</span> <span class="o">=</span> <span class="o">[</span>
 <span class="o">{</span><span class="s1">'id'</span>: 1, <span class="s1">'name'</span>: <span class="s1">'Alice'</span><span class="o">}</span>,
 <span class="o">{</span><span class="s1">'id'</span>: 2, <span class="s1">'name'</span>: <span class="s1">'Bob'</span><span class="o">}</span>
 <span class="o">]</span>
 app.logger.info<span class="o">(</span><span class="s2">"Fetched user data"</span><span class="o">)</span>
 <span class="k">return </span>jsonify<span class="o">(</span><span class="nb">users</span><span class="o">)</span>

def register_service<span class="o">()</span>:
 payload <span class="o">=</span> <span class="o">{</span>
 <span class="s2">"ID"</span>: <span class="s2">"user-service"</span>,
 <span class="s2">"Name"</span>: <span class="s2">"user-service"</span>,
 <span class="s2">"Address"</span>: <span class="s2">"user-service"</span>,
 <span class="s2">"Port"</span>: 5001
 <span class="o">}</span>
 response <span class="o">=</span> requests.put<span class="o">(</span><span class="s1">'http://consul:8500/v1/agent/service/register'</span>, <span class="nv">json</span><span class="o">=</span>payload<span class="o">)</span>
 <span class="k">if </span>response.status_code <span class="o">==</span> 200:
 app.logger.info<span class="o">(</span><span class="s2">"User service registered successfully"</span><span class="o">)</span>
 <span class="k">else</span>:
 app.logger.error<span class="o">(</span><span class="s2">"Failed to register user service"</span><span class="o">)</span>

<span class="k">if </span>__name__ <span class="o">==</span> <span class="s1">'__main__'</span>:
 <span class="c"># Configure logging</span>
 handler <span class="o">=</span> GelfUdpHandler<span class="o">(</span><span class="nv">host</span><span class="o">=</span><span class="s1">'logstash'</span>, <span class="nv">port</span><span class="o">=</span>12201<span class="o">)</span>
 app.logger.addHandler<span class="o">(</span>handler<span class="o">)</span>
 app.logger.setLevel<span class="o">(</span>logging.INFO<span class="o">)</span>
    
 register_service<span class="o">()</span>
 app.run<span class="o">(</span><span class="nv">host</span><span class="o">=</span><span class="s1">'0.0.0.0'</span>, <span class="nv">port</span><span class="o">=</span>5001<span class="o">)</span>

<span class="c"># vim order_service.py</span>

import logging
import requests
from flask import Flask, jsonify
from pygelf import GelfUdpHandler

app <span class="o">=</span> Flask<span class="o">(</span>__name__<span class="o">)</span>

@app.route<span class="o">(</span><span class="s1">'/orders'</span><span class="o">)</span>
def get_orders<span class="o">()</span>:
 orders <span class="o">=</span> <span class="o">[</span>
 <span class="o">{</span><span class="s1">'id'</span>: 1, <span class="s1">'item'</span>: <span class="s1">'Laptop'</span>, <span class="s1">'price'</span>: 1200<span class="o">}</span>,
 <span class="o">{</span><span class="s1">'id'</span>: 2, <span class="s1">'item'</span>: <span class="s1">'Phone'</span>, <span class="s1">'price'</span>: 800<span class="o">}</span>
 <span class="o">]</span>
 app.logger.info<span class="o">(</span><span class="s2">"Fetched order data"</span><span class="o">)</span>
 <span class="k">return </span>jsonify<span class="o">(</span>orders<span class="o">)</span>

def register_service<span class="o">()</span>:
 payload <span class="o">=</span> <span class="o">{</span>
 <span class="s2">"ID"</span>: <span class="s2">"order-service"</span>,
 <span class="s2">"Name"</span>: <span class="s2">"order-service"</span>,
 <span class="s2">"Address"</span>: <span class="s2">"order-service"</span>,
 <span class="s2">"Port"</span>: 5002
 <span class="o">}</span>
 response <span class="o">=</span> requests.put<span class="o">(</span><span class="s1">'http://consul:8500/v1/agent/service/register'</span>, <span class="nv">json</span><span class="o">=</span>payload<span class="o">)</span>
 <span class="k">if </span>response.status_code <span class="o">==</span> 200:
 app.logger.info<span class="o">(</span><span class="s2">"Order service registered successfully"</span><span class="o">)</span>
 <span class="k">else</span>:
 app.logger.error<span class="o">(</span><span class="s2">"Failed to register order service"</span><span class="o">)</span>

<span class="k">if </span>__name__ <span class="o">==</span> <span class="s1">'__main__'</span>:
 <span class="c"># Configure logging</span>
 handler <span class="o">=</span> GelfUdpHandler<span class="o">(</span><span class="nv">host</span><span class="o">=</span><span class="s1">'logstash'</span>, <span class="nv">port</span><span class="o">=</span>12201<span class="o">)</span>
 app.logger.addHandler<span class="o">(</span>handler<span class="o">)</span>
 app.logger.setLevel<span class="o">(</span>logging.INFO<span class="o">)</span>
    
 register_service<span class="o">()</span>
 app.run<span class="o">(</span><span class="nv">host</span><span class="o">=</span><span class="s1">'0.0.0.0'</span>, <span class="nv">port</span><span class="o">=</span>5002<span class="o">)</span>


<span class="c"># create user_service/requirements.txt for each service (user, order)</span>
flask
requests
pygelf

<span class="c"># modify each Dockerfile: Dockerfile-user</span>

<span class="c"># Use an official Python runtime as a parent image</span>
FROM python:3.9-slim

<span class="c"># Set the working directory in the container</span>
WORKDIR /app

<span class="c"># Copy the current directory contents into the container at /app</span>
COPY <span class="nb">.</span> /app

<span class="c"># Install any needed packages specified in requirements.txt</span>
RUN pip <span class="nb">install</span> <span class="nt">--no-cache-dir</span> <span class="nt">-r</span> requirements.txt

<span class="c"># Make port 5001 available to the world outside this container</span>
EXPOSE 5001

<span class="c"># Define environment variable</span>
ENV <span class="nv">FLASK_APP</span><span class="o">=</span>user_service.py

<span class="c"># Run user_service.py when the container launches</span>
CMD <span class="o">[</span><span class="s2">"flask"</span>, <span class="s2">"run"</span>, <span class="s2">"--host=0.0.0.0"</span>, <span class="s2">"--port=5001"</span><span class="o">]</span>


<span class="c"># vim Dockerfile-order</span>

<span class="c"># Use an official Python runtime as a parent image</span>
FROM python:3.9-slim

<span class="c"># Set the working directory in the container</span>
WORKDIR /app

<span class="c"># Copy the current directory contents into the container at /app</span>
COPY <span class="nb">.</span> /app

<span class="c"># Install any needed packages specified in requirements.txt</span>
RUN pip <span class="nb">install</span> <span class="nt">--no-cache-dir</span> <span class="nt">-r</span> requirements.txt

<span class="c"># Make port 5002 available to the world outside this container</span>
EXPOSE 5002

<span class="c"># Define environment variable</span>
ENV <span class="nv">FLASK_APP</span><span class="o">=</span>order_service.py

<span class="c"># Run order_service.py when the container launches</span>
CMD <span class="o">[</span><span class="s2">"flask"</span>, <span class="s2">"run"</span>, <span class="s2">"--host=0.0.0.0"</span>, <span class="s2">"--port=5002"</span><span class="o">]</span>

<span class="c"># modify docker-compose.yaml</span>

version: <span class="s1">'3'</span>
services:
 consul:
 image: consul:1.15.4
 ports:
 - <span class="s2">"8500:8500"</span>

 elasticsearch:
 image: docker.elastic.co/elasticsearch/elasticsearch:7.13.2
 environment:
 - discovery.type<span class="o">=</span>single-node
 ports:
 - <span class="s2">"9200:9200"</span>
 - <span class="s2">"9300:9300"</span>
 volumes:
 - esdata:/usr/share/elasticsearch/data

 logstash:
 image: docker.elastic.co/logstash/logstash:7.13.2
 volumes:
 - ./logstash.conf:/usr/share/logstash/pipeline/logstash.conf
 ports:
 - <span class="s2">"12201:12201/udp"</span>
 - <span class="s2">"5044:5044"</span>

 kibana:
 image: docker.elastic.co/kibana/kibana:7.13.2
 ports:
 - <span class="s2">"5601:5601"</span>
 depends_on:
 - elasticsearch

 user-service:
 build:
 context: ./user_service
 depends_on:
 - consul
 - logstash
 environment:
 - <span class="nv">CONSUL_HTTP_ADDR</span><span class="o">=</span>consul:8500
 ports:
 - <span class="s2">"5001:5001"</span>
 logging:
 driver: gelf
 options:
 gelf-address: udp://logstash:12201

 order-service:
 build:
 context: ./order_service
 depends_on:
 - consul
 - logstash
 environment:
 - <span class="nv">CONSUL_HTTP_ADDR</span><span class="o">=</span>consul:8500
 ports:
 - <span class="s2">"5002:5002"</span>
 logging:
 driver: gelf
 options:
 gelf-address: udp://logstash:12201

 api-gateway:
 build:
 context: ./api_gateway
 depends_on:
 - consul
 - user-service
 - order-service
 - logstash
 environment:
 - <span class="nv">CONSUL_HTTP_ADDR</span><span class="o">=</span>consul:8500
 ports:
 - <span class="s2">"5000:5000"</span>
 logging:
 driver: gelf
 options:
 gelf-address: udp://logstash:12201

volumes:
 esdata:</code></pre></figure>

<p>Now Run docker-compose to bring all containers up and running. Should see all services with ES, Logstash and Kibana populating logs on the screen.</p>

<figure class="highlight"><pre><code class="language-shell" data-lang="shell">docker-compose up <span class="nt">--build</span>

Creating 05-with-elk_logstash_1      ... <span class="k">done
</span>Creating 05-with-elk_consul_1        ... <span class="k">done
</span>Creating 05-with-elk_elasticsearch_1 ... <span class="k">done
</span>Creating 05-with-elk_kibana_1        ... <span class="k">done
</span>Creating 05-with-elk_user-service_1  ... <span class="k">done
</span>Creating 05-with-elk_order-service_1 ... <span class="k">done
</span>Creating 05-with-elk_api-gateway_1   ... <span class="k">done


</span>logstash_1       | <span class="o">[</span>2024-05-18T14:55:13,140][INFO <span class="o">][</span>logstash.inputs.udp      ][main][a30d8db137f99f1de18acbd53c081374cd720430a4dd0e752ff4a99c3005f9d0] Starting UDP listener <span class="o">{</span>:address<span class="o">=&gt;</span><span class="s2">"0.0.0.0:12201"</span><span class="o">}</span>
logstash_1       | <span class="o">[</span>2024-05-18T14:55:13,187][INFO <span class="o">][</span>logstash.inputs.udp      ][main][a30d8db137f99f1de18acbd53c081374cd720430a4dd0e752ff4a99c3005f9d0] UDP listener started <span class="o">{</span>:address<span class="o">=&gt;</span><span class="s2">"0.0.0.0:12201"</span>, :receive_buffer_bytes<span class="o">=&gt;</span><span class="s2">"106496"</span>, :queue_size<span class="o">=&gt;</span><span class="s2">"2000"</span><span class="o">}</span>
consul_1         | 2024-05-18T14:55:46.686Z <span class="o">[</span>DEBUG] agent: Skipping remote check since it is managed automatically: <span class="nv">check</span><span class="o">=</span>serfHealth
consul_1         | 2024-05-18T14:55:46.688Z <span class="o">[</span>DEBUG] agent: Node info <span class="k">in </span><span class="nb">sync
</span>logstash_1       | https://www.elastic.co/guide/en/logstash/current/monitoring-with-metricbeat.html
elasticsearch_1  | <span class="o">{</span><span class="s2">"type"</span>: <span class="s2">"deprecation.elasticsearch"</span>, <span class="s2">"timestamp"</span>: <span class="s2">"2024-05-18T14:55:09,016Z"</span>, <span class="s2">"level"</span>: <span class="s2">"DEPRECATION"</span>, <span class="s2">"component"</span>: <span class="s2">"o.e.d.r.RestController"</span>, <span class="s2">"cluster.name"</span>: <span class="s2">"docker-cluster"</span>, <span class="s2">"node.name"</span>: <span class="s2">"430bff78a529"</span>, <span class="s2">"message"</span>: <span class="s2">"Legacy index templates are deprecated in favor of composable templates."</span>, <span class="s2">"cluster.uuid"</span>: <span class="s2">"B9QKhgEGTA6Ot5auY9skQQ"</span>, <span class="s2">"node.id"</span>: <span class="s2">"QzKPL7DYSB2_CeWJpUaxXg"</span>  <span class="o">}</span>
kibana_1         | <span class="o">{</span><span class="s2">"type"</span>:<span class="s2">"log"</span>,<span class="s2">"@timestamp"</span>:<span class="s2">"2024-05-18T14:55:09+00:00"</span>,<span class="s2">"tags"</span>:[<span class="s2">"info"</span>,<span class="s2">"plugins"</span>,<span class="s2">"monitoring"</span>,<span class="s2">"monitoring"</span>,<span class="s2">"kibana-monitoring"</span><span class="o">]</span>,<span class="s2">"pid"</span>:952,<span class="s2">"message"</span>:<span class="s2">"Starting monitoring stats collection"</span><span class="o">}</span></code></pre></figure>

<p><img src="/assets/flask6.png" alt="image tooltip here" /></p>

<p><b> Verify ElasticSearch and Kibana</b></p>

<ul>
  <li>Validate ElasticSearch status via localhost:9200</li>
</ul>

<p><img src="/assets/flask7.png" alt="image tooltip here" /></p>

<ul>
  <li>Visit localhost:5601 to access Kibana dashboard, add Index Pattern “logs-*” to see data populated in the Discover tab</li>
</ul>

<p><img src="/assets/flask8.png" alt="image tooltip here" />
<b> Conclusion</b></p>

<p>Now we can enable logging with ELK stack, and use Logstash, ElasticSearch and Kibana.</p>

<p>In the next post, I will see how to enable monitoring with Prometheus and Grafana stack.</p>]]></content><author><name></name></author><category term="jekyll" /><category term="Cat2" /><summary type="html"><![CDATA[About logging with ELK (Elasticsearch, Logstash, Kibana) Stack]]></summary></entry></feed>