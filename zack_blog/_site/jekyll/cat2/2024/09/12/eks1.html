<!DOCTYPE html>
<html lang="en"><head>
  <meta charset="utf-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta name="viewport" content="width=device-width, initial-scale=1"><!-- Begin Jekyll SEO tag v2.8.0 -->
<title>EKS Cluster Autoscaler and Horizontal Pod Autoscaler (HPA) | Zack’s Blog</title>
<meta name="generator" content="Jekyll v4.3.2" />
<meta property="og:title" content="EKS Cluster Autoscaler and Horizontal Pod Autoscaler (HPA)" />
<meta property="og:locale" content="en_US" />
<meta name="description" content="Autoscaler and Horizontal Pod Autoscaler (HPA) Practice on EKS" />
<meta property="og:description" content="Autoscaler and Horizontal Pod Autoscaler (HPA) Practice on EKS" />
<link rel="canonical" href="http://localhost:4000/jekyll/cat2/2024/09/12/eks1.html" />
<meta property="og:url" content="http://localhost:4000/jekyll/cat2/2024/09/12/eks1.html" />
<meta property="og:site_name" content="Zack’s Blog" />
<meta property="og:type" content="article" />
<meta property="article:published_time" content="2024-09-12T10:15:29+10:00" />
<meta name="twitter:card" content="summary" />
<meta property="twitter:title" content="EKS Cluster Autoscaler and Horizontal Pod Autoscaler (HPA)" />
<script type="application/ld+json">
{"@context":"https://schema.org","@type":"BlogPosting","dateModified":"2024-09-12T10:15:29+10:00","datePublished":"2024-09-12T10:15:29+10:00","description":"Autoscaler and Horizontal Pod Autoscaler (HPA) Practice on EKS","headline":"EKS Cluster Autoscaler and Horizontal Pod Autoscaler (HPA)","mainEntityOfPage":{"@type":"WebPage","@id":"http://localhost:4000/jekyll/cat2/2024/09/12/eks1.html"},"url":"http://localhost:4000/jekyll/cat2/2024/09/12/eks1.html"}</script>
<!-- End Jekyll SEO tag -->
<link rel="stylesheet" href="/assets/main.css"><link type="application/atom+xml" rel="alternate" href="http://localhost:4000/feed.xml" title="Zack&apos;s Blog" /></head>
<body><header class="site-header" role="banner">

  <div class="wrapper"><a class="site-title" rel="author" href="/">Zack&#39;s Blog</a><nav class="site-nav">
        <input type="checkbox" id="nav-trigger" class="nav-trigger" />
        <label for="nav-trigger">
          <span class="menu-icon">
            <svg viewBox="0 0 18 15" width="18px" height="15px">
              <path d="M18,1.484c0,0.82-0.665,1.484-1.484,1.484H1.484C0.665,2.969,0,2.304,0,1.484l0,0C0,0.665,0.665,0,1.484,0 h15.032C17.335,0,18,0.665,18,1.484L18,1.484z M18,7.516C18,8.335,17.335,9,16.516,9H1.484C0.665,9,0,8.335,0,7.516l0,0 c0-0.82,0.665-1.484,1.484-1.484h15.032C17.335,6.031,18,6.696,18,7.516L18,7.516z M18,13.516C18,14.335,17.335,15,16.516,15H1.484 C0.665,15,0,14.335,0,13.516l0,0c0-0.82,0.665-1.483,1.484-1.483h15.032C17.335,12.031,18,12.695,18,13.516L18,13.516z"/>
            </svg>
          </span>
        </label>

        <div class="trigger"><a class="page-link" href="/certificate/">Education &amp; Certificate</a><a class="page-link" href="/pro/">Work Experiences</a><a class="page-link" href="/skillroadmap/">Skill Roadmap</a><a class="page-link" href="/aboutme/">About Me</a><a class="page-link" href="/gitrepo/">Github Repos</a></div>
      </nav></div>
</header>
<main class="page-content" aria-label="Content">
      <div class="wrapper">
        <article class="post h-entry" itemscope itemtype="http://schema.org/BlogPosting">

  <header class="post-header">
    <h1 class="post-title p-name" itemprop="name headline">EKS Cluster Autoscaler and Horizontal Pod Autoscaler (HPA)</h1>
    <p class="post-meta">
      <time class="dt-published" datetime="2024-09-12T10:15:29+10:00" itemprop="datePublished">Sep 12, 2024
      </time></p>
  </header>

  <div class="post-content e-content" itemprop="articleBody">
    <p><b>Autoscaler and Horizontal Pod Autoscaler (HPA) Practice on EKS </b></p>

<p>This post walks through the process of setting up an Autoscaler and Horizontal Pod Autoscaler (HPA) in an Amazon EKS cluster. We will explore how to dynamically scale the number of nodes in EKS cluster and how to autoscale K8S pods based on CPU utilization using HPA.</p>

<p>Prerequisites:</p>

<ul>
  <li>Use the <code class="language-plaintext highlighter-rouge">AWS CLI</code> to update kubeconfig so that kubectl can communicate with the EKS cluster</li>
</ul>

<figure class="highlight"><pre><code class="language-shell" data-lang="shell"><span class="nv">$ </span>aws eks <span class="nt">--region</span> ap-southeast-2 update-kubeconfig <span class="nt">--name</span> module-eks-cluster
Updated context arn:aws:eks:ap-southeast-2:851725491342:cluster/module-eks-cluster <span class="k">in </span>C:<span class="se">\U</span>sers<span class="se">\z</span>ack<span class="se">\.</span>kube<span class="se">\c</span>onfig

Verify that the nodes are ready:
<span class="nv">$ </span>kubectl.exe get node
NAME                                              STATUS   ROLES    AGE     VERSION
ip-172-31-37-57.ap-southeast-2.compute.internal   Ready    &lt;none&gt;   2m40s   v1.31.0-eks-a737599</code></pre></figure>

<ul>
  <li>Deploy the <code class="language-plaintext highlighter-rouge">Cluster Autoscaler</code> from the official Kubernetes Autoscaler GitHub repository, The Cluster Autoscaler automatically adjusts the number of nodes in eks cluster based on the resource requirements of the workloads.</li>
</ul>

<figure class="highlight"><pre><code class="language-shell" data-lang="shell"><span class="nv">$ </span>kubectl.exe apply <span class="nt">-f</span> https://raw.githubusercontent.com/kubernetes/autoscaler/refs/heads/master/cluster-autoscaler/cloudprovider/aws/examples/cluster-autoscaler-one-asg.yaml
serviceaccount/cluster-autoscaler created
clusterrole.rbac.authorization.k8s.io/cluster-autoscaler created
role.rbac.authorization.k8s.io/cluster-autoscaler created
clusterrolebinding.rbac.authorization.k8s.io/cluster-autoscaler created
rolebinding.rbac.authorization.k8s.io/cluster-autoscaler created
deployment.apps/cluster-autoscaler created</code></pre></figure>

<ul>
  <li>Modify the Autoscaler Parameters to tuning Scale-Up and Down Behavior.</li>
</ul>

<p>Customized Autoscaler parameters to add arguments to control the scaling behavior, such as the <code class="language-plaintext highlighter-rouge">minimum and maximum node counts</code>, the <code class="language-plaintext highlighter-rouge">time between scale-down events</code>, <code class="language-plaintext highlighter-rouge">stabilization window</code> and <code class="language-plaintext highlighter-rouge">cooldown period</code>.</p>

<figure class="highlight"><pre><code class="language-shell" data-lang="shell"><span class="nv">$ </span>kubectl <span class="nt">-n</span> kube-system edit deployment.apps/cluster-autoscaler
deployment.apps/cluster-autoscaler edited

      labels:
        app: cluster-autoscaler
    spec:
      containers:
      - <span class="nb">command</span>:
        - ./cluster-autoscaler
        - <span class="nt">--cluster-name</span><span class="o">=</span>module-eks-cluster
        - <span class="nt">--v</span><span class="o">=</span>4
        - <span class="nt">--stderrthreshold</span><span class="o">=</span>info
        - <span class="nt">--cloud-provider</span><span class="o">=</span>aws
        - <span class="nt">--skip-nodes-with-local-storage</span><span class="o">=</span><span class="nb">false</span>
        - <span class="nt">--balance-similar-node-groups</span>
        - <span class="nt">--skip-nodes-with-system-pods</span><span class="o">=</span><span class="nb">false</span>
        - <span class="nt">--scale-down-unneeded-time</span><span class="o">=</span>1m
        - <span class="nt">--scale-down-delay-after-add</span><span class="o">=</span>1m
        - <span class="nt">--nodes</span><span class="o">=</span>1:3:eks-module-eks-cluster-node-group-5ec93604-4bdc-a740-1fcc-707afc8431b</code></pre></figure>

<p><b>HPA testing based on Pod CPU utilization metric </b></p>

<ul>
  <li>Now, let’s deploy zackweb and set up an <code class="language-plaintext highlighter-rouge">Horizontal Pod Autoscaler (HPA)</code> to scale the number of pods based on CPU utilization.</li>
</ul>

<figure class="highlight"><pre><code class="language-shell" data-lang="shell"><span class="nv">$ </span><span class="nb">cat </span>deployment.yaml

apiVersion: apps/v1
kind: Deployment
metadata:
  name: zackblog
spec:
  replicas: 1  <span class="c"># Start with 1 replica</span>
  selector:
    matchLabels:
      app: zackblog
  template:
    metadata:
      labels:
        app: zackblog
    spec:
      containers:
      - name: zackblog
        image: zackz001/gitops-jekyll:latest
        resources:
          requests:
            cpu: <span class="s2">"500m"</span>  <span class="c"># 0.5 vCPU</span>
            memory: <span class="s2">"512Mi"</span>  <span class="c"># 0.5 GiB</span>
          limits:
            cpu: <span class="s2">"1"</span>  <span class="c"># 1 vCPU</span>
            memory: <span class="s2">"1Gi"</span>  <span class="c"># 1 GiB</span>
<span class="nt">---</span>
apiVersion: v1
kind: Service
metadata:
  name: zackblog
spec:
  selector:
    app: zackblog  <span class="c"># This must match the labels in the Deployment</span>
  ports:
    - protocol: TCP
      port: 80        <span class="c"># Port that the service will expose</span>
      targetPort: 80 <span class="c"># Port that the container listens on</span>
  <span class="nb">type</span>: LoadBalancer

kubectl.exe apply <span class="nt">-f</span> deployment.yaml
deployment.apps/zackblog created
service/zackblog created</code></pre></figure>

<ul>
  <li>Set Resource Requests and Limits, and Configure Horizontal Pod Autoscaler (HPA) to automatically scale the deployment based on CPU usage</li>
</ul>

<figure class="highlight"><pre><code class="language-shell" data-lang="shell"><span class="nv">$ </span>kubectl <span class="nb">set </span>resources deployment zackblog <span class="nt">--limits</span><span class="o">=</span><span class="nv">cpu</span><span class="o">=</span>200m,memory<span class="o">=</span>200Mi <span class="nt">--requests</span><span class="o">=</span><span class="nv">cpu</span><span class="o">=</span>100m,memory<span class="o">=</span>100Mi
deployment.apps/zackblog resource requirements updated

kubectl autoscale deployment zackblog <span class="nt">--cpu-percent</span><span class="o">=</span>50 <span class="nt">--min</span><span class="o">=</span>1 <span class="nt">--max</span><span class="o">=</span>3

<span class="nv">$ </span>kubectl get hpa zackblog
NAME       REFERENCE             TARGETS              MINPODS   MAXPODS   REPLICAS   AGE
zackblog   Deployment/zackblog   cpu: &lt;unknown&gt;/50%   1         3         1          18s</code></pre></figure>

<ul>
  <li>Generate CPU Load to Test the HPA</li>
</ul>

<p>To test the HPA, we need to generate CPU load by runing a busybox container to repeatedly request the zackblog service.</p>

<figure class="highlight"><pre><code class="language-shell" data-lang="shell">kubectl run <span class="nt">-i</span> <span class="nt">--tty</span> load-generator <span class="nt">--image</span><span class="o">=</span>busybox /bin/sh
<span class="c"># Inside the busybox shell, run this:</span>
<span class="k">while </span><span class="nb">true</span><span class="p">;</span> <span class="k">do </span>wget <span class="nt">-q</span> <span class="nt">-O-</span> http://zackblog <span class="o">&gt;</span> /dev/null<span class="p">;</span> <span class="nb">sleep </span>0.5<span class="p">;</span> <span class="k">done</span></code></pre></figure>

<ul>
  <li>Monitor the HPA and Scaling Events, As CPU utilization increases, the HPA will automatically scale the number of pods:</li>
</ul>

<figure class="highlight"><pre><code class="language-shell" data-lang="shell"><span class="nv">$ </span>kubectl.exe get po
NAME                       READY   STATUS             RESTARTS      AGE
load-generator             1/1     Running            0             2m6s
zackblog-95f746486-wlmgx   1/1     Running            0             6m20s

kubectl get hpa zackblog <span class="nt">-w</span>
NAME       REFERENCE             TARGETS       MINPODS   MAXPODS   REPLICAS   AGE
zackblog   Deployment/zackblog   cpu: 0%/50%   1         10        1          12m
zackblog   Deployment/zackblog   cpu: 92%/50%  1         10        2          5m
zackblog   Deployment/zackblog   cpu: 52%/50%  1         10        3          2m

kubectl get hpa zackblog <span class="nt">-w</span>
zackblog   Deployment/zackblog   cpu: 37%/50%   1         10        3          27m
zackblog   Deployment/zackblog   cpu: 38%/50%   1         10        3          27m
zackblog   Deployment/zackblog   cpu: 6%/50%    1         10        3          27m
zackblog   Deployment/zackblog   cpu: 0%/50%    1         10        3          27m
zackblog   Deployment/zackblog   cpu: 0%/50%    1         10        1          28m</code></pre></figure>

<p>It can be seen that pods got  scaled up to 3 when CPU utilization reached 92% and scaled down to 1 when CPU utilization dropped below 50%.</p>

<p><b>Testing EKS Cluster Autoscaler by changing deployment replicas: </b></p>

<p><code class="language-plaintext highlighter-rouge">EKS Cluster Autoscaler</code> comes with scale-in and scale-out policies, which define when nodes should be added or removed. The Cluster Autoscaler adds nodes when there aren’t enough resources to schedule pending pods and removes nodes when they are underutilized.</p>

<ul>
  <li>Change the resource limitation for zackblog deployment for EKS node autoscaler testing, Set zackweb deployment with requests cpu 500m. As the EKS node group with a t3.small instance type (2c2g), which means one node can only handle one pod, so to make the Autoscaler testing easier to achieve.</li>
</ul>

<figure class="highlight"><pre><code class="language-shell" data-lang="shell"><span class="nv">$ </span>vim deployment.yaml

        resources:
          requests:
            cpu: <span class="s2">"500m"</span>  <span class="c"># 0.5 vCPU</span>
            memory: <span class="s2">"512Mi"</span>  <span class="c"># 0.5 GiB</span>
          limits:
            cpu: <span class="s2">"1"</span>  <span class="c"># 1 vCPU</span>
            memory: <span class="s2">"1Gi"</span>  <span class="c"># 1 GiB</span></code></pre></figure>

<ul>
  <li>Gracefully increase the number of deployment replicas to 2, to test EKS node scale up</li>
</ul>

<figure class="highlight"><pre><code class="language-shell" data-lang="shell"><span class="nv">$ </span>kubectl scale deployment zackblog <span class="nt">--replicas</span><span class="o">=</span>2
deployment.apps/zackblog scaled

<span class="nv">$ </span>kubectl.exe get po
NAME                        READY   STATUS             RESTARTS      AGE
load-generator              1/1     Running            0             7m39s
zackblog-7f67584fbd-47jvt   1/1     Running            0             31s
zackblog-7f67584fbd-9gtfn   0/1     Pending            0             6s

<span class="nv">$ </span>kubectl.exe describe po zackblog-7f67584fbd-9gtfn

Events:
  Type     Reason            Age   From                Message
  <span class="nt">----</span>     <span class="nt">------</span>            <span class="nt">----</span>  <span class="nt">----</span>                <span class="nt">-------</span>
  Warning  FailedScheduling  18s   default-scheduler   0/1 nodes are available: 1 Insufficient memory. preemption: 0/1 nodes are available: 1 No preemption victims found <span class="k">for </span>incoming pod.
  Normal   TriggeredScaleUp  9s    cluster-autoscaler  pod triggered scale-up: <span class="o">[{</span>eks-module-eks-cluster-node-group-5ec93604-4bdc-a740-1fcc-707afc8431b3 1-&gt;2 <span class="o">(</span>max: 3<span class="o">)}]</span>

<span class="nv">$ </span>kubectl.exe get node
NAME                                               STATUS   ROLES    AGE   VERSION
ip-172-31-15-152.ap-southeast-2.compute.internal   Ready    &lt;none&gt;   31s   v1.31.0-eks-a737599
ip-172-31-37-57.ap-southeast-2.compute.internal    Ready    &lt;none&gt;   37m   v1.31.0-eks-a737599

<span class="nv">$ </span>kubectl.exe get po
NAME                        READY   STATUS             RESTARTS        AGE
load-generator              1/1     Running            0               9m14s
zackblog-7f67584fbd-47jvt   1/1     Running            0               2m6s
zackblog-7f67584fbd-9gtfn   1/1     Running            0               101s</code></pre></figure>

<p>It can be seen that pod <code class="language-plaintext highlighter-rouge">zackblog-7f67584fbd-9gtfn</code> was in pending state due to waiting for node to be scale-up, once we have 2 nodes in EKS cluster, that pod can be scheduled and run.</p>

<ul>
  <li>Increase the number of deployment replicas to 3, to trigger EKS node scale up again</li>
</ul>

<figure class="highlight"><pre><code class="language-shell" data-lang="shell"><span class="nv">$ </span>kubectl scale deployment zackblog <span class="nt">--replicas</span><span class="o">=</span>3
deployment.apps/zackblog scaled

<span class="nv">$ </span>kubectl.exe get po
NAME                        READY   STATUS             RESTARTS        AGE
load-generator              1/1     Running            0               9m44s
zackblog-7f67584fbd-47jvt   1/1     Running            0               2m36s
zackblog-7f67584fbd-9gtfn   1/1     Running            0               2m11s
zackblog-7f67584fbd-f5s9d   1/1     Running            0               3s


<span class="nv">$ </span>kubectl.exe get po <span class="nt">-o</span> wide
NAME                        READY   STATUS    RESTARTS   AGE     IP              NODE                                               NOMINATED NODE   READINESS GATES
zackblog-7f67584fbd-47jvt   1/1     Running   0          5m58s   172.31.37.227   ip-172-31-37-57.ap-southeast-2.compute.internal    &lt;none&gt;           &lt;none&gt;
zackblog-7f67584fbd-9gtfn   1/1     Running   0          5m33s   172.31.5.139    ip-172-31-15-152.ap-southeast-2.compute.internal   &lt;none&gt;           &lt;none&gt;
zackblog-7f67584fbd-vzcx4   1/1     Running   0          2m3s    172.31.18.111   ip-172-31-20-24.ap-southeast-2.compute.internal    &lt;none&gt;           &lt;none&gt;</code></pre></figure>

<p>Now EKS scale up to 3 nodes to handle the replica increase again.</p>

<ul>
  <li>Change the number of deployment replicas down to 1, to trigger EKS node scale down, and monitor by autoscaler log file to see the scale down behavior:</li>
</ul>

<figure class="highlight"><pre><code class="language-shell" data-lang="shell"><span class="nv">$ </span>kubectl scale deployment zackblog <span class="nt">--replicas</span><span class="o">=</span>1

<span class="nv">$ </span>kubectl <span class="nt">-n</span> kube-system logs <span class="nt">-f</span> deployment/cluster-autoscaler

I1008 12:53:22.686377       1 static_autoscaler.go:598] Starting scale down
I1008 12:53:22.686430       1 nodes.go:123] ip-172-31-15-152.ap-southeast-2.compute.internal was unneeded <span class="k">for </span>40.253885622s
I1008 12:53:22.686452       1 nodes.go:123] ip-172-31-37-57.ap-southeast-2.compute.internal was unneeded <span class="k">for </span>1m0.362059191s
I1008 12:53:22.686502       1 cluster.go:153] ip-172-31-37-57.ap-southeast-2.compute.internal <span class="k">for </span>removal
I1008 12:53:22.686644       1 hinting_simulator.go:77] Pod kube-system/cluster-autoscaler-5767f77d77-xgfjq can be moved to ip-172-31-20-24.ap-southeast-2.compute.internal
I1008 12:53:22.686717       1 hinting_simulator.go:77] Pod kube-system/coredns-7575495454-9n6kd can be moved to ip-172-31-15-152.ap-southeast-2.compute.internal
I1008 12:53:22.686832       1 hinting_simulator.go:77] Pod kube-system/coredns-7575495454-dxzdc can be moved to ip-172-31-15-152.ap-southeast-2.compute.internal
I1008 12:53:22.686875       1 cluster.go:176] node ip-172-31-37-57.ap-southeast-2.compute.internal may be removed
I1008 12:53:22.705270       1 delete.go:103] Successfully added ToBeDeletedTaint on node ip-172-31-37-57.ap-southeast-2.compute.internal
I1008 12:53:22.705367       1 actuator.go:212] Scale-down: removing node ip-172-31-37-57.ap-southeast-2.compute.internal, utilization: <span class="o">{</span>0.23316062176165803 0.49755477462428627 0 memory 0.49755477462428627<span class="o">}</span>, pods to reschedule: cluster-autoscaler-5767f77d77-xgfjq,coredns-7575495454-9n6kd,coredns-7575495454-dxzdc

<span class="nv">$ </span>kubectl.exe get node
NAME                                               STATUS                        ROLES    AGE     VERSION
ip-172-31-15-152.ap-southeast-2.compute.internal   NotReady,SchedulingDisabled   &lt;none&gt;   9m10s   v1.31.0-eks-a737599
ip-172-31-20-24.ap-southeast-2.compute.internal    Ready                         &lt;none&gt;   6m59s   v1.31.0-eks-a737599
ip-172-31-37-57.ap-southeast-2.compute.internal    Ready,SchedulingDisabled      &lt;none&gt;   45m     v1.31.0-eks-a737599

<span class="nv">$ </span>kubectl.exe get node
NAME                                              STATUS   ROLES    AGE     VERSION
ip-172-31-20-24.ap-southeast-2.compute.internal   Ready    &lt;none&gt;   7m58s   v1.31.0-eks-a737599</code></pre></figure>

<p>It can be seen that Cluster Autoscaler identified nodes that were underutilized or idle and marked them as “unneeded.”
It simulated moving the existing pods to other nodes. Once it determined that the pods could be rescheduled, it marked the node for deletion (using a ToBeDeletedTaint), preventing new workloads from being scheduled. Finally, the node was removed from the cluster, and the pods were successfully rescheduled on other nodes.</p>

<p>This behavior ensures that the cluster’s resources are used efficiently, scaling down when there is no workload, thereby reducing costs.</p>

<p><img src="/assets/eks1.png" alt="image tooltip here" /></p>

<p><b> Conclusion: </b></p>

<p>By following these steps, we can effectively manage the scaling of k8s applications and nodes in an EKS cluster using both the Cluster Autoscaler and Horizontal Pod Autoscaler (HPA). These tools ensure that the infrastructure adapts to varying workloads, optimizing resource utilization and costs.</p>

  </div><a class="u-url" href="/jekyll/cat2/2024/09/12/eks1.html" hidden></a>
</article>

      </div>
    </main><footer class="site-footer h-card">
  <data class="u-url" href="/"></data>

  <div class="wrapper">

    <h2 class="footer-heading">Zack&#39;s Blog</h2>

    <div class="footer-col-wrapper">
      <div class="footer-col footer-col-1">
        <ul class="contact-list">
          <li class="p-name">Zack&#39;s Blog</li><li><a class="u-email" href="mailto:zhbsoftboy1@gmail.com">zhbsoftboy1@gmail.com</a></li></ul>
      </div>

      <div class="footer-col footer-col-2"><ul class="social-media-list"><li><a href="https://github.com/ZackZhouHB"><svg class="svg-icon"><use xlink:href="/assets/minima-social-icons.svg#github"></use></svg> <span class="username">ZackZhouHB</span></a></li><li><a href="https://www.twitter.com/ZackZ"><svg class="svg-icon"><use xlink:href="/assets/minima-social-icons.svg#twitter"></use></svg> <span class="username">ZackZ</span></a></li></ul>
</div>

      <div class="footer-col footer-col-3">
        <p>## AWS   ## Jenkins  ## Microservices ## Automation ## K8S   ## CICD     ## Gitops </p>
      </div>
    </div>

  </div>

</footer>
</body>

</html>
